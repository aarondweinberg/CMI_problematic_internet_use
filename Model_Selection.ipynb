{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling**\n",
    "\n",
    "The purpose of this workbook is to set up a collection of models to test out-of-the-box performance, then to tune hyperparameters for several of the models. At the end, we will compare the performance of the top candidates and select one as our final model.\n",
    "\n",
    "The models we'll compare are:\n",
    "- multiple linear regression\n",
    "- knn regression\n",
    "- random forest\n",
    "- support vector\n",
    "- gradient boost\n",
    "- adaboost\n",
    "- xgboost \n",
    "\n",
    "Like in the Kaggle competition, performance will be measured using Cohen's kappa.\n",
    "\n",
    "Our target variable is sii. However, in the original data set, sii was computed from adding the twenty PCIAT variables and then grouping the total into bins. So we can try three different ways of evaluating the performance of these models:\n",
    "* Predicting sii directly\n",
    "* First predicting PCIAT_Total, then computing sii using the \"official\" bins\n",
    "* Adjusting the bins we use to compute sii\n",
    "\n",
    "We will also write an \"ordinal classifier\" wrapper (imported from an external file) as a \"wrapper\" for several models and compare their performance.\n",
    "\n",
    "After comparing out-of-the-box performance of the various models, we will try tuning several of the models and then comparing the OOTB and tuned versions of the best-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# CustomImputers includes two imputers (using KNN and interative imputing) for this dataset\n",
    "# and also two functions to transform fitnessgram values into fitnessgram zones, and to round sii values\n",
    "from CustomImputers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the Data and Creating Lists**\n",
    "\n",
    "In this section, we'll load the data (cleaned, with unnecessary features already removed) and create lists of predictors based on previous exploration\n",
    "\n",
    "For the purpose of developing our model(s), we'll work with data that include the imputed outcome (PCIAT_Total and/or sii) scores AND have cleaned predictors.\n",
    "\n",
    "In the final version of our code (which we'll submit to Kaggle), we'll work with data with cleaned predictors but won't have any access to the outcome scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the cleaned & outcome-imputed data\n",
    "train_cleaned=pd.read_csv('train_cleaned_outcome_imputed_feature_selected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an initial list of predictor columns\n",
    "\n",
    "predictors = train_cleaned.columns.tolist()\n",
    "if 'id' in predictors:\n",
    "    predictors.remove('id')\n",
    "if 'sii' in predictors:\n",
    "    predictors.remove('sii')\n",
    "predictors = [x for x in predictors if 'PCIAT' not in x]\n",
    "predictors = [x for x in predictors if 'Season' not in x]\n",
    "\n",
    "# Create an augmented list that will be used for \n",
    "predictors_plus = predictors + ['PCIAT-PCIAT_Total']\n",
    "\n",
    "# Create a list of \"key features\" based on work in the Feature Selection notebook\n",
    "keyfeatures = ['Basic_Demos-Age',\n",
    " 'Physical-Height',\n",
    " 'PreInt_EduHx-computerinternet_hoursday',\n",
    " 'BIA-BIA_FFM',\n",
    " 'SDS-SDS_Total_Raw',\n",
    " 'Physical-Weight',\n",
    " 'ENMO_Avg_Active_Days_MVPA110',\n",
    " 'FGC-FGC_CU']\n",
    "\n",
    "# The Fitness_Endurance predictor was creating havoc with the MLR models, so we'll omit it from the predictor list for those models\n",
    "predictors_less = [x for x in predictors if 'Fitness_Endurance_Total_Time_Sec' not in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trying a Linear Model**\n",
    "\n",
    "In this section, I'll make a linear model with a single predictor (hours spent on the internet)\n",
    "\n",
    "Note: Column selector documented here: https://stackoverflow.com/questions/62416223/how-to-select-only-few-columns-in-scikit-learn-column-selector-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLR MSE: 343.0355615764681\n",
      "MLR MSE: 5917.7087538693795\n",
      "MLR MSE after adding Basic_Demos-Age is 360.28860892976917\n",
      "MLR MSE after adding Basic_Demos-Sex is 357.85598178707306\n",
      "MLR MSE after adding CGAS-CGAS_Score is 357.48465633211987\n",
      "MLR MSE after adding Physical-BMI is 357.17851471911985\n",
      "MLR MSE after adding Physical-Height is 356.73168613893006\n",
      "MLR MSE after adding Physical-Weight is 356.6232170703393\n",
      "MLR MSE after adding Physical-Waist_Circumference is 355.9531351099258\n",
      "MLR MSE after adding Physical-Diastolic_BP is 355.8744058895502\n",
      "MLR MSE after adding Physical-HeartRate is 357.1000861457026\n",
      "MLR MSE after adding Physical-Systolic_BP is 359.1918572416056\n",
      "MLR MSE after adding FGC-FGC_CU is 361.74734194713284\n",
      "MLR MSE after adding FGC-FGC_PU is 362.5288001227467\n",
      "MLR MSE after adding FGC-FGC_TL is 364.5251985145941\n",
      "MLR MSE after adding BIA-BIA_Activity_Level_num is 364.3621408764233\n",
      "MLR MSE after adding BIA-BIA_FFM is 361.9976809076499\n",
      "MLR MSE after adding BIA-BIA_FFMI is 369.063579236326\n",
      "MLR MSE after adding BIA-BIA_FMI is 368.4024601761821\n",
      "MLR MSE after adding BIA-BIA_Fat is 363.32426518043115\n",
      "MLR MSE after adding BIA-BIA_Frame_num is 362.01221259586197\n",
      "MLR MSE after adding SDS-SDS_Total_Raw is 342.31995674928214\n",
      "MLR MSE after adding PreInt_EduHx-computerinternet_hoursday is 321.1854310958428\n",
      "MLR MSE after adding ENMO_Avg_Active_Days_MVPA192 is 317.9140114901311\n",
      "MLR MSE after adding ENMO_Avg_Active_Days_MVPA110 is 320.0069056127105\n",
      "MLR MSE after adding Positive_Anglez_Active_Days is 319.2105861779677\n",
      "MLR MSE after adding FGC-FGC_SR is 318.58026366159504\n",
      "MLR MSE after adding FGC-FGC_SR_Zone is 318.77865241341595\n",
      "MLR MSE after adding PAQ_Total is 318.81201040838664\n",
      "MLR MSE after adding PAQ_Zone is 318.8120104083866\n",
      "MLR MSE after adding Fitness_Endurance_Total_Time_Sec is 5917.7087538693795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# First I'll see if I can get a pipe set up to do prediction on a split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split the data into train and test\n",
    "train_tt, train_ho = train_test_split(train_cleaned, test_size=0.2)\n",
    "\n",
    "# Impute and compute values for the train and test sets\n",
    "mice = Custom_MICE_Imputer()\n",
    "train_tt = mice.fit_transform(train_tt)\n",
    "train_tt = zone_encoder(train_tt)\n",
    "train_ho = mice.fit_transform(train_ho)\n",
    "train_ho = zone_encoder(train_ho)\n",
    "\n",
    "# Set up SMOTE to create 128 (rather than 32) instances of sii=3 while keeping the other counts the same\n",
    "siiratios = {0: 1228, 1: 619, 2:315, 3:128}\n",
    "oversample = SMOTE(sampling_strategy=siiratios)\n",
    "X, y = oversample.fit_resample(train_tt[predictors_plus], train_tt['sii'])\n",
    "\n",
    "# Create pipes/models for single and multiple linear regression\n",
    "slr = Pipeline([\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', ['PreInt_EduHx-computerinternet_hoursday'])], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())])\n",
    "\n",
    "mlr = LinearRegression()\n",
    "\n",
    "# Fit and make predictions\n",
    "slr.fit(X[predictors], X['PCIAT-PCIAT_Total'])\n",
    "print('SLR MSE:', mean_squared_error(train_ho['PCIAT-PCIAT_Total'], slr.predict(train_ho)))\n",
    "\n",
    "mlr.fit(X[predictors], X['PCIAT-PCIAT_Total'])\n",
    "print('MLR MSE:', mean_squared_error(train_ho['PCIAT-PCIAT_Total'], mlr.predict(train_ho[predictors])))\n",
    "\n",
    "# The code below is meant to identify which predictor might be inflating the MLR\n",
    "templist = []\n",
    "for item in predictors:\n",
    "    templist = templist + [item]\n",
    "    mlr.fit(X[templist], X['PCIAT-PCIAT_Total'])\n",
    "    print('MLR MSE after adding',item,'is', mean_squared_error(train_ho['PCIAT-PCIAT_Total'], mlr.predict(train_ho[templist])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Models for Out-of-the-Box Performance**\n",
    "\n",
    "**Part 1: Setting Up Models**\n",
    "\n",
    "In the sections below, we'll set up a collection of un-tuned models and use them to predict sii scores. \n",
    "\n",
    "This first section instantiates the various models inside a dictionary that we'll use in the loop.\n",
    "\n",
    "Note that we **aren't** using SMOTE here because we're (sometimes) going to predict PCIAT-PCIAT_Total rather than sii, and we want SMOTE to generate synthetic points based on sii.\n",
    "\n",
    "Later, when we just want to predict sii, we can incorporate SMOTE into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "#Import our custom Ordinal Classifier wrapper\n",
    "from OrdinalClassifier import *\n",
    "\n",
    "# If we were including SMOTE in the pipeline, we'd need a different import statement\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create classifiers to use as inputs to ordinal classifiers\n",
    "\n",
    "# Note that the logistic regression is failing to converge.\n",
    "# This can be addressed - see https://stackoverflow.com/questions/62658215/convergencewarning-lbfgs-failed-to-converge-status-1-stop-total-no-of-iter\n",
    "# Here we're increasing max_iter from its default and also adding a standard scaler into its pipeline\n",
    "# We could also adjust the solver, ad described here: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "logisticc = LogisticRegression(max_iter=1000)\n",
    "\n",
    "knnc=KNeighborsClassifier(10)\n",
    "svc = SVC()\n",
    "rfc = RandomForestClassifier()\n",
    "# Note that the default for adaboost is the SAMME.R algorithm, but this will be deprecated in future releases. Switching to SAMME\n",
    "adac = AdaBoostClassifier(algorithm='SAMME')\n",
    "gradc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n",
    "\n",
    "#Note - for some reason, including Fitness_Endurance in MLR tanks its performance, so we'll leave it out of the predictors for MLR\n",
    "predictors_less = [x for x in predictors if 'Fitness_Endurance_Total_Time_Sec' not in x]\n",
    "\n",
    "\n",
    "# List the various models we'll try to identify their \"out of the box\" performance\n",
    "models = {\n",
    "'slr_pipe' : Pipeline([\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', ['PreInt_EduHx-computerinternet_hoursday'])], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())]),\n",
    "\n",
    "'mlr_key_pipe' : Pipeline([\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', keyfeatures)], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())]),\n",
    "\n",
    "'mlr_all_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', predictors_less)], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())]),\n",
    "\n",
    "'knn_pipe' : Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('knn', KNeighborsRegressor(10))]),\n",
    "\n",
    "'svr' : SVR(),\n",
    "\n",
    "'rf': RandomForestRegressor(),\n",
    "\n",
    "'ada' : AdaBoostRegressor(),\n",
    "\n",
    "'grad' : GradientBoostingRegressor(),\n",
    "\n",
    "'xgb': XGBRegressor(),\n",
    "\n",
    "'ordinal_logistic_pipe' : Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('logistic_oc', OrdinalClassifier(logisticc))]),\n",
    "\n",
    "'ordinal_knn_pipe' : Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('knn_ordinal', OrdinalClassifier(knnc))]),\n",
    "\n",
    "# Note that SVC doesn't have a predict_proba method. This can be manually added later in a custom classifier; removing for now to facilitate completion...\n",
    "#'ordinal_svc_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "#                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "#                ('svc_ordinal', OrdinalClassifier(svc))]),\n",
    "\n",
    "'ordinal_rf' : OrdinalClassifier(rfc),\n",
    "\n",
    "'ordinal_ada' : OrdinalClassifier(adac),\n",
    "\n",
    "'ordinal_grad': OrdinalClassifier(gradc),\n",
    "\n",
    "'ordinal_xgb': OrdinalClassifier(xgbc)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Models for Out-of-the-Box Performance**\n",
    "\n",
    "**Part 2: Evaluating Models**\n",
    "\n",
    "The second section runs the models through a 5-fold split to compute kappa values.\n",
    "\n",
    "We can predict sii scores in two ways:\n",
    "1. Predict the PCIAT_Total score and then compute sii values\n",
    "2. Predict the sii score directly\n",
    "\n",
    "We can also modify some of these computations by adjusting the bins for computing sii values and by adjusting the computed sii scores manually.\n",
    "\n",
    "Note: Column selector documented here: https://stackoverflow.com/questions/62416223/how-to-select-only-few-columns-in-scikit-learn-column-selector-pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling Minority Classes**\n",
    "\n",
    "One issue here is the extremely small number of sii=3 values in our data set: specifically, there are only 32 such instances in the dataset. This will make it difficult for models to predict an outcome of sii=3.\n",
    "\n",
    "We'll use SMOTE to create additional \"synthetic\" samples with sii=3 (see \n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n",
    "\n",
    "In short, SMOTE looks at the cases where sii=3, uses KNN to identify the five \"nearest\" cases, randomly selects one of these neighbors, and creates a new case where sii=3 by averaging the values of this selected neighbor with the actual sii=3 case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Set up SMOTE to create 128 (rather than 32) instances of sii=3\n",
    "siiratios = {0: 1228, 1: 619, 2:315, 3:128}\n",
    "oversample = SMOTE(sampling_strategy=siiratios)\n",
    "\n",
    "# Set up a list of the models and methods to organize the computation of means in the kfold split\n",
    "modellist = []\n",
    "for pipeline_name, pipeline_obj in models.items():\n",
    "    modellist.append(pipeline_name)\n",
    "\n",
    "methodlist = ['Compute SII from PCIAT (Standard Bins) (kappa)', \n",
    "                'Compute SII from PCIAT (Modified Bins) (kappa)',\n",
    "                'Predict SII (rounded) (kappa)']\n",
    "\n",
    "num_splits = 5\n",
    "\n",
    "# Create an array with len(modellist) rows and len(methodlist) columns\n",
    "output = np.zeros((len(methodlist), len(modellist), num_splits))\n",
    "\n",
    "#Make a StratifiedKFold object stratified by the variable sii\n",
    "# This is necessary due to the small number of sii=3 values\n",
    "kfold = StratifiedKFold(n_splits=num_splits, shuffle=True)\n",
    "\n",
    "## i will count the split number \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(train_cleaned, train_cleaned['sii']):\n",
    "    train_tt = train_cleaned.iloc[train_index]\n",
    "    train_ho = train_cleaned.iloc[test_index]\n",
    "\n",
    "    #Use our custom imputer and transformer to impute/compute necessary predictors\n",
    "    mice = Custom_MICE_Imputer()\n",
    "    train_tt = mice.fit_transform(train_tt)\n",
    "    train_tt = zone_encoder(train_tt)\n",
    "    train_ho = mice.fit_transform(train_ho)\n",
    "    train_ho = zone_encoder(train_ho)\n",
    "\n",
    "    # Use SMOTE to oversample the sii=3 minority class\n",
    "    X, y = oversample.fit_resample(train_tt[predictors_plus], train_tt['sii'])\n",
    "\n",
    "    # j will enumerate the model\n",
    "    j=0\n",
    "\n",
    "    for pipeline_name, pipeline_obj in models.items():\n",
    "        # The ordinal predictors can't predict PCIAT scores, so we'll leave them out of the first round of computations\n",
    "        if 'ordinal' in pipeline_name:\n",
    "            kappa_sii_comp = 0\n",
    "            kappa_sii_comp_mod = 0\n",
    "        else:\n",
    "            # Fit and make predictions of PCIAT_Total\n",
    "            pipeline_obj.fit(X[predictors_less], X['PCIAT-PCIAT_Total'])\n",
    "            pred = pipeline_obj.predict(train_ho[predictors_less])\n",
    "\n",
    "            # Compute sii based on PCIAT\n",
    "            bins = [0, 30, 49,79,100]\n",
    "            pred_bin = np.digitize(pred, bins)-1\n",
    "\n",
    "            # Try a slightly different set of bins suggested by the \"tuning\" below\n",
    "            bins_mod = [0, 27, 39, 79, 100]\n",
    "            pred_bin_mod = np.digitize(pred, bins_mod)-1\n",
    "\n",
    "            # Compute kappa values\n",
    "            kappa_sii_comp = cohen_kappa_score(train_ho['sii'], pred_bin, weights='quadratic')\n",
    "            kappa_sii_comp_mod = cohen_kappa_score(train_ho['sii'], pred_bin_mod, weights='quadratic')\n",
    "        \n",
    "        # Store the kappa values in the output array\n",
    "        output[0,j,i] = kappa_sii_comp\n",
    "        output[1,j,i] = kappa_sii_comp_mod\n",
    "        j=j+1\n",
    "\n",
    "    j=0\n",
    "    for pipeline_name, pipeline_obj in models.items():\n",
    "        # Fit and make predictions of sii\n",
    "        pipeline_obj.fit(X[predictors], y)\n",
    "        pred = pipeline_obj.predict(train_ho[predictors])\n",
    "\n",
    "        # Round the predictors to compute kappa\n",
    "        pred_round = np.round(pred)\n",
    "\n",
    "        # Compute and record the kappa values\n",
    "        kappa_sii_round = cohen_kappa_score(train_ho['sii'], pred_round, weights='quadratic')\n",
    "\n",
    "        output[2,j,i] = kappa_sii_round\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "\n",
    "# Create a new array by computing the average of the values in output along the third axis\n",
    "output_avg = np.mean(output, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slr_pipe</th>\n",
       "      <th>mlr_key_pipe</th>\n",
       "      <th>mlr_all_pipe</th>\n",
       "      <th>knn_pipe</th>\n",
       "      <th>svr</th>\n",
       "      <th>rf</th>\n",
       "      <th>ada</th>\n",
       "      <th>grad</th>\n",
       "      <th>xgb</th>\n",
       "      <th>ordinal_logistic_pipe</th>\n",
       "      <th>ordinal_knn_pipe</th>\n",
       "      <th>ordinal_rf</th>\n",
       "      <th>ordinal_ada</th>\n",
       "      <th>ordinal_grad</th>\n",
       "      <th>ordinal_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Compute SII from PCIAT (Standard Bins) (kappa)</th>\n",
       "      <td>0.255586</td>\n",
       "      <td>0.420277</td>\n",
       "      <td>0.417688</td>\n",
       "      <td>0.371806</td>\n",
       "      <td>0.285835</td>\n",
       "      <td>0.407872</td>\n",
       "      <td>0.383164</td>\n",
       "      <td>0.405178</td>\n",
       "      <td>0.378211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compute SII from PCIAT (Modified Bins) (kappa)</th>\n",
       "      <td>0.320950</td>\n",
       "      <td>0.451147</td>\n",
       "      <td>0.449815</td>\n",
       "      <td>0.393062</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.441952</td>\n",
       "      <td>0.427930</td>\n",
       "      <td>0.450957</td>\n",
       "      <td>0.394311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predict SII (rounded) (kappa)</th>\n",
       "      <td>0.279026</td>\n",
       "      <td>0.407338</td>\n",
       "      <td>0.402916</td>\n",
       "      <td>0.372991</td>\n",
       "      <td>0.325849</td>\n",
       "      <td>0.354275</td>\n",
       "      <td>0.166847</td>\n",
       "      <td>0.394077</td>\n",
       "      <td>0.332422</td>\n",
       "      <td>0.393088</td>\n",
       "      <td>0.306073</td>\n",
       "      <td>0.323828</td>\n",
       "      <td>0.333468</td>\n",
       "      <td>0.418456</td>\n",
       "      <td>0.382866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                slr_pipe  mlr_key_pipe  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)  0.255586      0.420277   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)  0.320950      0.451147   \n",
       "Predict SII (rounded) (kappa)                   0.279026      0.407338   \n",
       "\n",
       "                                                mlr_all_pipe  knn_pipe  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)      0.417688  0.371806   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)      0.449815  0.393062   \n",
       "Predict SII (rounded) (kappa)                       0.402916  0.372991   \n",
       "\n",
       "                                                     svr        rf       ada  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)  0.285835  0.407872  0.383164   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)  0.349600  0.441952  0.427930   \n",
       "Predict SII (rounded) (kappa)                   0.325849  0.354275  0.166847   \n",
       "\n",
       "                                                    grad       xgb  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)  0.405178  0.378211   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)  0.450957  0.394311   \n",
       "Predict SII (rounded) (kappa)                   0.394077  0.332422   \n",
       "\n",
       "                                                ordinal_logistic_pipe  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)               0.000000   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)               0.000000   \n",
       "Predict SII (rounded) (kappa)                                0.393088   \n",
       "\n",
       "                                                ordinal_knn_pipe  ordinal_rf  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)          0.000000    0.000000   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)          0.000000    0.000000   \n",
       "Predict SII (rounded) (kappa)                           0.306073    0.323828   \n",
       "\n",
       "                                                ordinal_ada  ordinal_grad  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)     0.000000      0.000000   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)     0.000000      0.000000   \n",
       "Predict SII (rounded) (kappa)                      0.333468      0.418456   \n",
       "\n",
       "                                                ordinal_xgb  \n",
       "Compute SII from PCIAT (Standard Bins) (kappa)     0.000000  \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)     0.000000  \n",
       "Predict SII (rounded) (kappa)                      0.382866  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data frame from output using modellist as the names of the columns and methodlist as the names of the rows\n",
    "output_df = pd.DataFrame(output_avg, columns=modellist, index=methodlist)\n",
    "\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results of OOtB Investigation**\n",
    "\n",
    "* The multiple regression - both using all predictors and using just the \"key\" features had among the largest kappa values.\n",
    "* Gradient Boosting - both as a regressor and inside an ordinal classifier - was at or near the top of kappa values.\n",
    "* Logistic regression inside an ordinal classifier did well\n",
    "* Random forest performed decently for predicting PCIAT scores and then computing sii values\n",
    "* XGBoost performed decently for predicting sii values both via regression and inside an ordinal classifier.\n",
    "* Adaboost performed well for predicting PCIAT, but not for predicting sii\n",
    "\n",
    "Predicting PCIAT and then computing sii benefitted from adjusting the cutpoints.\n",
    "\n",
    "In the sections below, we'll \"tune\" the cutpoints and then try tuning a few of the models and re-testing the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning the Bins**\n",
    "\n",
    "We noticed that our model struggled to predict higher output values.\n",
    "\n",
    "When we adjusted the values for converting PCIAT scores to sii scores, we noticed an improvement in prediction when we lowered the cutpoints.\n",
    "\n",
    "We sought to \"tune\" these cutpoints. However, we need to be mindful of overfitting. \n",
    "\n",
    "We'll look at the combination of cutpoints that maximize kappa, and then from the top 20 (or so) select the cutpoints that are closest to the original ones (as measured by euclidean distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# We'll use the multiple linear regression with \"key\" features to test the cutpoints\n",
    "# This model performed as good or better than most of the other (untuned) models\n",
    "# Since it is quick to run, it should be a decent choice for doing this tuning\n",
    "\n",
    "# Start by setting up the MLR pipeline\n",
    "mlr_key_pipe=Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', keyfeatures)], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())])\n",
    "\n",
    "# Set the number of k-fold splits\n",
    "num_splits = 5\n",
    "\n",
    "# Set the number of different cutpoints to try\n",
    "num_bincuts=15\n",
    "\n",
    "# Create an array with len(modellist) rows and len(methodlist) columns\n",
    "output = np.zeros((num_bincuts, num_bincuts,num_bincuts, num_splits))\n",
    "\n",
    "#Make a KFold object, stratified on sii=3 values\n",
    "kfold= StratifiedKFold(n_splits=num_splits, shuffle=True)\n",
    "\n",
    "## i will count the split number \n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(train_cleaned, train_cleaned['sii']):\n",
    "    train_tt = train_cleaned.iloc[train_index]\n",
    "    train_ho = train_cleaned.iloc[test_index]\n",
    "\n",
    "    # Compute and impute\n",
    "    mice = Custom_MICE_Imputer()\n",
    "    train_tt = mice.fit_transform(train_tt)\n",
    "    train_tt = zone_encoder(train_tt)\n",
    "    train_ho = mice.fit_transform(train_ho)\n",
    "    train_ho = zone_encoder(train_ho)\n",
    "\n",
    "    #Oversample with SMOTE\n",
    "    X, y = oversample.fit_resample(train_tt[predictors_plus], train_tt['sii'])\n",
    "\n",
    "    \n",
    "    # Fit the pipe and make predictions\n",
    "    mlr_key_pipe.fit(train_tt[predictors], train_tt['PCIAT-PCIAT_Total'])\n",
    "    pred = mlr_key_pipe.predict(train_ho[predictors])\n",
    "\n",
    "    # Iterate through values of the three cutpoints    \n",
    "    for r in range(num_bincuts):\n",
    "        for s in range(num_bincuts):\n",
    "            for t in range(num_bincuts):\n",
    "                bins = [0, 30-r, 49-s,79-t,100]\n",
    "                pred_bin_mod = np.digitize(pred, bins)-1\n",
    "                # Compute kappa for the binned predictions\n",
    "                kappa_sii_comp_mod = cohen_kappa_score(train_ho['sii'], pred_bin_mod, weights='quadratic')\n",
    "                output[r,s,t,i]=kappa_sii_comp_mod\n",
    "                \n",
    "    i=i+1\n",
    "\n",
    "# Create a new array by computing the average of the values in output along the third axis\n",
    "output_avg = np.mean(output, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll examine the output of the tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top values: [0.46093949 0.46093949 0.46093949 0.46093949 0.4605503  0.4605503\n",
      " 0.4605503  0.4605503  0.4605503  0.4605503  0.4605503  0.4605503\n",
      " 0.4605503  0.4605503  0.4605503  0.46037258 0.46037258 0.46037258\n",
      " 0.46037258 0.46005213]\n",
      "Locations of the top values: [(4, 11, 13), (4, 11, 11), (4, 11, 14), (4, 11, 12), (4, 11, 0), (4, 11, 1), (4, 11, 2), (4, 11, 3), (4, 11, 4), (4, 11, 5), (4, 11, 7), (4, 11, 8), (4, 11, 9), (4, 11, 10), (4, 11, 6), (3, 11, 14), (3, 11, 13), (3, 11, 12), (3, 11, 11), (4, 10, 14)]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the array and sort the indices in descending order\n",
    "sorted_indices_flat = np.argsort(output_avg.ravel())[::-1]\n",
    "\n",
    "#Decide how many top values you want to look at. \n",
    "n=20\n",
    "\n",
    "# Get the flat indices of the top two values\n",
    "top_flat_indices = sorted_indices_flat[:n]\n",
    "\n",
    "# Convert the flat indices to 3D indices\n",
    "top_indices = [np.unravel_index(idx, output_avg.shape) for idx in top_flat_indices]\n",
    "\n",
    "# Retrieve the top two values\n",
    "top_values = output_avg.ravel()[top_flat_indices]\n",
    "\n",
    "print(\"Top values:\", top_values)\n",
    "print(\"Locations of the top values:\", top_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results of Cutpoint Tuning**\n",
    "\n",
    "We ran the code above, looked at the top 20 (in terms of kappa) sets of cutpoints, and selected the combination of cutpoints that minimized the Euclidean distance to the original cutpoints. Then we repeated this two more times. The results were:\n",
    "\n",
    "* First time: [0, 30-3, 49-6,79-8,100] = [0, 27, 43, 71, 100]\n",
    "* Second time: [0, 30-3, 49-11,79-0,100] = [0, 27, 38, 79, 100]\n",
    "* Third time: [0, 30-3, 49-10,79-0,100] = [0, 27, 39, 79, 100]\n",
    "\n",
    "We'll use this third set of cutpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**\n",
    "\n",
    "The models above were run \"out of the box.\" In the next sections, we'll try to tune a few of them (random forest, gradient boost, and logistic regression inside an ordinal classifier) to see how much we can improve their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning the Random Forest Regressor**\n",
    "\n",
    "In this section, we'll tune the random forest regressor.\n",
    "\n",
    "Note that using a pipeline with gridcvsearch requires slightly different naming conventions for the parameter grid: \n",
    "https://stackoverflow.com/questions/34889110/random-forest-with-gridsearchcv-error-on-param-grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                                       (&#x27;rf&#x27;, RandomForestRegressor())]),\n",
       "             param_grid={&#x27;rf__max_depth&#x27;: range(1, 10),\n",
       "                         &#x27;rf__min_samples_split&#x27;: [2, 4, 8],\n",
       "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200, 500]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                                       (&#x27;rf&#x27;, RandomForestRegressor())]),\n",
       "             param_grid={&#x27;rf__max_depth&#x27;: range(1, 10),\n",
       "                         &#x27;rf__min_samples_split&#x27;: [2, 4, 8],\n",
       "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200, 500]},\n",
       "             return_train_score=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                (&#x27;add_zones&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                (&#x27;rf&#x27;,\n",
       "                 RandomForestRegressor(max_depth=5, min_samples_split=4,\n",
       "                                       n_estimators=200))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Custom_MICE_Imputer</label><div class=\"sk-toggleable__content fitted\"><pre>Custom_MICE_Imputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=5, min_samples_split=4, n_estimators=200)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('mice_impute', Custom_MICE_Imputer()),\n",
       "                                       ('add_zones',\n",
       "                                        FunctionTransformer(func=<function zone_encoder at 0x305cc5800>)),\n",
       "                                       ('rf', RandomForestRegressor())]),\n",
       "             param_grid={'rf__max_depth': range(1, 10),\n",
       "                         'rf__min_samples_split': [2, 4, 8],\n",
       "                         'rf__n_estimators': [50, 100, 200, 500]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Below is the initial parameter grid we're trying\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200, 500],\n",
    "    'rf__max_depth': range(1,10),\n",
    "    'rf__min_samples_split': [2, 4, 8]\n",
    "}\n",
    "\n",
    "#Below is the last round of parameters we're trying after several iterations\n",
    "#param_grid = {\n",
    "#    'rf__n_estimators': [90, 95, 100, 105, 110],\n",
    "#    'rf__max_depth': [6],\n",
    "#    'rf__min_samples_split': [4]\n",
    "#}\n",
    "\n",
    "# Instantiate a random forest pipeline\n",
    "rf_pipe = Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('rf', RandomForestRegressor())])\n",
    "\n",
    "grid_cv_rf = GridSearchCV(rf_pipe, \n",
    "                          param_grid = param_grid, \n",
    "                          cv = 5,\n",
    "                          return_train_score=True)\n",
    "\n",
    "# We'll start by tuning on PCIAT, and can tune separately on sii\n",
    "grid_cv_rf.fit(train_cleaned[predictors], train_cleaned['PCIAT-PCIAT_Total'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'rf__max_depth': 5, 'rf__min_samples_split': 4, 'rf__n_estimators': 200}\n",
      "Best score: 0.28041971572948254\n"
     ]
    }
   ],
   "source": [
    "# Report the results\n",
    "print('Best parameters:',grid_cv_rf.best_params_)\n",
    "print('Best score:',grid_cv_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results from GridSearch for Random Forest Regressor**\n",
    "\n",
    "The first run took 30 minutes using the following parameter grid:\n",
    "* 'rf__n_estimators': [50, 100, 200, 500],\n",
    "* 'rf__max_depth': range(1,10),\n",
    "* 'rf__min_samples_split': [2, 4, 8]\n",
    "\n",
    "The best parameters, achieving a score of 0.28379 were:\n",
    "* max_depth: 6\n",
    "* min_samples_split: 4\n",
    "* n_estimators: 100\n",
    "\n",
    "(When run again, we got a score of 0.280419 using [5, 4, 200])\n",
    "\n",
    "The second run took 4 minutes, using a narrower ranges of parameters:\n",
    "* 'rf__n_estimators': [75, 100, 150],\n",
    "* 'rf__max_depth': range(4,7),\n",
    "* 'rf__min_samples_split': [3, 4, 5]\n",
    "\n",
    "The best parameters, achieving a score of 0.28396 were:\n",
    "* max_depth: 6\n",
    "* min_samples_split: 4\n",
    "* n_estimators: 100\n",
    "\n",
    "We will try one more search, further narrowing the ranges:\n",
    "* 'rf__n_estimators': [90, 95, 100, 105, 110],\n",
    "* 'rf__max_depth': [6],\n",
    "* 'rf__min_samples_split': [4]\n",
    "\n",
    "The best parameters, achieving a score of 0.2812376 were:\n",
    "* n_estimators: 105\n",
    "\n",
    "We noticed that this score was lower than the previous run, so we tried re-running. This time, the best parameters, achieving a score of 0.280982 were:\n",
    "* n_estimators: 110\n",
    "\n",
    "A third run yielded a score of 0.2808725 with\n",
    "* n_estimators: 95\n",
    "\n",
    "So it seems like the original set of best parameters (6, 4, 100) will likely work fine for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking Random Forest (for PCIAT) for Overfitting**\n",
    "\n",
    "We can look at the mean_train_scores and mean_test_scores reported for each of the combinations of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_rf__max_depth', 'param_rf__min_samples_split', 'param_rf__n_estimators', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'mean_train_score', 'std_train_score'])\n",
      "(108,)\n",
      "(108,)\n",
      "[0.18390851 0.1834061  0.1848826  0.18449659 0.18404056 0.18436459\n",
      " 0.18384535 0.18378982 0.18431751 0.18283691 0.18496858 0.18405515\n",
      " 0.25742096 0.25823451 0.25693219 0.2580366  0.25651277 0.25735381\n",
      " 0.25703056 0.2580047  0.25808027 0.25758818 0.25770655 0.25802382\n",
      " 0.30977512 0.31116411 0.31120783 0.31124656 0.31087921 0.31123801\n",
      " 0.31112095 0.31148983 0.31079393 0.31121341 0.31083666 0.31166513\n",
      " 0.3666522  0.36872735 0.36941598 0.37005238 0.36860141 0.36930643\n",
      " 0.3691513  0.36951611 0.36698516 0.36821696 0.36881649 0.36975469\n",
      " 0.43559861 0.43858173 0.43776722 0.43837075 0.4355979  0.43676003\n",
      " 0.43680054 0.4385272  0.43313105 0.43382588 0.43580186 0.43579634\n",
      " 0.51007341 0.51268948 0.51511001 0.5158286  0.50995223 0.51322764\n",
      " 0.51362813 0.51419195 0.5034699  0.50595627 0.50613317 0.50787075\n",
      " 0.58960228 0.59169742 0.59360909 0.59390345 0.5867165  0.58752614\n",
      " 0.59129789 0.59156611 0.57519783 0.57511237 0.57799087 0.57704273\n",
      " 0.66120092 0.66516648 0.66732824 0.66732009 0.65679192 0.65988546\n",
      " 0.66111856 0.66270685 0.63643764 0.64205698 0.63936427 0.64116583\n",
      " 0.72528815 0.72807543 0.72896653 0.73104578 0.71695003 0.72131721\n",
      " 0.72207608 0.72304234 0.68778119 0.6936574  0.69452405 0.69701713]\n",
      "[0.17061769 0.17184049 0.17318512 0.17307608 0.17234171 0.17252117\n",
      " 0.17202234 0.1729669  0.17253526 0.17204165 0.17332977 0.17286158\n",
      " 0.23862088 0.24310388 0.2406377  0.24212726 0.24259055 0.24266836\n",
      " 0.24133504 0.2419706  0.24269235 0.24214532 0.24146176 0.24263325\n",
      " 0.26789026 0.26841859 0.2671284  0.26761909 0.26616681 0.2658822\n",
      " 0.26779315 0.26759774 0.26582996 0.26516254 0.26736889 0.2671682\n",
      " 0.27642127 0.27910375 0.27689714 0.27765636 0.27509106 0.27525021\n",
      " 0.2764196  0.27689729 0.27286477 0.27512187 0.27485428 0.27715788\n",
      " 0.27807503 0.27795674 0.27937373 0.27958796 0.27456433 0.27646205\n",
      " 0.28041972 0.28006192 0.2769242  0.27933355 0.27989021 0.27943195\n",
      " 0.27353588 0.27817088 0.28001721 0.2791369  0.27248095 0.27561919\n",
      " 0.27673455 0.27791612 0.27736643 0.27577518 0.27887859 0.2798473\n",
      " 0.27212801 0.27464199 0.27543055 0.27712747 0.27324979 0.27372296\n",
      " 0.27405298 0.27605841 0.27306392 0.2748068  0.27710879 0.2773548\n",
      " 0.2695717  0.27295124 0.2742259  0.27518003 0.26572219 0.26774708\n",
      " 0.27205005 0.27390151 0.26957479 0.27453459 0.27637955 0.27622832\n",
      " 0.26675593 0.26642842 0.2753146  0.27437127 0.26583498 0.26753719\n",
      " 0.27293484 0.2749152  0.26736259 0.26921135 0.27158403 0.27389657]\n"
     ]
    }
   ],
   "source": [
    "# Check for overfitting\n",
    "# Start by getting the mean scores for the train and test\n",
    "\n",
    "print(grid_cv_rf.cv_results_.keys())\n",
    "print(grid_cv_rf.cv_results_[\"mean_train_score\"].shape)  # n_estimators: 11 values, max_depth: 4 values. Thus shape, 11*4=44\n",
    "print(grid_cv_rf.cv_results_[\"mean_test_score\"].shape)\n",
    "\n",
    "print(grid_cv_rf.cv_results_[\"mean_train_score\"])\n",
    "print(grid_cv_rf.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean_train_score: [0.43680054]\n",
      "Best mean_test_score: [0.28041972]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify the mean_train_score and mean_test_score values associated with best_score\n",
    "best_score_index = np.where(grid_cv_rf.cv_results_[\"mean_test_score\"]==grid_cv_rf.best_score_)\n",
    "print('Best mean_train_score:', grid_cv_rf.cv_results_[\"mean_train_score\"][best_score_index])\n",
    "print('Best mean_test_score:', grid_cv_rf.cv_results_[\"mean_test_score\"][best_score_index])\n",
    "\n",
    "#Create a df with grid_cv_grad.cv_results_[\"mean_train_score\"] as the first column and grid_cv_grad.cv_results_[\"mean_test_score\"] as the second column\n",
    "rf_results_df = pd.DataFrame({'mean_train_score': grid_cv_rf.cv_results_[\"mean_train_score\"], 'mean_test_score': grid_cv_rf.cv_results_[\"mean_test_score\"]})\n",
    "\n",
    "# Compute a new collumn that is the ratio of mean_train_score to mean_test_score\n",
    "rf_results_df['ratio'] = rf_results_df['mean_train_score']/rf_results_df['mean_test_score']\n",
    "\n",
    "# Identify outliers in ratio\n",
    "Q1 = rf_results_df['ratio'].quantile(0.25)\n",
    "Q3 = rf_results_df['ratio'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = rf_results_df[(rf_results_df['ratio'] < (Q1 - 1.5 * IQR)) | (rf_results_df['ratio'] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# Remove the outliers from grad_results_df\n",
    "rf_sii_results_df = rf_results_df[~rf_results_df['ratio'].isin(outliers['ratio'])]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram of ratio\n",
    "plt.hist(rf_results_df['ratio'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The ratio of train kappas to test kappas using our \"best\" set of parameters was 1.557666985759775. This seems like it might correspond to overfitting. But it seems in line with the (non-outlier) ratios among all tested sets of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning Random Forest for Predicting sii**\n",
    "\n",
    "In the section above, we trained a random forest regressor to predict PCIAT scores.\n",
    "\n",
    "Next, we'll train it for sii scores. Since we are now predicting sii, we can use SMOTE as part of the pipeline.\n",
    "\n",
    "GridSearchCV doesn't include kappa as a built-in metric. In addition, RF will use regression to predict sii scores, and these will need to be rounded.\n",
    "\n",
    "So we'll need to make a custom scorer to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                                       (&#x27;over&#x27;,\n",
       "                                        SMOTE(sampling_strategy={0: 1228,\n",
       "                                                                 1: 619, 2: 315,\n",
       "                                                                 3: 128})),\n",
       "                                       (&#x27;rf&#x27;, RandomForestRegressor())]),\n",
       "             param_grid={&#x27;rf__max_depth&#x27;: range(1, 11),\n",
       "                         &#x27;rf__min_samples_split&#x27;: [2, 4, 8],\n",
       "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(sii_kappa, response_method=&#x27;predict&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                                       (&#x27;over&#x27;,\n",
       "                                        SMOTE(sampling_strategy={0: 1228,\n",
       "                                                                 1: 619, 2: 315,\n",
       "                                                                 3: 128})),\n",
       "                                       (&#x27;rf&#x27;, RandomForestRegressor())]),\n",
       "             param_grid={&#x27;rf__max_depth&#x27;: range(1, 11),\n",
       "                         &#x27;rf__min_samples_split&#x27;: [2, 4, 8],\n",
       "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(sii_kappa, response_method=&#x27;predict&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                (&#x27;add_zones&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                (&#x27;over&#x27;,\n",
       "                 SMOTE(sampling_strategy={0: 1228, 1: 619, 2: 315, 3: 128})),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor(max_depth=6))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Custom_MICE_Imputer</label><div class=\"sk-toggleable__content fitted\"><pre>Custom_MICE_Imputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">SMOTE</label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(sampling_strategy={0: 1228, 1: 619, 2: 315, 3: 128})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=6)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('mice_impute', Custom_MICE_Imputer()),\n",
       "                                       ('add_zones',\n",
       "                                        FunctionTransformer(func=<function zone_encoder at 0x305cc5800>)),\n",
       "                                       ('over',\n",
       "                                        SMOTE(sampling_strategy={0: 1228,\n",
       "                                                                 1: 619, 2: 315,\n",
       "                                                                 3: 128})),\n",
       "                                       ('rf', RandomForestRegressor())]),\n",
       "             param_grid={'rf__max_depth': range(1, 11),\n",
       "                         'rf__min_samples_split': [2, 4, 8],\n",
       "                         'rf__n_estimators': [50, 100, 200]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(sii_kappa, response_method='predict'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "#Importing classes to use SMOTE in a pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Create a custom scorer that first rounds the values of sii and then applies a cohen_kappa_score\n",
    "def sii_kappa(y_true, y_pred):\n",
    "    y_pred_round = np.round(y_pred)\n",
    "    return cohen_kappa_score(y_true, y_pred_round, weights='quadratic')\n",
    "\n",
    "kappa_scorer = make_scorer(sii_kappa)\n",
    "\n",
    "# Set up SMOTE to create 128 (rather than 32) instances of sii=3\n",
    "siiratios = {0: 1228, 1: 619, 2:315, 3:128}\n",
    "oversample = SMOTE(sampling_strategy=siiratios)\n",
    "\n",
    "#Below is the initial parameter grid we used\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': range(1,11),\n",
    "    'rf__min_samples_split': [2, 4, 8]\n",
    "}\n",
    "\n",
    "#Below is the last iteration of the parameter grid we used\n",
    "#param_grid = {\n",
    "#    'rf__n_estimators': [50, 75, 100],\n",
    "#    'rf__max_depth': range(5, 7),\n",
    "#    'rf__min_samples_split': [8, 10, 12]\n",
    "#}\n",
    "\n",
    "# Instantiate a random forest pipeline\n",
    "rf_pipe_sii = Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('over', oversample),\n",
    "                ('rf', RandomForestRegressor())])\n",
    "\n",
    "grid_cv_rf_sii = GridSearchCV(rf_pipe_sii, \n",
    "                          param_grid = param_grid, \n",
    "                          scoring = kappa_scorer, \n",
    "                          cv = 5,\n",
    "                          return_train_score = True)\n",
    "\n",
    "grid_cv_rf_sii.fit(train_cleaned[predictors], train_cleaned['sii'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'rf__max_depth': 6, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "Best score: 0.40595844368852746\n"
     ]
    }
   ],
   "source": [
    "# Report the results\n",
    "print('Best parameters:',grid_cv_rf_sii.best_params_)\n",
    "print('Best score:',grid_cv_rf_sii.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results from GridSearch for Random Forest Regressor for sii**\n",
    "\n",
    "The first run (done before we incorporated SMOTE) took 14 minutes using the following parameter grid:\n",
    "* 'rf__n_estimators': [50, 100, 200],\n",
    "* 'rf__max_depth': range(1,11),\n",
    "* 'rf__min_samples_split': [2, 4, 8]\n",
    "\n",
    "The best parameters, achieving a score of 0.36574 were:\n",
    "* max_depth: 8\n",
    "* min_samples_split: 8\n",
    "* n_estimators: 50\n",
    "\n",
    "On a second run with the original parameters but using SMOTE, we got a score of 0.40595 using [6, 2, 100]\n",
    "\n",
    "The second run took 4 minutes, using a narrower ranges of parameters:\n",
    "* 'rf__n_estimators': [25, 50, 75],\n",
    "* 'rf__max_depth': range(5,7),\n",
    "* 'rf__min_samples_split': [6, 8, 10]\n",
    "\n",
    "The best parameters, achieving a score of 0.364877 were:\n",
    "* max_depth: 6\n",
    "* min_samples_split: 10\n",
    "* n_estimators: 75\n",
    "\n",
    "We will try one more search, further narrowing the ranges:\n",
    "* 'rf__n_estimators': [50, 75, 100],\n",
    "* 'rf__max_depth': range(5, 7),\n",
    "* 'rf__min_samples_split': [8, 10, 12]\n",
    "\n",
    "The best parameters, achieving a score of 0.3576324 were:\n",
    "* max_depth: 6\n",
    "* min_samples_split: 10\n",
    "* n_estimators: 50\n",
    "\n",
    "Re-running, The best parameters, achieving a score of 0.35866 were:\n",
    "* max_depth: 6\n",
    "* min_samples_split: 8\n",
    "* n_estimators: 50\n",
    "\n",
    "Re-running one more time WITH SMOTE, the best parameters, achieving a score of 0.40938 were\n",
    "* max_depth: 5\n",
    "* min_samples_split: 8\n",
    "* n_estimators: 75\n",
    "\n",
    "So it seems like the set of best parameters (5, 8, 75) will likely be ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for Overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_rf__max_depth', 'param_rf__min_samples_split', 'param_rf__n_estimators', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'mean_train_score', 'std_train_score'])\n",
      "(90,)\n",
      "(90,)\n",
      "[0.31295261 0.31255306 0.31249781 0.31308296 0.30767403 0.30885906\n",
      " 0.31278834 0.30919119 0.30732978 0.36631831 0.40238114 0.37237101\n",
      " 0.38655556 0.39632033 0.39251838 0.38594886 0.3825209  0.39601109\n",
      " 0.44926826 0.44868662 0.43414517 0.43681397 0.44372658 0.43765974\n",
      " 0.44755988 0.44507598 0.44348152 0.48759026 0.49145322 0.49070118\n",
      " 0.48684891 0.48841374 0.48845935 0.48005647 0.4960198  0.48359903\n",
      " 0.55909422 0.54989074 0.55263152 0.55469487 0.55876084 0.55258538\n",
      " 0.55310935 0.54989776 0.553267   0.62286495 0.62386246 0.61958474\n",
      " 0.62069999 0.61679752 0.61731506 0.61633932 0.6237753  0.61746473\n",
      " 0.68778721 0.68563181 0.6966813  0.69010285 0.68962381 0.69387107\n",
      " 0.66963465 0.68702995 0.67671868 0.75360891 0.76192324 0.76127616\n",
      " 0.7554393  0.75099424 0.75336148 0.738083   0.73597218 0.73437007\n",
      " 0.81577199 0.82058826 0.8167761  0.80806    0.80738834 0.81197588\n",
      " 0.77773645 0.77667382 0.78226528 0.86082271 0.87267098 0.86755651\n",
      " 0.84947242 0.85859411 0.85537576 0.81089718 0.82017635 0.82164249]\n",
      "[0.31516906 0.31788103 0.30854988 0.31011334 0.30172651 0.30227588\n",
      " 0.30897395 0.3047183  0.30868614 0.35667941 0.37701393 0.36451553\n",
      " 0.37398152 0.38306876 0.38523402 0.38464494 0.37594815 0.37820804\n",
      " 0.38540283 0.39660164 0.39612155 0.38999769 0.38491179 0.3875436\n",
      " 0.38020801 0.39932813 0.38496281 0.39559088 0.39016419 0.40201927\n",
      " 0.39061772 0.39375852 0.40267216 0.39149742 0.40247957 0.39018721\n",
      " 0.39362665 0.38154369 0.39110203 0.39082703 0.38235981 0.38538012\n",
      " 0.39700165 0.40056094 0.39890587 0.39289109 0.40595844 0.38431945\n",
      " 0.38629348 0.3768095  0.39034118 0.3988228  0.40382708 0.38634629\n",
      " 0.38619236 0.37958228 0.39454491 0.38264147 0.39214666 0.38984769\n",
      " 0.38854988 0.38779754 0.38376347 0.38663985 0.38509137 0.37795905\n",
      " 0.3752672  0.38367463 0.40263    0.38502552 0.38179931 0.38974573\n",
      " 0.36170105 0.36963383 0.38569391 0.38454502 0.38011406 0.39108928\n",
      " 0.37681183 0.37134267 0.38193338 0.37658412 0.37137768 0.36836671\n",
      " 0.36824122 0.37403479 0.38284722 0.36662799 0.38752825 0.38905669]\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv_rf_sii.cv_results_.keys())\n",
    "print(grid_cv_rf_sii.cv_results_[\"mean_train_score\"].shape)  # n_estimators: 11 values, max_depth: 4 values. Thus shape, 11*4=44\n",
    "print(grid_cv_rf_sii.cv_results_[\"mean_test_score\"].shape)\n",
    "\n",
    "print(grid_cv_rf_sii.cv_results_[\"mean_train_score\"])\n",
    "print(grid_cv_rf_sii.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean_train_score: [0.62386246]\n",
      "Best mean_test_score: [0.40595844]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify the mean_train_score and mean_test_score values associated with best_score\n",
    "best_score_index = np.where(grid_cv_rf_sii.cv_results_[\"mean_test_score\"]==grid_cv_rf_sii.best_score_)\n",
    "print('Best mean_train_score:', grid_cv_rf_sii.cv_results_[\"mean_train_score\"][best_score_index])\n",
    "print('Best mean_test_score:', grid_cv_rf_sii.cv_results_[\"mean_test_score\"][best_score_index])\n",
    "\n",
    "#Create a df with grid_cv_grad.cv_results_[\"mean_train_score\"] as the first column and grid_cv_grad.cv_results_[\"mean_test_score\"] as the second column\n",
    "rf_sii_results_df = pd.DataFrame({'mean_train_score': grid_cv_rf_sii.cv_results_[\"mean_train_score\"], 'mean_test_score': grid_cv_rf_sii.cv_results_[\"mean_test_score\"]})\n",
    "\n",
    "# Compute a new collumn that is the ratio of mean_train_score to mean_test_score\n",
    "rf_sii_results_df['ratio'] = rf_sii_results_df['mean_train_score']/rf_sii_results_df['mean_test_score']\n",
    "\n",
    "# Identify outliers in ratio\n",
    "Q1 = rf_sii_results_df['ratio'].quantile(0.25)\n",
    "Q3 = rf_sii_results_df['ratio'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = rf_sii_results_df[(rf_sii_results_df['ratio'] < (Q1 - 1.5 * IQR)) | (rf_sii_results_df['ratio'] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# Remove the outliers from grad_results_df\n",
    "rf_sii_results_df = rf_sii_results_df[~rf_sii_results_df['ratio'].isin(outliers['ratio'])]\n",
    "\n",
    "# Create a histogram of ratio\n",
    "plt.hist(rf_sii_results_df['ratio'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The ratio of train kappas to test kappas using our \"best\" set of parameters was 1.536. This seems like it might correspond to overfitting. But it seems in line with the (non-outlier) ratios among all tested sets of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning Gradient Boosting Regressor for PCIAT**\n",
    "\n",
    "There are lots of parameters to consider here.\n",
    "\n",
    "We'll use some suggestions from various websites to think about a parameter grid, being mindful of the amount of time it will take to run the code.\n",
    "\n",
    "Sources consulted:\n",
    "* https://stackoverflow.com/questions/49500313/tune-parameters-in-gradient-boosting-reggression-with-cross-validation-sklearn\n",
    "* https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae\n",
    "* https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "Note that we have a total of ~2500 observations with PCIAT scores in the entire dataset, a very small (32) number of scores with sii=3 and a relatively small number of scores with sii=2. SMOTE could help with this, but we can't use it inside a pipe when we're trying to predict PCIAT. (We could do this tuning manually, but due to time constraints, we're going to stick with using GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                                       (&#x27;grad&#x27;, GradientBoostingRegressor())]),\n",
       "             param_grid={&#x27;grad__learning_rate&#x27;: [0.5, 0.1, 0.05],\n",
       "                         &#x27;grad__max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;grad__max_features&#x27;: [10, 15, 20, 25],\n",
       "                         &#x27;grad__min_samples_leaf&#x27;: [5, 8, 11],\n",
       "                         &#x27;grad__min_samples_split&#x27;: [3, 5, 7],\n",
       "                         &#x27;grad__n_estimators&#x27;: [50, 100, 200]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                                       (&#x27;grad&#x27;, GradientBoostingRegressor())]),\n",
       "             param_grid={&#x27;grad__learning_rate&#x27;: [0.5, 0.1, 0.05],\n",
       "                         &#x27;grad__max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;grad__max_features&#x27;: [10, 15, 20, 25],\n",
       "                         &#x27;grad__min_samples_leaf&#x27;: [5, 8, 11],\n",
       "                         &#x27;grad__min_samples_split&#x27;: [3, 5, 7],\n",
       "                         &#x27;grad__n_estimators&#x27;: [50, 100, 200]},\n",
       "             return_train_score=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                (&#x27;add_zones&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                (&#x27;grad&#x27;,\n",
       "                 GradientBoostingRegressor(max_features=10, min_samples_leaf=8,\n",
       "                                           min_samples_split=3,\n",
       "                                           n_estimators=50))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Custom_MICE_Imputer</label><div class=\"sk-toggleable__content fitted\"><pre>Custom_MICE_Imputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(max_features=10, min_samples_leaf=8,\n",
       "                          min_samples_split=3, n_estimators=50)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('mice_impute', Custom_MICE_Imputer()),\n",
       "                                       ('add_zones',\n",
       "                                        FunctionTransformer(func=<function zone_encoder at 0x305cc5800>)),\n",
       "                                       ('grad', GradientBoostingRegressor())]),\n",
       "             param_grid={'grad__learning_rate': [0.5, 0.1, 0.05],\n",
       "                         'grad__max_depth': [3, 5, 7],\n",
       "                         'grad__max_features': [10, 15, 20, 25],\n",
       "                         'grad__min_samples_leaf': [5, 8, 11],\n",
       "                         'grad__min_samples_split': [3, 5, 7],\n",
       "                         'grad__n_estimators': [50, 100, 200]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'grad__learning_rate': [0.5, 0.1, 0.05],\n",
    "    'grad__max_depth': [3,5,7],\n",
    "    'grad__max_features': [10, 15, 20, 25],\n",
    "    'grad__min_samples_leaf': [5, 8, 11],\n",
    "    'grad__min_samples_split': [3, 5, 7],\n",
    "    'grad__n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Instantiate a gradient boosting regressor pipeline\n",
    "grad_pipe = Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('grad', GradientBoostingRegressor())])\n",
    "\n",
    "grid_cv_grad = GridSearchCV(grad_pipe, \n",
    "                          param_grid = param_grid, \n",
    "                          cv = 5,\n",
    "                          return_train_score=True)\n",
    "\n",
    "# We'll start by tuning on PCIAT, and can tune separately on sii\n",
    "grid_cv_grad.fit(train_cleaned[predictors], train_cleaned['PCIAT-PCIAT_Total'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'grad__learning_rate': 0.1, 'grad__max_depth': 3, 'grad__max_features': 10, 'grad__min_samples_leaf': 8, 'grad__min_samples_split': 3, 'grad__n_estimators': 50}\n",
      "Best score: 0.292846048851039\n"
     ]
    }
   ],
   "source": [
    "# Report the results\n",
    "print('Best parameters:',grid_cv_grad.best_params_)\n",
    "print('Best score:',grid_cv_grad.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning Results**\n",
    "\n",
    "Best parameters (first run): \n",
    "* 'grad__learning_rate': 0.05\n",
    "* 'grad__max_depth': 3\n",
    "* 'grad__max_features': 15\n",
    "* 'grad__min_samples_leaf': 11\n",
    "* 'grad__min_samples_split': 6\n",
    "* 'grad__n_estimators': 100\n",
    "\n",
    "Best parameters (second run):\n",
    "* learning_rate: 0.1\n",
    "* max_depth: 3\n",
    "* max_features: 10\n",
    "* min_samples_leaf: 8\n",
    "* min_samples_spit: 3\n",
    "* n_estimators: 50\n",
    "\n",
    "The differences suggest that there is some variance based on the random selection of the CV split and/or that the maximum values of kappa among these random variations are quite similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_grad__learning_rate', 'param_grad__max_depth', 'param_grad__max_features', 'param_grad__min_samples_leaf', 'param_grad__min_samples_split', 'param_grad__n_estimators', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'mean_train_score', 'std_train_score'])\n",
      "(972,)\n",
      "(972,)\n",
      "[0.65189586 0.80029376 0.92135735 0.65409586 0.7987357  0.92351374\n",
      " 0.64791556 0.79767938 0.92096862 0.64412865 0.78515763 0.9157732\n",
      " 0.64353646 0.78795314 0.914249   0.64554734 0.78419286 0.91561709\n",
      " 0.63226408 0.77356867 0.9070727  0.64147087 0.78337    0.91038977\n",
      " 0.63575623 0.77927076 0.9084253  0.66322111 0.8184424  0.93250769\n",
      " 0.66289117 0.80994802 0.93586184 0.66342119 0.81080982 0.9343366\n",
      " 0.65728543 0.80195557 0.92413289 0.66170712 0.80956102 0.92983166\n",
      " 0.66690465 0.80886754 0.92763755 0.65245624 0.79517396 0.92254721\n",
      " 0.65708512 0.79551046 0.92154243 0.64641113 0.79731922 0.9232357\n",
      " 0.67395427 0.8209492  0.94129207 0.67336322 0.81823353 0.94052184\n",
      " 0.67307346 0.82435958 0.94229279 0.67027595 0.8161572  0.93279165\n",
      " 0.66951364 0.80842316 0.9356467  0.66684437 0.81502087 0.93455539\n",
      " 0.65871962 0.81136805 0.92548785 0.66300114 0.80087669 0.93025916\n",
      " 0.66866546 0.80794351 0.92887239 0.68210305 0.83330467 0.94302522\n",
      " 0.69170109 0.83379137 0.94662273 0.67610895 0.82751615 0.946011\n",
      " 0.67426306 0.82449329 0.93983009 0.67979508 0.819426   0.93901929\n",
      " 0.67275613 0.82728062 0.94141588 0.67270287 0.81174117 0.93502558\n",
      " 0.67511422 0.81289105 0.93277821 0.66923346 0.81463129 0.93362977\n",
      " 0.91751972 0.98841317 0.99946262 0.91666775 0.98643493 0.9994655\n",
      " 0.91537775 0.98754719 0.99948084 0.90275999 0.98208128 0.99912071\n",
      " 0.91229273 0.98333791 0.99910289 0.90131056 0.98307634 0.99911301\n",
      " 0.89007044 0.97856423 0.99866204 0.89530804 0.97640983 0.9985671\n",
      " 0.89129443 0.97734963 0.99855026 0.92279771 0.99010257 0.99954754\n",
      " 0.92409105 0.9907938  0.99956096 0.92985305 0.99008895 0.99956657\n",
      " 0.91706437 0.98495038 0.99935393 0.91204967 0.98635712 0.99928184\n",
      " 0.91620783 0.98680001 0.99937509 0.89773649 0.98042453 0.99905379\n",
      " 0.89997687 0.98047789 0.99889472 0.9037276  0.9821602  0.99899429\n",
      " 0.9357123  0.99179629 0.99960838 0.93560098 0.99125544 0.99961875\n",
      " 0.93402468 0.99086088 0.99960304 0.91780146 0.98758699 0.99944282\n",
      " 0.91686563 0.98628468 0.99939939 0.91889319 0.98649071 0.99941258\n",
      " 0.90994207 0.98306271 0.9990908  0.90468921 0.98295134 0.99908396\n",
      " 0.90791496 0.9835853  0.99905876 0.9355014  0.99177515 0.99964257\n",
      " 0.93433668 0.99226094 0.99961381 0.93982019 0.99167147 0.99962623\n",
      " 0.92319384 0.98811497 0.99945602 0.92710627 0.98807768 0.99944747\n",
      " 0.92394716 0.98926133 0.99940344 0.91688043 0.98281587 0.99922348\n",
      " 0.90599984 0.98517155 0.99920554 0.91424386 0.98266491 0.99915476\n",
      " 0.99476105 0.99972722 0.9997829  0.99495547 0.99974018 0.9997829\n",
      " 0.99549358 0.99973501 0.9997829  0.99015282 0.99959799 0.99978277\n",
      " 0.98881403 0.99949812 0.99978278 0.98947958 0.99954805 0.99978278\n",
      " 0.98295544 0.99918161 0.99978192 0.98199159 0.99911534 0.99978205\n",
      " 0.98154192 0.99914661 0.99978205 0.99600448 0.99975362 0.9997829\n",
      " 0.99612487 0.99974303 0.9997829  0.99537081 0.99974962 0.9997829\n",
      " 0.99104965 0.99962928 0.99978285 0.99020582 0.99962534 0.99978283\n",
      " 0.99078898 0.99959881 0.99978284 0.98540103 0.99935877 0.99978212\n",
      " 0.98494374 0.99928847 0.99978232 0.98511233 0.9993713  0.99978238\n",
      " 0.99615597 0.9997474  0.9997829  0.99639123 0.99975988 0.9997829\n",
      " 0.99607088 0.99975028 0.9997829  0.99372537 0.99964937 0.99978285\n",
      " 0.99237177 0.99964519 0.99978285 0.99262526 0.99965909 0.99978285\n",
      " 0.98735872 0.99942024 0.99978233 0.98708263 0.99939418 0.99978245\n",
      " 0.98715078 0.99932578 0.99978248 0.99611203 0.99974451 0.9997829\n",
      " 0.99652984 0.99975656 0.9997829  0.99628838 0.99975641 0.9997829\n",
      " 0.99230035 0.99962858 0.99978285 0.99219493 0.99961086 0.99978286\n",
      " 0.99150688 0.99964999 0.99978284 0.98744078 0.99944219 0.99978243\n",
      " 0.98865237 0.99941179 0.99978254 0.98739893 0.99941977 0.99978244\n",
      " 0.43682959 0.5136357  0.62553357 0.43920817 0.51822348 0.6245182\n",
      " 0.44029062 0.51706883 0.62715725 0.43540853 0.51362844 0.61757978\n",
      " 0.43663504 0.5079673  0.62025441 0.43183163 0.51160866 0.61821451\n",
      " 0.43260209 0.50933522 0.61603188 0.43247889 0.50879558 0.61663474\n",
      " 0.43165482 0.50890509 0.61369591 0.44223821 0.52384178 0.63703217\n",
      " 0.44292435 0.52235867 0.63694584 0.44081048 0.52487705 0.63759399\n",
      " 0.44131661 0.52012899 0.63206377 0.44005295 0.51946394 0.6299831\n",
      " 0.44092345 0.51837583 0.63051045 0.43811283 0.51607572 0.62762384\n",
      " 0.43723527 0.52098315 0.62479603 0.43649648 0.51824175 0.62690304\n",
      " 0.44784486 0.52807751 0.64900492 0.44719588 0.52795516 0.64246258\n",
      " 0.44757721 0.52613161 0.64975599 0.44555478 0.52332981 0.63969805\n",
      " 0.44566482 0.52761295 0.6390784  0.44437371 0.52229302 0.63326306\n",
      " 0.44221483 0.5226617  0.63374036 0.44012084 0.52120878 0.63293079\n",
      " 0.4422455  0.52335738 0.63494361 0.44822609 0.53157196 0.65090789\n",
      " 0.45085352 0.53121967 0.65053154 0.44939441 0.53188962 0.65093344\n",
      " 0.44906622 0.5283654  0.63916335 0.44746232 0.52907358 0.6438742\n",
      " 0.44850524 0.53025858 0.64176298 0.44340216 0.52379204 0.63826635\n",
      " 0.44626461 0.5254695  0.63777162 0.44373927 0.52679198 0.64016163\n",
      " 0.64319774 0.76818896 0.89234069 0.649009   0.75917029 0.89567114\n",
      " 0.64784095 0.76572622 0.89724652 0.63511062 0.74412107 0.87701456\n",
      " 0.62944096 0.74628004 0.87666666 0.6298198  0.74627837 0.87956166\n",
      " 0.61751684 0.72599214 0.86445441 0.61503324 0.73108014 0.86320669\n",
      " 0.61333821 0.73081763 0.86095362 0.65729273 0.77264774 0.90267469\n",
      " 0.65331283 0.77656762 0.90442902 0.65614827 0.77906615 0.90586482\n",
      " 0.64463525 0.75807694 0.88888338 0.64838523 0.76086604 0.88786657\n",
      " 0.64133217 0.76300232 0.88599578 0.62951886 0.74093501 0.87188562\n",
      " 0.62970335 0.74400436 0.87119059 0.6273998  0.74314278 0.87107661\n",
      " 0.66275573 0.78236953 0.90672308 0.66342646 0.7797085  0.90966989\n",
      " 0.66450532 0.78007414 0.90803706 0.64656096 0.76239749 0.89373482\n",
      " 0.64699103 0.76487472 0.89108029 0.64873546 0.76802536 0.89425403\n",
      " 0.64154216 0.74675622 0.87742289 0.63767367 0.74934804 0.88510255\n",
      " 0.63663135 0.74776956 0.88143246 0.66737251 0.78482746 0.91193219\n",
      " 0.67054399 0.78229244 0.91061372 0.67040115 0.78138679 0.90840411\n",
      " 0.65557117 0.7641979  0.89600448 0.65662688 0.7651104  0.89431651\n",
      " 0.65259445 0.76844801 0.89683788 0.63771172 0.75424883 0.88020019\n",
      " 0.637727   0.75792506 0.88089331 0.63959158 0.753618   0.88171128\n",
      " 0.84128978 0.93370834 0.99017442 0.84227423 0.93362657 0.98955956\n",
      " 0.8401258  0.93552757 0.98996484 0.80664171 0.91011194 0.98040657\n",
      " 0.80414716 0.90609927 0.98111933 0.80474679 0.90696371 0.97942346\n",
      " 0.78328474 0.88118102 0.96942264 0.7720528  0.88422917 0.96856284\n",
      " 0.78098525 0.88226324 0.97013272 0.85135859 0.93979405 0.99062672\n",
      " 0.8504134  0.93997135 0.99149857 0.85296255 0.94006277 0.99023327\n",
      " 0.81512305 0.91656521 0.98065085 0.82400808 0.91496438 0.98293241\n",
      " 0.81462685 0.91082619 0.98236659 0.79024643 0.89237001 0.97288727\n",
      " 0.79154708 0.89342116 0.97210164 0.79374507 0.8904585  0.97162161\n",
      " 0.85583142 0.93884484 0.99049795 0.85749648 0.94116535 0.99132358\n",
      " 0.86128968 0.94362983 0.9917296  0.82392285 0.9188499  0.98225432\n",
      " 0.83042873 0.91511917 0.98225223 0.82469195 0.92089186 0.98258322\n",
      " 0.79533415 0.89894615 0.97421619 0.79923701 0.89300766 0.97359081\n",
      " 0.7935201  0.89110833 0.97262418 0.86131501 0.94450431 0.99045321\n",
      " 0.85991512 0.94442385 0.99052906 0.86359015 0.94437392 0.99020085\n",
      " 0.82570303 0.9234215  0.98388475 0.83396485 0.91934099 0.98346847\n",
      " 0.8283308  0.91937894 0.98406591 0.80047566 0.89807971 0.97459641\n",
      " 0.80015766 0.89796131 0.97313676 0.80626242 0.8975238  0.97140455\n",
      " 0.36768514 0.43952503 0.51633853 0.36638413 0.43898848 0.51656327\n",
      " 0.3661885  0.43907655 0.51482842 0.3646454  0.43719925 0.51079294\n",
      " 0.3668104  0.4359594  0.51018509 0.365976   0.43724126 0.51214759\n",
      " 0.36574109 0.43226868 0.50853186 0.36639618 0.43425903 0.50775625\n",
      " 0.36398291 0.43296402 0.50969381 0.37281512 0.44402068 0.524907\n",
      " 0.37293145 0.44416156 0.5250409  0.37373622 0.44248364 0.52368178\n",
      " 0.37076692 0.44239374 0.51863619 0.37134021 0.44243627 0.51913149\n",
      " 0.37133915 0.44270135 0.52095949 0.36993979 0.43848342 0.51974993\n",
      " 0.37018337 0.43789456 0.51756007 0.37154611 0.43794056 0.51691056\n",
      " 0.37479865 0.44619696 0.52619022 0.37479211 0.44656099 0.52775733\n",
      " 0.37532679 0.44670959 0.52566209 0.37523527 0.44334825 0.52395336\n",
      " 0.37541745 0.44532239 0.52408284 0.37468213 0.44434622 0.52381602\n",
      " 0.37272935 0.44131547 0.52390385 0.37333889 0.44203527 0.52221851\n",
      " 0.37241516 0.44083802 0.5222766  0.37664359 0.4484597  0.53000371\n",
      " 0.3761538  0.45037874 0.53278521 0.37702238 0.4492728  0.52998936\n",
      " 0.37566575 0.44807377 0.5264418  0.37610478 0.44780653 0.52698651\n",
      " 0.37630337 0.44786431 0.52622743 0.37495788 0.44456191 0.52425456\n",
      " 0.37468053 0.4440553  0.52376112 0.37488912 0.44478274 0.5264603\n",
      " 0.53566489 0.65055857 0.76215032 0.53764488 0.64752584 0.76294156\n",
      " 0.53734567 0.65247892 0.76184819 0.5266742  0.63352476 0.74418126\n",
      " 0.52677426 0.63266995 0.74494177 0.52772735 0.63242824 0.74341406\n",
      " 0.51556549 0.62105894 0.73008329 0.51697457 0.62189008 0.73042005\n",
      " 0.51659361 0.62184972 0.72878982 0.54671361 0.6601144  0.77436815\n",
      " 0.54814935 0.65716184 0.77264095 0.54583615 0.65968156 0.7699634\n",
      " 0.5353181  0.64777189 0.75771923 0.53741579 0.64387521 0.75538489\n",
      " 0.53590882 0.64466162 0.75367741 0.52710086 0.62782268 0.74100867\n",
      " 0.52722669 0.62894366 0.74194112 0.52672531 0.62960146 0.74176605\n",
      " 0.55507499 0.66466283 0.77971857 0.55280244 0.66473038 0.7761752\n",
      " 0.55387446 0.66445556 0.77917344 0.54346485 0.65370914 0.76298467\n",
      " 0.54403118 0.64948031 0.76237704 0.54179433 0.64820463 0.76466469\n",
      " 0.53171931 0.63610135 0.74544592 0.53135149 0.63806115 0.74894166\n",
      " 0.5337991  0.63301834 0.74685495 0.55812657 0.67048915 0.78054429\n",
      " 0.55783273 0.66487248 0.78026493 0.55810698 0.66708043 0.78177251\n",
      " 0.54568707 0.65399549 0.76800809 0.54522742 0.65260725 0.76319428\n",
      " 0.5457115  0.65328886 0.76703122 0.53485984 0.64092955 0.75265433\n",
      " 0.53427148 0.63862074 0.75228041 0.53588518 0.63908106 0.75313142\n",
      " 0.73011934 0.84634463 0.93537649 0.72902129 0.84728073 0.93452531\n",
      " 0.72804958 0.84809065 0.93331477 0.69457414 0.81067026 0.90607483\n",
      " 0.69814851 0.81000924 0.91016224 0.69711124 0.80744463 0.90697942\n",
      " 0.6675442  0.78400101 0.88129721 0.66948275 0.78059922 0.88341059\n",
      " 0.66990733 0.77974222 0.88217016 0.74336981 0.85228698 0.93885928\n",
      " 0.7440995  0.85392664 0.93855652 0.74168485 0.84987138 0.9367766\n",
      " 0.70841742 0.82183978 0.91428038 0.71128404 0.82028481 0.91529306\n",
      " 0.70923419 0.82487995 0.91522624 0.68316704 0.79475814 0.88809713\n",
      " 0.68185415 0.79052785 0.88686254 0.67927544 0.79231348 0.89149339\n",
      " 0.74774912 0.85435806 0.94020091 0.75063006 0.86082025 0.93968135\n",
      " 0.74718131 0.86058643 0.93962606 0.7129145  0.82655422 0.91566621\n",
      " 0.71684553 0.82541389 0.91645264 0.71522926 0.82554868 0.91621766\n",
      " 0.68602422 0.79822483 0.89511608 0.68824464 0.79669529 0.89560907\n",
      " 0.68752693 0.79420909 0.89317256 0.75013918 0.86195089 0.93980164\n",
      " 0.75169011 0.86185621 0.94244348 0.74930201 0.86356661 0.94340717\n",
      " 0.72056989 0.82725353 0.9158662  0.71757478 0.8271955  0.91659254\n",
      " 0.71600511 0.82937335 0.92040562 0.69430044 0.80518017 0.89536203\n",
      " 0.69033399 0.80414824 0.89713109 0.69251321 0.80415361 0.89571548]\n",
      "[ 1.77738922e-01  1.41821611e-01  2.19705293e-02  1.93512305e-01\n",
      "  9.37041825e-02  3.26215154e-02  1.74448412e-01  1.29094001e-01\n",
      "  4.26280089e-02  1.63547502e-01  8.00610224e-02  5.37326566e-02\n",
      "  1.81135375e-01  1.01399587e-01  5.81596377e-02  1.85814168e-01\n",
      "  1.09788410e-01  3.88582100e-02  1.89859202e-01  1.31600775e-01\n",
      "  1.12771838e-01  1.89320416e-01  1.28006274e-01  3.27665949e-02\n",
      "  1.58137432e-01  1.13433597e-01  7.05833153e-02  1.72388722e-01\n",
      "  7.43069028e-02  2.87015098e-02  1.84036656e-01  1.01737807e-01\n",
      "  1.93505113e-02  1.99474394e-01  1.19141340e-01  4.33871694e-02\n",
      "  1.68863820e-01  9.77763764e-02  7.29209374e-02  1.59977960e-01\n",
      "  1.23744039e-01  5.21386117e-02  1.84911659e-01  9.58371479e-02\n",
      "  3.66036490e-02  1.92671244e-01  1.19997104e-01  4.91098091e-02\n",
      "  1.96722512e-01  1.34869918e-01  6.60440692e-02  1.77078940e-01\n",
      "  1.00969492e-01  4.50276631e-02  1.79144704e-01  1.08172616e-01\n",
      "  6.20263360e-02  1.48351780e-01  9.15504188e-02  4.78222048e-02\n",
      "  1.64440808e-01  8.41246926e-02  3.94354396e-02  1.58711135e-01\n",
      "  1.06447669e-01  4.23521423e-02  1.77779475e-01  9.70612447e-02\n",
      "  4.26731255e-02  1.61793231e-01  1.14678502e-01  1.54347669e-02\n",
      "  1.84545418e-01  1.20403746e-01  3.43904054e-02  1.72715243e-01\n",
      "  1.00546464e-01  7.35404750e-02  1.75719136e-01  1.09980789e-01\n",
      "  5.97767925e-02  1.65912196e-01  8.05383525e-02  5.08488615e-02\n",
      "  1.65767408e-01  1.14481164e-01  3.13206038e-02  1.67410457e-01\n",
      "  9.37103467e-02  3.21615203e-02  1.65317461e-01  1.05870142e-01\n",
      "  5.48085743e-02  1.78526238e-01  1.13037303e-01  2.03130436e-02\n",
      "  1.54614995e-01  9.79687061e-02  2.65472064e-02  1.83805128e-01\n",
      "  1.23214323e-01  4.89352190e-02  1.72771903e-01  1.09360839e-01\n",
      "  5.24981732e-02  1.74263228e-01  1.29036973e-01  1.29859411e-02\n",
      "  6.63488188e-02  5.49041195e-02  3.00536114e-02  6.05143667e-02\n",
      "  2.91337726e-03  2.24605597e-02  4.71823491e-02  4.10128386e-02\n",
      " -6.28824510e-03  5.94817904e-02  3.66049073e-02  1.03467088e-02\n",
      "  9.80318358e-02  2.67755261e-02  1.00762626e-02  6.00052122e-02\n",
      "  2.53063114e-02  1.59128533e-02  1.06297912e-01  2.82186939e-02\n",
      "  3.79991508e-02  8.97413043e-02  5.09012747e-02  1.08880252e-02\n",
      "  8.72204866e-02  5.32995193e-02  2.40579656e-02  4.99784785e-02\n",
      " -1.58957908e-02  2.88768891e-02  8.60887031e-02  2.85869889e-02\n",
      "  1.59644781e-02  5.32055931e-02  3.11700915e-02  5.01192487e-02\n",
      "  6.89711201e-02  2.87446122e-02  1.03689164e-02  6.16325066e-02\n",
      "  2.79575083e-02  4.48790076e-02  6.08065505e-02  3.78321586e-02\n",
      "  5.10594424e-02  7.33547435e-02  4.62660000e-02  1.43528621e-02\n",
      "  9.11848172e-02  7.06095788e-02  1.84294345e-02  7.76937764e-02\n",
      "  5.37263924e-03  3.05087415e-02  5.95586729e-02  9.85532772e-03\n",
      "  2.81345642e-02  8.83000042e-02  2.64436492e-02  4.34976469e-02\n",
      "  8.14280804e-02  4.41813398e-02  4.97437042e-02  9.53645193e-02\n",
      "  4.97935316e-02  2.86115615e-02  5.96283531e-02  2.42731597e-02\n",
      " -2.37466410e-04  7.86943832e-02  2.33721077e-02  3.23896954e-02\n",
      "  8.35177449e-02  1.58800223e-02  2.24591401e-02  8.50363988e-02\n",
      "  3.66314614e-02  9.61374625e-03  7.19940019e-02  5.75755523e-03\n",
      "  2.11446706e-02  5.52237988e-02  5.86761569e-02  4.91356856e-02\n",
      "  6.21539343e-02  3.49108094e-02  3.52609554e-02  6.48319511e-02\n",
      "  3.31278665e-02  1.86462377e-02  8.26080533e-02  5.64459421e-02\n",
      "  1.45507960e-02  5.18733465e-02  5.55744226e-02  2.43840578e-02\n",
      "  8.63436012e-02  3.25910575e-02  5.55573228e-02  1.02261385e-01\n",
      "  4.37774234e-02  1.64016400e-02  9.88328638e-02  5.01028829e-02\n",
      " -2.90265224e-03  7.90869667e-02  6.55809371e-02  2.44732400e-02\n",
      "  2.76719236e-03  3.11564676e-02  3.80609999e-02  2.83116462e-02\n",
      " -4.24661158e-03  1.35990119e-02  4.38176702e-02  3.21256300e-02\n",
      "  5.15224525e-02  5.49898993e-02  4.50072468e-02  2.86553885e-02\n",
      "  6.97275844e-02  3.46608623e-02  5.02095650e-03  5.57927363e-02\n",
      "  2.13037913e-02  2.88082218e-02  6.29330025e-02  4.41482623e-02\n",
      "  1.89929897e-02  3.49148408e-02  1.03720995e-02  1.69260177e-02\n",
      "  2.80545523e-02  5.70976439e-02  5.15393384e-03 -8.37830632e-04\n",
      "  5.13001749e-02  3.46890950e-02  4.18351337e-02  2.90463093e-02\n",
      "  6.03861411e-02  4.09402500e-02  2.77334642e-02  4.06564604e-02\n",
      "  3.59053770e-02  3.98810297e-02  3.81936865e-02  3.81072646e-02\n",
      "  4.52131933e-02  1.78306730e-02  4.96256356e-02  1.90957520e-02\n",
      "  6.01260053e-02  4.95208031e-02  3.37957180e-02  2.18667421e-02\n",
      "  3.58751867e-02  4.11663664e-02  1.70209230e-02  4.45920797e-02\n",
      "  2.55992535e-02  2.38487587e-02  5.72204418e-02  5.62790475e-02\n",
      "  3.66390671e-03  3.54112068e-02  2.86699091e-02  1.58325309e-02\n",
      "  3.72512265e-02  1.64708454e-02  7.40703343e-02  7.12989762e-02\n",
      "  1.90419277e-02  4.84466302e-02  4.59678120e-02 -1.26019022e-02\n",
      "  3.04902415e-02  3.88521512e-02  6.61260085e-02  2.64647104e-02\n",
      "  2.61779871e-02  5.67505571e-02  3.72845493e-02  3.21892383e-02\n",
      "  4.43142550e-02  3.08236467e-02  4.68324508e-02 -2.10256552e-02\n",
      "  4.58976793e-02  4.03872103e-02  6.29789144e-03  5.29252899e-02\n",
      "  3.53980951e-02  2.92110175e-02  2.04689277e-02  1.76144230e-02\n",
      "  1.92918112e-02  5.18949416e-02  4.14942768e-02  1.38022461e-02\n",
      "  1.53706213e-02  4.37736665e-02  1.80256864e-03  5.24129664e-02\n",
      "  4.49488634e-02  2.86825981e-02  8.13819696e-02  1.59268641e-02\n",
      "  2.32820554e-02  2.81561537e-02  1.83691656e-02  2.27792263e-02\n",
      "  5.63910851e-02  2.81555817e-02  4.37869378e-02 -2.51913447e-03\n",
      "  2.90697308e-01  2.82419445e-01  2.57213285e-01  2.90143940e-01\n",
      "  2.73724954e-01  2.54913142e-01  2.90629432e-01  2.74952903e-01\n",
      "  2.60596685e-01  2.92846049e-01  2.74945768e-01  2.55629956e-01\n",
      "  2.87942298e-01  2.74446126e-01  2.57623934e-01  2.86822140e-01\n",
      "  2.74386494e-01  2.55004954e-01  2.87527078e-01  2.80972414e-01\n",
      "  2.61172995e-01  2.89548492e-01  2.73839817e-01  2.58217891e-01\n",
      "  2.85378778e-01  2.77483992e-01  2.66767894e-01  2.87287409e-01\n",
      "  2.73501415e-01  2.56792674e-01  2.86205413e-01  2.74253827e-01\n",
      "  2.50396579e-01  2.83809123e-01  2.74066708e-01  2.61047171e-01\n",
      "  2.86813277e-01  2.69297006e-01  2.48847475e-01  2.92450334e-01\n",
      "  2.73683810e-01  2.53839465e-01  2.85987319e-01  2.77307839e-01\n",
      "  2.52077549e-01  2.85702390e-01  2.79473243e-01  2.57048550e-01\n",
      "  2.82789382e-01  2.79075437e-01  2.57082650e-01  2.88428695e-01\n",
      "  2.77318176e-01  2.57391379e-01  2.89192249e-01  2.78422642e-01\n",
      "  2.57356879e-01  2.86689796e-01  2.74193405e-01  2.49543354e-01\n",
      "  2.82930791e-01  2.79542005e-01  2.52813484e-01  2.88295068e-01\n",
      "  2.74975778e-01  2.44798497e-01  2.84768281e-01  2.70293006e-01\n",
      "  2.42881331e-01  2.81846390e-01  2.72222139e-01  2.50345490e-01\n",
      "  2.84763479e-01  2.75178555e-01  2.55527542e-01  2.84436169e-01\n",
      "  2.78333520e-01  2.54541970e-01  2.85453055e-01  2.79009353e-01\n",
      "  2.57103915e-01  2.86270270e-01  2.78115935e-01  2.54362439e-01\n",
      "  2.85943995e-01  2.73499821e-01  2.48950245e-01  2.85718830e-01\n",
      "  2.71893787e-01  2.57273617e-01  2.82848665e-01  2.73987888e-01\n",
      "  2.51720422e-01  2.86091089e-01  2.65739682e-01  2.47718479e-01\n",
      "  2.87243366e-01  2.69793248e-01  2.45022372e-01  2.87782871e-01\n",
      "  2.80606075e-01  2.52702122e-01  2.86103017e-01  2.78974331e-01\n",
      "  2.52086669e-01  2.89448415e-01  2.75660269e-01  2.56702677e-01\n",
      "  2.58226171e-01  2.45275623e-01  2.17701731e-01  2.71233535e-01\n",
      "  2.40727354e-01  2.23346593e-01  2.71863526e-01  2.47108082e-01\n",
      "  2.33076532e-01  2.65403990e-01  2.35012044e-01  2.18735729e-01\n",
      "  2.53735408e-01  2.57654942e-01  2.16981361e-01  2.72131905e-01\n",
      "  2.44142729e-01  2.23580523e-01  2.67802364e-01  2.44498054e-01\n",
      "  2.24067416e-01  2.74560904e-01  2.42034860e-01  2.19212658e-01\n",
      "  2.72968324e-01  2.50937647e-01  2.12140262e-01  2.66699576e-01\n",
      "  2.53565074e-01  2.24447276e-01  2.66764358e-01  2.53053543e-01\n",
      "  2.10328602e-01  2.67244131e-01  2.53639733e-01  2.21017234e-01\n",
      "  2.68924934e-01  2.41682107e-01  2.24309692e-01  2.62746567e-01\n",
      "  2.39329016e-01  2.15603983e-01  2.61393022e-01  2.46528450e-01\n",
      "  2.09330238e-01  2.73136131e-01  2.62261932e-01  2.17593609e-01\n",
      "  2.68376115e-01  2.51192683e-01  2.23606275e-01  2.64106198e-01\n",
      "  2.55518839e-01  2.23973066e-01  2.64683726e-01  2.48768118e-01\n",
      "  2.17999484e-01  2.60497880e-01  2.51977416e-01  2.27990289e-01\n",
      "  2.68461245e-01  2.56381715e-01  2.30030548e-01  2.61909117e-01\n",
      "  2.46743027e-01  2.09085483e-01  2.65414626e-01  2.49317087e-01\n",
      "  2.09538480e-01  2.62057801e-01  2.42168755e-01  2.26878341e-01\n",
      "  2.72229221e-01  2.48176343e-01  2.17236388e-01  2.70411423e-01\n",
      "  2.51735218e-01  2.15110864e-01  2.64239382e-01  2.47885462e-01\n",
      "  2.12989877e-01  2.69893409e-01  2.45674804e-01  2.22478785e-01\n",
      "  2.65396881e-01  2.49776907e-01  2.27819435e-01  2.64615369e-01\n",
      "  2.43451633e-01  2.22291358e-01  2.54747177e-01  2.44241303e-01\n",
      "  2.12955900e-01  2.62338076e-01  2.31733312e-01  2.02665440e-01\n",
      "  2.67886346e-01  2.42131624e-01  2.14853442e-01  2.68014134e-01\n",
      "  2.50237754e-01  2.30510474e-01  2.67444812e-01  2.50767108e-01\n",
      "  2.22241498e-01  2.74940255e-01  2.44228760e-01  2.18659484e-01\n",
      "  2.47488174e-01  2.22475781e-01  2.16017003e-01  2.40574570e-01\n",
      "  2.23851351e-01  2.10816661e-01  2.44805634e-01  2.12721308e-01\n",
      "  2.11153157e-01  2.53409993e-01  2.35442242e-01  1.96318703e-01\n",
      "  2.40998845e-01  2.22302648e-01  2.17326463e-01  2.33964061e-01\n",
      "  2.34136673e-01  1.97346961e-01  2.47355578e-01  2.23751210e-01\n",
      "  1.98672191e-01  2.49185745e-01  2.20542367e-01  2.02910551e-01\n",
      "  2.56092942e-01  2.35609280e-01  2.10252423e-01  2.37778168e-01\n",
      "  2.33162785e-01  2.12480670e-01  2.49394597e-01  2.24185494e-01\n",
      "  2.19169500e-01  2.36783462e-01  2.31687604e-01  2.06584509e-01\n",
      "  2.41093498e-01  2.17005313e-01  2.07544168e-01  2.44972267e-01\n",
      "  2.08737726e-01  2.00088436e-01  2.50465035e-01  2.27001417e-01\n",
      "  2.08069011e-01  2.58384090e-01  2.29411250e-01  2.09015343e-01\n",
      "  2.45924604e-01  2.24428929e-01  2.00977236e-01  2.41183583e-01\n",
      "  2.32568265e-01  2.06245860e-01  2.42875736e-01  2.21789779e-01\n",
      "  2.11137586e-01  2.40249690e-01  2.25700844e-01  2.12878193e-01\n",
      "  2.46398647e-01  2.25897591e-01  2.05611976e-01  2.39418435e-01\n",
      "  2.19283200e-01  2.09430373e-01  2.50332493e-01  2.21957135e-01\n",
      "  2.09624160e-01  2.52208948e-01  2.33116256e-01  2.05715472e-01\n",
      "  2.43168796e-01  2.30954402e-01  1.96964580e-01  2.53068693e-01\n",
      "  2.25277493e-01  2.01680567e-01  2.44353008e-01  2.30346686e-01\n",
      "  2.02686357e-01  2.47710802e-01  2.25547671e-01  2.11686944e-01\n",
      "  2.42574850e-01  2.35979510e-01  2.10550734e-01  2.40539333e-01\n",
      "  2.21650997e-01  2.11010786e-01  2.43052304e-01  2.25566359e-01\n",
      "  2.08588117e-01  2.40743924e-01  2.33158493e-01  2.07707043e-01\n",
      "  2.38805146e-01  2.29213298e-01  1.94779104e-01  2.47957845e-01\n",
      "  2.23899030e-01  2.02458634e-01  2.46648449e-01  2.29025081e-01\n",
      "  2.00697996e-01  2.54633266e-01  2.29932897e-01  2.09799361e-01\n",
      "  2.81633184e-01  2.89141265e-01  2.82547694e-01  2.83575362e-01\n",
      "  2.91121545e-01  2.83744156e-01  2.84628267e-01  2.92381285e-01\n",
      "  2.82021441e-01  2.84302671e-01  2.91036053e-01  2.80104155e-01\n",
      "  2.79858190e-01  2.92053972e-01  2.78896754e-01  2.86122853e-01\n",
      "  2.89231096e-01  2.80126532e-01  2.85681330e-01  2.89962947e-01\n",
      "  2.85367696e-01  2.82476304e-01  2.91630095e-01  2.87095262e-01\n",
      "  2.81949935e-01  2.89179949e-01  2.79726597e-01  2.85542687e-01\n",
      "  2.90221928e-01  2.74748179e-01  2.83487585e-01  2.86958168e-01\n",
      "  2.74332748e-01  2.83703065e-01  2.91427286e-01  2.80021866e-01\n",
      "  2.85550255e-01  2.91227273e-01  2.76181082e-01  2.84724474e-01\n",
      "  2.91364756e-01  2.78534928e-01  2.88607236e-01  2.91169271e-01\n",
      "  2.76474467e-01  2.85450615e-01  2.89892274e-01  2.81166659e-01\n",
      "  2.86664350e-01  2.89645868e-01  2.82492705e-01  2.85928551e-01\n",
      "  2.92624250e-01  2.78819344e-01  2.85887888e-01  2.86009677e-01\n",
      "  2.77263710e-01  2.84353634e-01  2.89646827e-01  2.78240257e-01\n",
      "  2.87939431e-01  2.88798560e-01  2.74982524e-01  2.86363114e-01\n",
      "  2.88683777e-01  2.74115716e-01  2.85904214e-01  2.86080572e-01\n",
      "  2.73286059e-01  2.86619988e-01  2.88088848e-01  2.71646989e-01\n",
      "  2.87844547e-01  2.90375223e-01  2.77313306e-01  2.86471458e-01\n",
      "  2.92528809e-01  2.79564995e-01  2.87076948e-01  2.90686629e-01\n",
      "  2.78737698e-01  2.86270823e-01  2.87126716e-01  2.72406997e-01\n",
      "  2.86584417e-01  2.88356388e-01  2.76145877e-01  2.86101150e-01\n",
      "  2.87971435e-01  2.74866541e-01  2.86804866e-01  2.88419970e-01\n",
      "  2.71679950e-01  2.83887113e-01  2.86376876e-01  2.70567044e-01\n",
      "  2.87049612e-01  2.85249539e-01  2.71960752e-01  2.86766315e-01\n",
      "  2.88872629e-01  2.77777797e-01  2.88648879e-01  2.90076553e-01\n",
      "  2.80060101e-01  2.88624225e-01  2.91282929e-01  2.76514602e-01\n",
      "  2.79515245e-01  2.73991021e-01  2.60869174e-01  2.79918644e-01\n",
      "  2.80876097e-01  2.63004704e-01  2.73925156e-01  2.74786166e-01\n",
      "  2.58906850e-01  2.82596272e-01  2.71515065e-01  2.59839567e-01\n",
      "  2.84691245e-01  2.77411819e-01  2.56539123e-01  2.77298138e-01\n",
      "  2.76462638e-01  2.53553557e-01  2.82297547e-01  2.70918687e-01\n",
      "  2.55984850e-01  2.78777643e-01  2.80687413e-01  2.61654850e-01\n",
      "  2.78001026e-01  2.79401264e-01  2.62044618e-01  2.78996000e-01\n",
      "  2.74965140e-01  2.59692944e-01  2.81216807e-01  2.77671588e-01\n",
      "  2.54374980e-01  2.84360512e-01  2.73969857e-01  2.57006065e-01\n",
      "  2.76810682e-01  2.70842101e-01  2.57401711e-01  2.81661887e-01\n",
      "  2.69609960e-01  2.54538660e-01  2.79614178e-01  2.73204450e-01\n",
      "  2.52908081e-01  2.75215078e-01  2.76411016e-01  2.59159241e-01\n",
      "  2.79361657e-01  2.76250943e-01  2.59820044e-01  2.78354860e-01\n",
      "  2.79660412e-01  2.60244707e-01  2.77786415e-01  2.75432402e-01\n",
      "  2.51741673e-01  2.83003466e-01  2.72546780e-01  2.53562313e-01\n",
      "  2.78873506e-01  2.68430541e-01  2.53949909e-01  2.79269571e-01\n",
      "  2.69312284e-01  2.54816461e-01  2.79605827e-01  2.71059174e-01\n",
      "  2.52601044e-01  2.80029644e-01  2.78233443e-01  2.56870924e-01\n",
      "  2.83508898e-01  2.78760172e-01  2.64059720e-01  2.82044596e-01\n",
      "  2.78557619e-01  2.56488978e-01  2.83195439e-01  2.73870233e-01\n",
      "  2.58711191e-01  2.78900763e-01  2.76171087e-01  2.61968225e-01\n",
      "  2.77844557e-01  2.74187354e-01  2.52392277e-01  2.78080769e-01\n",
      "  2.69549100e-01  2.54264290e-01  2.83275847e-01  2.67322935e-01\n",
      "  2.48135351e-01  2.80262055e-01  2.70174694e-01  2.45117711e-01\n",
      "  2.77405300e-01  2.67893129e-01  2.46552193e-01  2.80185545e-01\n",
      "  2.72593989e-01  2.55229452e-01  2.79578411e-01  2.73364041e-01\n",
      "  2.56943587e-01  2.78070479e-01  2.74357014e-01  2.58903297e-01\n",
      "  2.70469498e-01  2.59581472e-01  2.41083782e-01  2.68749952e-01\n",
      "  2.56786218e-01  2.42847306e-01  2.62178519e-01  2.52947715e-01\n",
      "  2.42471755e-01  2.69454608e-01  2.55823630e-01  2.42628462e-01\n",
      "  2.70780198e-01  2.61500948e-01  2.41605457e-01  2.56941167e-01\n",
      "  2.65800658e-01  2.38893245e-01  2.75330948e-01  2.60639549e-01\n",
      "  2.33152263e-01  2.67566278e-01  2.63645690e-01  2.45741914e-01\n",
      "  2.65974406e-01  2.67740206e-01  2.47506902e-01  2.64496569e-01\n",
      "  2.57190987e-01  2.42664961e-01  2.68490416e-01  2.58222412e-01\n",
      "  2.44829025e-01  2.67222723e-01  2.58419550e-01  2.43432222e-01\n",
      "  2.63171619e-01  2.54455116e-01  2.42232846e-01  2.73718303e-01\n",
      "  2.53617838e-01  2.38560134e-01  2.66871142e-01  2.62747063e-01\n",
      "  2.37273902e-01  2.70216232e-01  2.61740637e-01  2.42874180e-01\n",
      "  2.75576445e-01  2.48589803e-01  2.38481286e-01  2.70659167e-01\n",
      "  2.62889482e-01  2.49189940e-01  2.67654880e-01  2.59584594e-01\n",
      "  2.36213423e-01  2.66495407e-01  2.58411331e-01  2.40227688e-01\n",
      "  2.66971067e-01  2.56916097e-01  2.32861766e-01  2.67311384e-01\n",
      "  2.52713189e-01  2.35507645e-01  2.64847138e-01  2.48288739e-01\n",
      "  2.32604190e-01  2.65327184e-01  2.54133088e-01  2.43449952e-01\n",
      "  2.71268228e-01  2.53741506e-01  2.40687197e-01  2.76292764e-01\n",
      "  2.57717182e-01  2.43295346e-01  2.67573245e-01  2.60320068e-01\n",
      "  2.40206173e-01  2.58224793e-01  2.45908543e-01  2.42094983e-01\n",
      "  2.61499913e-01  2.45460280e-01  2.33604401e-01  2.54155394e-01\n",
      "  2.49561296e-01  2.35046286e-01  2.61569083e-01  2.51645780e-01\n",
      "  2.31998544e-01  2.61639213e-01  2.55028513e-01  2.29306743e-01\n",
      "  2.60172020e-01  2.57850728e-01  2.37544978e-01  2.70288574e-01\n",
      "  2.46763217e-01  2.42789573e-01  2.63936572e-01  2.50686309e-01\n",
      "  2.42960835e-01  2.66696841e-01  2.55962515e-01  2.34262750e-01]\n"
     ]
    }
   ],
   "source": [
    "# Check for overfitting\n",
    "\n",
    "print(grid_cv_grad.cv_results_.keys())\n",
    "print(grid_cv_grad.cv_results_[\"mean_train_score\"].shape)  # n_estimators: 11 values, max_depth: 4 values. Thus shape, 11*4=44\n",
    "print(grid_cv_grad.cv_results_[\"mean_test_score\"].shape)\n",
    "\n",
    "print(grid_cv_grad.cv_results_[\"mean_train_score\"])\n",
    "print(grid_cv_grad.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean_train_score: [0.43540853]\n",
      "Best mean_test_score: [0.29284605]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify the mean_train_score and mean_test_score values associated with best_score\n",
    "best_score_index = np.where(grid_cv_grad.cv_results_[\"mean_test_score\"]==grid_cv_grad.best_score_)\n",
    "print('Best mean_train_score:', grid_cv_grad.cv_results_[\"mean_train_score\"][best_score_index])\n",
    "print('Best mean_test_score:', grid_cv_grad.cv_results_[\"mean_test_score\"][best_score_index])\n",
    "\n",
    "#Create a df with grid_cv_grad.cv_results_[\"mean_train_score\"] as the first column and grid_cv_grad.cv_results_[\"mean_test_score\"] as the second column\n",
    "grad_results_df = pd.DataFrame({'mean_train_score': grid_cv_grad.cv_results_[\"mean_train_score\"], 'mean_test_score': grid_cv_grad.cv_results_[\"mean_test_score\"]})\n",
    "\n",
    "# Compute a new collumn that is the ratio of mean_train_score to mean_test_score\n",
    "grad_results_df['ratio'] = grad_results_df['mean_train_score']/grad_results_df['mean_test_score']\n",
    "\n",
    "# Identify outliers in ratio\n",
    "Q1 = grad_results_df['ratio'].quantile(0.25)\n",
    "Q3 = grad_results_df['ratio'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = grad_results_df[(grad_results_df['ratio'] < (Q1 - 1.5 * IQR)) | (grad_results_df['ratio'] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# Remove the outliers from grad_results_df\n",
    "grad_results_df = grad_results_df[~grad_results_df['ratio'].isin(outliers['ratio'])]\n",
    "\n",
    "# Create a histogram of ratio\n",
    "plt.hist(grad_results_df['ratio'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The ratio of train kappas to test kappas using our \"best\" set of parameters was 1.4868. This seems like it might correspond to overfitting. But it seems in line with the (non-outlier) ratios among all tested sets of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning the Gradiant Boosting Regressor for sii**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                                       (&#x27;over&#x27;,\n",
       "                                        SMOTE(sampling_strategy={0: 1228,\n",
       "                                                                 1: 619, 2: 315,\n",
       "                                                                 3: 128})),\n",
       "                                       (&#x27;grad&#x27;, GradientBoostingRegressor())]),\n",
       "             param_grid={&#x27;grad__learning_rate&#x27;: [0.5, 0.1, 0.05],\n",
       "                         &#x27;grad__max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;grad__max_features&#x27;: [10, 15, 20, 25],\n",
       "                         &#x27;grad__min_samples_leaf&#x27;: [5, 8, 11],\n",
       "                         &#x27;grad__min_samples_split&#x27;: [3, 5, 7],\n",
       "                         &#x27;grad__n_estimators&#x27;: [50, 100, 200]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(sii_kappa, response_method=&#x27;predict&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                                       (&#x27;over&#x27;,\n",
       "                                        SMOTE(sampling_strategy={0: 1228,\n",
       "                                                                 1: 619, 2: 315,\n",
       "                                                                 3: 128})),\n",
       "                                       (&#x27;grad&#x27;, GradientBoostingRegressor())]),\n",
       "             param_grid={&#x27;grad__learning_rate&#x27;: [0.5, 0.1, 0.05],\n",
       "                         &#x27;grad__max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;grad__max_features&#x27;: [10, 15, 20, 25],\n",
       "                         &#x27;grad__min_samples_leaf&#x27;: [5, 8, 11],\n",
       "                         &#x27;grad__min_samples_split&#x27;: [3, 5, 7],\n",
       "                         &#x27;grad__n_estimators&#x27;: [50, 100, 200]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(sii_kappa, response_method=&#x27;predict&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                (&#x27;add_zones&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)),\n",
       "                (&#x27;over&#x27;,\n",
       "                 SMOTE(sampling_strategy={0: 1228, 1: 619, 2: 315, 3: 128})),\n",
       "                (&#x27;grad&#x27;,\n",
       "                 GradientBoostingRegressor(max_features=10, min_samples_leaf=5,\n",
       "                                           min_samples_split=3,\n",
       "                                           n_estimators=200))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Custom_MICE_Imputer</label><div class=\"sk-toggleable__content fitted\"><pre>Custom_MICE_Imputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function zone_encoder at 0x305cc5800&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">SMOTE</label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(sampling_strategy={0: 1228, 1: 619, 2: 315, 3: 128})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(max_features=10, min_samples_leaf=5,\n",
       "                          min_samples_split=3, n_estimators=200)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('mice_impute', Custom_MICE_Imputer()),\n",
       "                                       ('add_zones',\n",
       "                                        FunctionTransformer(func=<function zone_encoder at 0x305cc5800>)),\n",
       "                                       ('over',\n",
       "                                        SMOTE(sampling_strategy={0: 1228,\n",
       "                                                                 1: 619, 2: 315,\n",
       "                                                                 3: 128})),\n",
       "                                       ('grad', GradientBoostingRegressor())]),\n",
       "             param_grid={'grad__learning_rate': [0.5, 0.1, 0.05],\n",
       "                         'grad__max_depth': [3, 5, 7],\n",
       "                         'grad__max_features': [10, 15, 20, 25],\n",
       "                         'grad__min_samples_leaf': [5, 8, 11],\n",
       "                         'grad__min_samples_split': [3, 5, 7],\n",
       "                         'grad__n_estimators': [50, 100, 200]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(sii_kappa, response_method='predict'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'grad__learning_rate': [0.5, 0.1, 0.05],\n",
    "    'grad__max_depth': [3,5,7],\n",
    "    'grad__max_features': [10, 15, 20, 25],\n",
    "    'grad__min_samples_leaf': [5, 8, 11],\n",
    "    'grad__min_samples_split': [3, 5, 7],\n",
    "    'grad__n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Create a custom scorer that first rounds the values of sii and then applies a cohen_kappa_score\n",
    "def sii_kappa(y_true, y_pred):\n",
    "    y_pred_round = np.round(y_pred)\n",
    "    return cohen_kappa_score(y_true, y_pred_round, weights='quadratic')\n",
    "\n",
    "kappa_scorer = make_scorer(sii_kappa)\n",
    "\n",
    "\n",
    "# Set up SMOTE to create 128 (rather than 32) instances of sii=3\n",
    "siiratios = {0: 1228, 1: 619, 2:315, 3:128}\n",
    "oversample = SMOTE(sampling_strategy=siiratios)\n",
    "\n",
    "# Instantiate a gradient boosting regressor pipeline\n",
    "grad_pipe_sii = Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('over', oversample),\n",
    "                ('grad', GradientBoostingRegressor())])\n",
    "\n",
    "grid_cv_grad_sii = GridSearchCV(grad_pipe_sii, \n",
    "                          param_grid = param_grid, \n",
    "                          scoring = kappa_scorer,\n",
    "                          cv = 5,\n",
    "                          return_train_score=True)\n",
    "\n",
    "grid_cv_grad_sii.fit(train_cleaned[predictors], train_cleaned['sii'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'grad__learning_rate': 0.1, 'grad__max_depth': 3, 'grad__max_features': 10, 'grad__min_samples_leaf': 5, 'grad__min_samples_split': 3, 'grad__n_estimators': 200}\n",
      "Best score: 0.42962528256851173\n"
     ]
    }
   ],
   "source": [
    "# Report the results\n",
    "print('Best parameters:',grid_cv_grad_sii.best_params_)\n",
    "print('Best score:',grid_cv_grad_sii.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning Results**\n",
    "\n",
    "First run:\n",
    "* 'grad__learning_rate': 0.1\n",
    "* 'grad__max_depth': 3\n",
    "* 'grad__max_features': 8\n",
    "* 'grad__min_samples_leaf': 8\n",
    "* 'grad__min_samples_split': 2\n",
    "* 'grad__n_estimators': 100\n",
    "\n",
    "Second run:\n",
    "* learning_rate: 0.1\n",
    "* max_depth: 3\n",
    "* max_features: 10\n",
    "* min_samples_leaf: 5\n",
    "* min_samples_split: 3\n",
    "* n_estimators: 200\n",
    "\n",
    "These results suggest similar things as the tuning for PCIAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_grad__learning_rate', 'param_grad__max_depth', 'param_grad__max_features', 'param_grad__min_samples_leaf', 'param_grad__min_samples_split', 'param_grad__n_estimators', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'mean_train_score', 'std_train_score'])\n",
      "(972,)\n",
      "(972,)\n",
      "[0.71809917 0.84212878 0.95437639 0.71812869 0.84101903 0.95124568\n",
      " 0.71574246 0.83170415 0.95493556 0.7009812  0.82779324 0.9490779\n",
      " 0.71038672 0.82819787 0.94720051 0.7157688  0.82343466 0.94244469\n",
      " 0.70236363 0.8183629  0.9398316  0.70189525 0.81698501 0.94304344\n",
      " 0.69717619 0.81730718 0.93921291 0.7245618  0.85179193 0.96262698\n",
      " 0.72395122 0.84529545 0.96461742 0.73253037 0.84657392 0.96302085\n",
      " 0.71913894 0.83762958 0.9586222  0.71916237 0.83966043 0.95822167\n",
      " 0.72351044 0.83794942 0.95636482 0.71882819 0.83791979 0.9528165\n",
      " 0.71169226 0.83367722 0.9550116  0.698714   0.83747248 0.95626158\n",
      " 0.72986124 0.86060405 0.96622008 0.73027471 0.85838294 0.96425438\n",
      " 0.73013176 0.85688461 0.96387711 0.72493473 0.85211122 0.96178622\n",
      " 0.72951925 0.84996766 0.95982679 0.72848511 0.85945288 0.9658576\n",
      " 0.71749776 0.84309348 0.95772761 0.71260498 0.84093996 0.96090014\n",
      " 0.72030229 0.84362886 0.95845016 0.73449477 0.86993257 0.9723656\n",
      " 0.74433985 0.86270428 0.97147215 0.73626246 0.86250085 0.96911746\n",
      " 0.72872145 0.86164658 0.96326208 0.73678306 0.8546199  0.9653923\n",
      " 0.72813108 0.85694802 0.96695433 0.73014829 0.84298743 0.96345441\n",
      " 0.73593    0.85262199 0.96217692 0.72275477 0.84519266 0.96355025\n",
      " 0.95412167 0.99859887 0.99972079 0.95754296 0.99859826 0.99972077\n",
      " 0.95260876 0.99851297 0.99972079 0.94478512 0.99588089 0.99972079\n",
      " 0.93896639 0.9968268  0.99972079 0.94461773 0.99701291 0.99972077\n",
      " 0.93241227 0.99484809 0.99972077 0.92897765 0.99410093 0.99972079\n",
      " 0.93528585 0.9952242  0.99972079 0.9625053  0.99906962 0.9997208\n",
      " 0.96037144 0.99869343 0.99972077 0.95937869 0.9991654  0.99972079\n",
      " 0.95294073 0.99757893 0.99972077 0.95214918 0.9980399  0.9997208\n",
      " 0.95529876 0.99765924 0.99972079 0.94843995 0.9956958  0.99972079\n",
      " 0.93896275 0.99587389 0.99972077 0.93920341 0.99672628 0.99972079\n",
      " 0.96528569 0.99906532 0.99972077 0.96455109 0.9990717  0.99972079\n",
      " 0.96634363 0.99850788 0.9997208  0.95432837 0.99785529 0.99972077\n",
      " 0.9545745  0.9982263  0.99972079 0.95490599 0.99802283 0.99972079\n",
      " 0.94322435 0.99785099 0.99972079 0.94091831 0.9976617  0.99972077\n",
      " 0.9437545  0.99795017 0.99972079 0.97051313 0.99925374 0.99972077\n",
      " 0.96629472 0.99925786 0.9997208  0.96521317 0.99953419 0.99972079\n",
      " 0.96240368 0.99861047 0.99972079 0.95846628 0.9979459  0.99972077\n",
      " 0.95895927 0.99841289 0.9997208  0.95132695 0.99814384 0.99972079\n",
      " 0.95435313 0.99729306 0.99972082 0.94715717 0.9969073  0.99972077\n",
      " 0.99953607 0.99972077 0.99972079 0.99962583 0.99972077 0.99972077\n",
      " 0.99962796 0.99972079 0.99972079 0.99887987 0.9997208  0.99972077\n",
      " 0.99879382 0.99972079 0.99972079 0.99888145 0.99972081 0.99972079\n",
      " 0.99813124 0.99972079 0.99972077 0.99680785 0.99972079 0.9997208\n",
      " 0.99662716 0.9997208  0.99972079 0.99972077 0.99972077 0.99972077\n",
      " 0.99953607 0.99972079 0.9997208  0.99962603 0.99972079 0.99972079\n",
      " 0.99925461 0.99972077 0.9997208  0.99915642 0.99972081 0.9997208\n",
      " 0.99925559 0.99972077 0.99972077 0.99785303 0.99972079 0.99972079\n",
      " 0.99794449 0.99972079 0.99972079 0.99822671 0.99972077 0.99972079\n",
      " 0.9997208  0.99972079 0.99972077 0.99962866 0.99972079 0.99972079\n",
      " 0.99972077 0.99972079 0.99972079 0.99934936 0.99972077 0.99972079\n",
      " 0.99925253 0.99972079 0.99972077 0.99898087 0.99972077 0.99972081\n",
      " 0.99831636 0.99972077 0.99972077 0.99878137 0.99972079 0.99972077\n",
      " 0.9986927  0.9997208  0.99972081 0.99953601 0.9997208  0.99972077\n",
      " 0.99953142 0.99972077 0.99972077 0.99962796 0.99972079 0.9997208\n",
      " 0.99943681 0.99972077 0.99972077 0.99916236 0.99972079 0.99972077\n",
      " 0.99934862 0.99972079 0.9997208  0.99851112 0.99972079 0.99972079\n",
      " 0.99822646 0.99972079 0.99972077 0.99841329 0.99972077 0.99972077\n",
      " 0.53789998 0.60207949 0.69634385 0.53253743 0.60420521 0.69934748\n",
      " 0.53631417 0.60405478 0.69525983 0.53949106 0.60717896 0.68729392\n",
      " 0.53405025 0.59520379 0.68650957 0.53709894 0.60167802 0.691867\n",
      " 0.53240718 0.5929498  0.68005276 0.5290334  0.58971132 0.68477258\n",
      " 0.5268509  0.59257602 0.67874179 0.5329662  0.60754381 0.70493135\n",
      " 0.53918975 0.60480409 0.70360828 0.53869245 0.61537191 0.70662078\n",
      " 0.53893728 0.6109179  0.69089168 0.53994309 0.59941161 0.70511908\n",
      " 0.53397697 0.60415256 0.6963014  0.53349399 0.60517586 0.69199054\n",
      " 0.542179   0.60190433 0.68777092 0.54169029 0.60506028 0.69160401\n",
      " 0.53923185 0.61553226 0.7090923  0.54738058 0.6115438  0.70687171\n",
      " 0.5410527  0.61526862 0.7093972  0.5442486  0.60944068 0.70335993\n",
      " 0.53895529 0.6100031  0.70613996 0.53766302 0.61168341 0.70190548\n",
      " 0.54147401 0.60201063 0.69885764 0.53594606 0.60391959 0.69802349\n",
      " 0.5340203  0.59551267 0.69340716 0.55011841 0.62635288 0.71460619\n",
      " 0.54884573 0.62324463 0.71390953 0.54519811 0.6153307  0.71732787\n",
      " 0.54624656 0.60821748 0.70878172 0.54627622 0.60796113 0.70614059\n",
      " 0.54849854 0.60913659 0.70230711 0.54900334 0.61002425 0.70487963\n",
      " 0.54413338 0.6114466  0.70835126 0.54077708 0.61306148 0.69910582\n",
      " 0.71910194 0.82370417 0.93640119 0.71725965 0.82398876 0.93693721\n",
      " 0.72189973 0.81681052 0.93959645 0.71055759 0.80916652 0.92569782\n",
      " 0.71028654 0.80549758 0.92569333 0.70723603 0.8050783  0.92386054\n",
      " 0.69642191 0.78877909 0.9103064  0.69081617 0.7926975  0.91182379\n",
      " 0.69285613 0.79270015 0.91156785 0.73110888 0.83581642 0.94331301\n",
      " 0.73054769 0.83333561 0.94755287 0.73740696 0.83078157 0.94239325\n",
      " 0.72403797 0.82024632 0.93092067 0.71772816 0.81837802 0.93100967\n",
      " 0.71618334 0.81730387 0.93235458 0.71260988 0.80177055 0.92129543\n",
      " 0.69963046 0.79954544 0.91823529 0.70801852 0.8137023  0.92109027\n",
      " 0.74231833 0.83620236 0.94674335 0.7330562  0.83866077 0.94688927\n",
      " 0.7345402  0.84459153 0.94700109 0.72651203 0.82101353 0.93486031\n",
      " 0.71295617 0.8177175  0.93195826 0.72038657 0.82418101 0.936097\n",
      " 0.7200919  0.81449572 0.9243825  0.7129695  0.80559662 0.92599548\n",
      " 0.70898266 0.81275515 0.92470869 0.74641669 0.84902489 0.9476712\n",
      " 0.73424752 0.84003633 0.94950277 0.74303742 0.8368114  0.94115809\n",
      " 0.72135704 0.83038286 0.93914033 0.7238658  0.83042139 0.93821592\n",
      " 0.72511377 0.82073556 0.94059789 0.71569208 0.81428502 0.92695145\n",
      " 0.71617333 0.81158421 0.92734835 0.71304554 0.80937459 0.92614946\n",
      " 0.9108985  0.97157108 0.99916341 0.90803557 0.97704607 0.99897116\n",
      " 0.90666449 0.97634352 0.9988839  0.87838849 0.9555196  0.99710638\n",
      " 0.87478786 0.95654406 0.99739156 0.87815683 0.95600382 0.99756222\n",
      " 0.84868837 0.93805415 0.99388748 0.85243738 0.93836925 0.9928572\n",
      " 0.84720081 0.93463481 0.99301946 0.92045383 0.97849875 0.99907152\n",
      " 0.92211684 0.97692793 0.99916237 0.91754051 0.97869464 0.99925672\n",
      " 0.88554552 0.96605109 0.99738275 0.8861126  0.96563704 0.99784925\n",
      " 0.88524629 0.96041951 0.99766117 0.86163066 0.94095196 0.99502579\n",
      " 0.86621159 0.94262574 0.99436959 0.86164948 0.94657283 0.99464808\n",
      " 0.92746954 0.98000849 0.999628   0.92670138 0.98190518 0.99934841\n",
      " 0.91987571 0.97645008 0.99935088 0.89792423 0.96679083 0.99756498\n",
      " 0.89335214 0.96525652 0.99803639 0.89452248 0.96598351 0.99832689\n",
      " 0.86997144 0.94873014 0.995318   0.8675037  0.94843654 0.99493331\n",
      " 0.8731096  0.95322926 0.99474784 0.93169297 0.9820626  0.99916448\n",
      " 0.9303116  0.98237649 0.99934994 0.92265804 0.98253815 0.99934941\n",
      " 0.89965777 0.96350263 0.99757064 0.90044764 0.96815031 0.99803823\n",
      " 0.90307865 0.96351556 0.99774291 0.87150526 0.95269073 0.99493381\n",
      " 0.87536222 0.95169249 0.99530027 0.86970509 0.95207332 0.9966269\n",
      " 0.47426012 0.53693301 0.60289617 0.47027579 0.53956883 0.60144277\n",
      " 0.47044175 0.53819745 0.60467243 0.4695264  0.54249429 0.59615471\n",
      " 0.47817737 0.53410974 0.59902025 0.47497309 0.53849639 0.59521152\n",
      " 0.472515   0.53286558 0.59012228 0.46768162 0.5291653  0.59166502\n",
      " 0.47713181 0.52629253 0.59653884 0.47733607 0.53873035 0.60869019\n",
      " 0.47731315 0.54440536 0.60483708 0.48032511 0.54276528 0.6136462\n",
      " 0.47652542 0.53972654 0.60063373 0.47386419 0.54188546 0.60139241\n",
      " 0.47370078 0.54244692 0.60187128 0.47191483 0.54152875 0.59854343\n",
      " 0.47988671 0.53617519 0.60507312 0.47788286 0.53899565 0.60528177\n",
      " 0.48747615 0.54708721 0.61039216 0.48112537 0.54416328 0.61727526\n",
      " 0.4811977  0.54061638 0.61503555 0.47653936 0.54504319 0.602135\n",
      " 0.48005896 0.54453927 0.60797149 0.48609258 0.53888964 0.60376482\n",
      " 0.48308825 0.54256244 0.60121499 0.47795325 0.54631256 0.60709378\n",
      " 0.4767183  0.54419732 0.60900057 0.48912382 0.55073081 0.61314514\n",
      " 0.48704392 0.55408539 0.61067749 0.48282426 0.54487474 0.62036939\n",
      " 0.48141412 0.54676649 0.6078821  0.48245191 0.55325817 0.62130976\n",
      " 0.48836183 0.54736487 0.61087038 0.48836061 0.54591453 0.6097374\n",
      " 0.49142186 0.54777309 0.60802904 0.48022546 0.54674262 0.60588558\n",
      " 0.62390038 0.72096174 0.82479124 0.62342401 0.72314484 0.8278218\n",
      " 0.6307378  0.72368044 0.82464312 0.62287726 0.70980765 0.80430716\n",
      " 0.62430595 0.70453708 0.80097446 0.62355266 0.70909777 0.80556818\n",
      " 0.61219143 0.70034496 0.79138496 0.60857171 0.70225235 0.78736357\n",
      " 0.61351056 0.69769388 0.78922443 0.63855252 0.73572688 0.83655994\n",
      " 0.63341593 0.72397645 0.83627676 0.64134081 0.74217139 0.82665388\n",
      " 0.63399115 0.7236726  0.80991172 0.63062703 0.71756779 0.82027024\n",
      " 0.62811557 0.71758514 0.81778481 0.62460466 0.70492683 0.80137171\n",
      " 0.62668285 0.70738395 0.79887043 0.62952071 0.70444644 0.80337694\n",
      " 0.64253664 0.73346156 0.84256127 0.64741865 0.73627619 0.84221314\n",
      " 0.64314118 0.7357805  0.84051778 0.6404556  0.72329429 0.82134561\n",
      " 0.63866993 0.72670011 0.8185926  0.63675458 0.72463149 0.82439911\n",
      " 0.63213135 0.71744912 0.8097271  0.6271808  0.71418985 0.80873832\n",
      " 0.62410611 0.71579855 0.8099321  0.64575986 0.74185878 0.84219901\n",
      " 0.65022547 0.74449225 0.83806072 0.63921747 0.74340207 0.84285028\n",
      " 0.63390487 0.72814695 0.82208328 0.63713223 0.72240763 0.82888601\n",
      " 0.63534551 0.72322425 0.82600396 0.63206982 0.71442195 0.80952703\n",
      " 0.62925469 0.72036808 0.80840798 0.62736851 0.71831813 0.81384776\n",
      " 0.81451477 0.91246625 0.97127469 0.81215685 0.91205895 0.97518367\n",
      " 0.81339411 0.91700233 0.9749471  0.77991432 0.87553256 0.95759733\n",
      " 0.77774119 0.87687544 0.95754556 0.78612269 0.88019019 0.9580483\n",
      " 0.7526286  0.85384814 0.93921157 0.75897681 0.85459584 0.94183517\n",
      " 0.75742858 0.84930539 0.9397189  0.82443765 0.92605523 0.97988122\n",
      " 0.83024041 0.9217118  0.97834631 0.82403334 0.91983583 0.97760822\n",
      " 0.79934408 0.89411388 0.96137937 0.79424126 0.8965652  0.9637821\n",
      " 0.79811128 0.89013597 0.96084861 0.77159071 0.86636908 0.94463178\n",
      " 0.7674075  0.86271594 0.94586869 0.76459728 0.86482539 0.94859805\n",
      " 0.83602414 0.92365212 0.97833396 0.8397679  0.92941105 0.98102222\n",
      " 0.84178899 0.93041323 0.98198385 0.80359492 0.89627351 0.96352881\n",
      " 0.80721902 0.90107807 0.96194961 0.81340438 0.89250704 0.96353137\n",
      " 0.7791643  0.87415535 0.95093008 0.77588674 0.87502368 0.95003593\n",
      " 0.78242313 0.86834553 0.94846751 0.84289491 0.92911355 0.97801895\n",
      " 0.84986802 0.92790193 0.97841326 0.84880154 0.93260057 0.97927269\n",
      " 0.80733403 0.89677331 0.96296602 0.80722822 0.89750625 0.96598131\n",
      " 0.81048934 0.89845174 0.96232936 0.78239119 0.87642295 0.9485904\n",
      " 0.782611   0.8741575  0.95480504 0.7819617  0.87785222 0.95010018]\n",
      "[0.37316968 0.38595322 0.34195055 0.3865698  0.34681475 0.3254054\n",
      " 0.36400401 0.35068052 0.35635823 0.39140688 0.37717411 0.32966483\n",
      " 0.35009362 0.34962917 0.35679825 0.39298723 0.34945175 0.3242756\n",
      " 0.37561977 0.3586869  0.34442597 0.37227111 0.35737328 0.35174192\n",
      " 0.37133215 0.34735895 0.3469876  0.39522269 0.33358132 0.32607369\n",
      " 0.36707498 0.3231459  0.32794937 0.36914283 0.35655053 0.33607409\n",
      " 0.35934275 0.35457321 0.349347   0.36415761 0.34903285 0.32307963\n",
      " 0.37091774 0.37271547 0.3308262  0.36299757 0.34244255 0.3448852\n",
      " 0.39054745 0.34990958 0.36111174 0.36063063 0.34746385 0.33266568\n",
      " 0.37274306 0.37098031 0.33911123 0.37003518 0.35491976 0.34267612\n",
      " 0.37293913 0.32977466 0.31879419 0.3604464  0.34361177 0.34336524\n",
      " 0.39609783 0.37505956 0.32788729 0.37972919 0.36005619 0.36500853\n",
      " 0.36542965 0.34562537 0.33936602 0.3587595  0.34409215 0.34783389\n",
      " 0.37050788 0.36112532 0.34950486 0.34048306 0.34419687 0.32166094\n",
      " 0.3987726  0.35839627 0.30088653 0.36939948 0.35405886 0.33977039\n",
      " 0.38085333 0.34027238 0.31736528 0.36205818 0.3483973  0.33154542\n",
      " 0.36909502 0.34032697 0.34597773 0.37661219 0.34054296 0.35721208\n",
      " 0.38345221 0.35834641 0.33558261 0.38487581 0.35352849 0.31168236\n",
      " 0.33279803 0.34503139 0.32347009 0.33839868 0.31166298 0.3180934\n",
      " 0.34455816 0.3113294  0.3004704  0.3357575  0.3150981  0.33719158\n",
      " 0.34273596 0.31510299 0.2916247  0.3612968  0.30433282 0.31560007\n",
      " 0.3534     0.34146306 0.3301953  0.3360362  0.29848254 0.28890207\n",
      " 0.34410029 0.33161954 0.33166616 0.3423062  0.31657847 0.30283187\n",
      " 0.32341737 0.3284114  0.3444219  0.3274085  0.35181539 0.33842384\n",
      " 0.34345878 0.32780682 0.33487655 0.32027346 0.33908204 0.28922307\n",
      " 0.35775346 0.33738305 0.34403946 0.34423414 0.33174838 0.3082827\n",
      " 0.32437677 0.33173316 0.32416488 0.3252779  0.30720005 0.31223155\n",
      " 0.33927615 0.35076562 0.32574707 0.3294195  0.32296427 0.3084681\n",
      " 0.32383256 0.31075594 0.33240184 0.33269498 0.32477593 0.30276067\n",
      " 0.34825584 0.313284   0.31940085 0.35573229 0.32317336 0.30110944\n",
      " 0.33002685 0.31722514 0.33750987 0.33606523 0.32600468 0.32235064\n",
      " 0.34814863 0.32214015 0.30925303 0.3537292  0.30849413 0.29875448\n",
      " 0.3481412  0.32973772 0.31716303 0.32860288 0.33392384 0.32203102\n",
      " 0.33904468 0.32586543 0.29713469 0.33159726 0.32575613 0.30742151\n",
      " 0.31829056 0.31255666 0.31350708 0.3403288  0.31755001 0.32299192\n",
      " 0.34011286 0.3303455  0.3398688  0.33174327 0.32239548 0.31501089\n",
      " 0.31634841 0.29422603 0.31625436 0.32635032 0.32912982 0.28452407\n",
      " 0.31895819 0.31365552 0.33258921 0.31847497 0.3245779  0.28741949\n",
      " 0.33901689 0.30848613 0.30325768 0.31527391 0.30890318 0.30083229\n",
      " 0.32035135 0.31174861 0.30833392 0.33403537 0.33507043 0.33164338\n",
      " 0.31563968 0.30966403 0.31155345 0.33790544 0.32288687 0.30912842\n",
      " 0.33266603 0.34787416 0.3389575  0.31579017 0.31979363 0.3146309\n",
      " 0.33201384 0.29185194 0.33714006 0.31517122 0.32992416 0.31153073\n",
      " 0.32202787 0.29451182 0.28492108 0.30285887 0.32357818 0.3237607\n",
      " 0.33608348 0.3238963  0.34308797 0.32270495 0.32576463 0.30368135\n",
      " 0.32351971 0.31879272 0.34625679 0.3239336  0.31130412 0.31336932\n",
      " 0.32219986 0.32769753 0.30542833 0.30720243 0.30227559 0.32078603\n",
      " 0.3290331  0.31960193 0.32411177 0.30766982 0.31063149 0.33478931\n",
      " 0.30092895 0.2982044  0.30733155 0.32819739 0.30993443 0.32582408\n",
      " 0.33858574 0.29499601 0.30717593 0.31466729 0.32916594 0.30662324\n",
      " 0.32201606 0.31501185 0.32059495 0.3266404  0.34116795 0.32751209\n",
      " 0.295075   0.31744503 0.32292183 0.29844146 0.31662175 0.28723607\n",
      " 0.33585552 0.29037007 0.31661799 0.34876993 0.30947925 0.27532915\n",
      " 0.33101895 0.29946794 0.31146866 0.31084943 0.32970543 0.31519778\n",
      " 0.40763751 0.42022302 0.42962528 0.40871613 0.42510721 0.39874743\n",
      " 0.40584467 0.40750347 0.41743643 0.41622807 0.40582207 0.41294515\n",
      " 0.39971263 0.39865056 0.40912039 0.39599886 0.40997154 0.40532939\n",
      " 0.40302711 0.40589632 0.41317803 0.41235783 0.40352716 0.39893353\n",
      " 0.40431769 0.40695612 0.41360985 0.41051192 0.40781964 0.40927751\n",
      " 0.40902776 0.39629547 0.39779064 0.39934101 0.41536014 0.40576044\n",
      " 0.41642835 0.40998504 0.39403367 0.40061644 0.40191848 0.4059078\n",
      " 0.40331643 0.38716184 0.39101518 0.39776925 0.40151575 0.38716565\n",
      " 0.40585008 0.41351678 0.40507391 0.40093346 0.41088096 0.40308285\n",
      " 0.40915039 0.39806788 0.39847693 0.40521237 0.39205853 0.3843321\n",
      " 0.40247522 0.40385832 0.41639437 0.39840233 0.41086488 0.40484949\n",
      " 0.39792962 0.41108407 0.38109    0.38947944 0.40381594 0.39402054\n",
      " 0.39995192 0.40742982 0.40905736 0.40732387 0.40831705 0.40893882\n",
      " 0.40304601 0.40970096 0.40030627 0.3878231  0.39879587 0.40471534\n",
      " 0.40922477 0.41109073 0.38616875 0.40827875 0.40414019 0.40946835\n",
      " 0.40075916 0.39878865 0.39235122 0.40043015 0.40463836 0.41281394\n",
      " 0.39143121 0.39710253 0.3900398  0.41066211 0.40541736 0.40328575\n",
      " 0.39735503 0.39648603 0.39618768 0.401459   0.4142276  0.40547335\n",
      " 0.37898715 0.41123908 0.37197447 0.39382149 0.38838459 0.37894527\n",
      " 0.38606222 0.40316533 0.37675007 0.40018869 0.38859154 0.36969185\n",
      " 0.39198898 0.39315474 0.38834783 0.39717905 0.37891565 0.38846428\n",
      " 0.40208105 0.39203606 0.3796375  0.40351607 0.38796715 0.37381603\n",
      " 0.38364985 0.38913696 0.38088928 0.39269648 0.38195111 0.38291423\n",
      " 0.39976847 0.38929827 0.38103664 0.38859939 0.38659632 0.36262473\n",
      " 0.37779142 0.39370473 0.37613962 0.40599648 0.37803355 0.39541459\n",
      " 0.38308964 0.38908519 0.37832215 0.38203317 0.40132113 0.38876713\n",
      " 0.38947227 0.38981317 0.37394084 0.39338566 0.38847741 0.38718298\n",
      " 0.38871865 0.39434368 0.37676452 0.39051511 0.37514991 0.37476997\n",
      " 0.39212625 0.37817118 0.38700842 0.39032321 0.37762506 0.37802075\n",
      " 0.38164374 0.39172533 0.38791524 0.38956095 0.37244016 0.37973703\n",
      " 0.38243173 0.37284191 0.38364742 0.38860741 0.37131629 0.37146864\n",
      " 0.39101097 0.37009561 0.38663781 0.37839683 0.38276607 0.38319592\n",
      " 0.38954386 0.38845296 0.36925297 0.39027064 0.38453448 0.38315438\n",
      " 0.37528551 0.36570607 0.38609479 0.3778013  0.39457133 0.40085534\n",
      " 0.40244218 0.38638265 0.35647598 0.38664751 0.36784422 0.37983572\n",
      " 0.38125099 0.38427887 0.37271382 0.37137633 0.37624973 0.37537646\n",
      " 0.38190427 0.37918586 0.36999376 0.35781353 0.37306398 0.37045838\n",
      " 0.38199365 0.37273724 0.34605189 0.3823769  0.38007425 0.36681313\n",
      " 0.35906162 0.38123369 0.35795831 0.37194971 0.37616214 0.37326396\n",
      " 0.36861105 0.38833352 0.36170177 0.40373244 0.36589285 0.37956277\n",
      " 0.39926836 0.38642744 0.357963   0.39677982 0.37413918 0.36431551\n",
      " 0.37084154 0.37981258 0.36462539 0.38898755 0.38691662 0.38065156\n",
      " 0.365404   0.37622081 0.35846447 0.35237018 0.37135257 0.35972301\n",
      " 0.38806725 0.38506352 0.3385658  0.36456968 0.36895249 0.36708697\n",
      " 0.38082174 0.38318686 0.36558711 0.3806708  0.36482177 0.36291518\n",
      " 0.37164954 0.36735231 0.38154154 0.36354448 0.35282827 0.35117927\n",
      " 0.38055732 0.37472724 0.36286945 0.37247125 0.36995646 0.37028576\n",
      " 0.36201948 0.37320062 0.39406282 0.36944148 0.37524262 0.33011985\n",
      " 0.3811488  0.36366346 0.36431332 0.38291776 0.36184781 0.37730909\n",
      " 0.37131593 0.36967714 0.36130485 0.36830974 0.37112456 0.37012904\n",
      " 0.36829416 0.37584996 0.36148409 0.37860077 0.39496101 0.33912104\n",
      " 0.36892341 0.3751883  0.36499089 0.36961152 0.36371937 0.37512495\n",
      " 0.3695466  0.36388221 0.35563042 0.38072677 0.37274847 0.35949638\n",
      " 0.39195253 0.36007446 0.3660863  0.37235216 0.36505546 0.38351705\n",
      " 0.37868916 0.40354239 0.40004321 0.3841216  0.40357543 0.41051506\n",
      " 0.37942849 0.41498949 0.41805554 0.38202498 0.40998986 0.42150928\n",
      " 0.38900697 0.39375321 0.40663277 0.39370829 0.4000118  0.41672837\n",
      " 0.38432773 0.40440663 0.41185334 0.39475343 0.39664457 0.41626176\n",
      " 0.38986327 0.39379023 0.40517854 0.39037055 0.3975535  0.40941248\n",
      " 0.39521337 0.40623764 0.41209199 0.38751447 0.39900289 0.40481376\n",
      " 0.39080854 0.41469969 0.41184012 0.38444816 0.4057368  0.40254021\n",
      " 0.37416218 0.40034359 0.41986941 0.38686482 0.40215202 0.41386004\n",
      " 0.3857834  0.39420247 0.41449898 0.38120968 0.41297647 0.40618519\n",
      " 0.39840434 0.40261342 0.41755779 0.41097365 0.40389137 0.40701563\n",
      " 0.39533166 0.40865412 0.40159094 0.38991325 0.40860383 0.40847625\n",
      " 0.38579161 0.39410498 0.39864777 0.38509306 0.39543391 0.41860765\n",
      " 0.38556045 0.40325328 0.40100655 0.38366994 0.39502251 0.40674644\n",
      " 0.38409508 0.39231308 0.41253276 0.38568758 0.39929341 0.41418314\n",
      " 0.39357178 0.41086307 0.40067844 0.37763453 0.40722097 0.40914105\n",
      " 0.38771009 0.4038775  0.40421719 0.40204915 0.40181139 0.41657699\n",
      " 0.3850338  0.39700734 0.41967445 0.38847846 0.41347397 0.41603001\n",
      " 0.38524598 0.40130258 0.41459206 0.38582469 0.41759318 0.41714937\n",
      " 0.39152714 0.39310943 0.39509874 0.38381539 0.38770722 0.38470647\n",
      " 0.38511657 0.38135897 0.38502062 0.38570191 0.4041031  0.39950163\n",
      " 0.39161207 0.38966609 0.38683346 0.37695395 0.38677929 0.39196373\n",
      " 0.38268338 0.38809197 0.39341806 0.38742046 0.39670314 0.39566524\n",
      " 0.38945156 0.39818106 0.40400651 0.37887606 0.37570166 0.39497525\n",
      " 0.38012345 0.39968714 0.39179464 0.39259885 0.38876857 0.39307825\n",
      " 0.37357658 0.40100201 0.39831211 0.38088363 0.37269345 0.38051635\n",
      " 0.38738966 0.4031601  0.38483415 0.38703328 0.39940531 0.38753395\n",
      " 0.39057193 0.38122776 0.40765218 0.37379998 0.40106898 0.37938995\n",
      " 0.37345619 0.38563288 0.39263315 0.38871024 0.39109139 0.37303039\n",
      " 0.3898549  0.39447682 0.39053193 0.37270889 0.39938281 0.38842782\n",
      " 0.38374624 0.40817137 0.37467986 0.39846759 0.38157521 0.38520836\n",
      " 0.3926873  0.38403543 0.38759164 0.38262867 0.38422882 0.40792941\n",
      " 0.38056025 0.3869989  0.38629446 0.36586481 0.38822531 0.38092206\n",
      " 0.37413018 0.38220687 0.39407181 0.36961446 0.39347612 0.3856162\n",
      " 0.38488379 0.37675137 0.39125273 0.3702161  0.39045946 0.39165208\n",
      " 0.36596261 0.37704576 0.3777804  0.3803971  0.3897634  0.38130398\n",
      " 0.37515116 0.38281599 0.37537334 0.39610016 0.36922992 0.39281949\n",
      " 0.38484822 0.37182718 0.37569808 0.36917775 0.36619435 0.36870968\n",
      " 0.35666656 0.36077197 0.36595585 0.38193945 0.36394121 0.38418975\n",
      " 0.36763767 0.37621289 0.35293997 0.36611621 0.38993195 0.38627659\n",
      " 0.38283541 0.37424898 0.36464805 0.39102015 0.38052763 0.37031185\n",
      " 0.37423773 0.38459719 0.38905026 0.37901832 0.37110143 0.36394687\n",
      " 0.36097512 0.37694404 0.37030533 0.3844526  0.36048379 0.38480959\n",
      " 0.37752053 0.38296733 0.36427641 0.37950739 0.37001941 0.37349684\n",
      " 0.37024713 0.37459236 0.38005472 0.39360224 0.38531169 0.38073504\n",
      " 0.36872191 0.37218398 0.37614849 0.36095602 0.37946527 0.38723064\n",
      " 0.37555703 0.37628471 0.37218504 0.36342198 0.37581433 0.38503455\n",
      " 0.36073569 0.37075528 0.36886638 0.35967288 0.36947375 0.3871294\n",
      " 0.35854704 0.36520296 0.36708243 0.38234364 0.38739818 0.38856753\n",
      " 0.36916329 0.37207415 0.38778836 0.37406587 0.37446958 0.37787453\n",
      " 0.37792331 0.37695652 0.37320926 0.35996299 0.37795752 0.37846228\n",
      " 0.35592164 0.38015839 0.36473439 0.3619545  0.37193283 0.37931964\n",
      " 0.37281059 0.37520238 0.36435915 0.35875507 0.3592807  0.38116067\n",
      " 0.35670592 0.37359967 0.3702331  0.36548388 0.38136686 0.37592523\n",
      " 0.36301936 0.37877809 0.3766357  0.36631383 0.36900578 0.36062062]\n"
     ]
    }
   ],
   "source": [
    "# Check for overfitting\n",
    "\n",
    "print(grid_cv_grad_sii.cv_results_.keys())\n",
    "print(grid_cv_grad_sii.cv_results_[\"mean_train_score\"].shape)  # n_estimators: 11 values, max_depth: 4 values. Thus shape, 11*4=44\n",
    "print(grid_cv_grad_sii.cv_results_[\"mean_test_score\"].shape)\n",
    "\n",
    "print(grid_cv_grad_sii.cv_results_[\"mean_train_score\"])\n",
    "print(grid_cv_grad_sii.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean_train_score: [0.69634385]\n",
      "Best mean_test_score: [0.42962528]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify the mean_train_score and mean_test_score values associated with best_score\n",
    "best_score_index = np.where(grid_cv_grad_sii.cv_results_[\"mean_test_score\"]==grid_cv_grad_sii.best_score_)\n",
    "print('Best mean_train_score:', grid_cv_grad_sii.cv_results_[\"mean_train_score\"][best_score_index])\n",
    "print('Best mean_test_score:', grid_cv_grad_sii.cv_results_[\"mean_test_score\"][best_score_index])\n",
    "\n",
    "#Create a df with grid_cv_grad.cv_results_[\"mean_train_score\"] as the first column and grid_cv_grad.cv_results_[\"mean_test_score\"] as the second column\n",
    "grad_sii_results_df = pd.DataFrame({'mean_train_score': grid_cv_grad_sii.cv_results_[\"mean_train_score\"], 'mean_test_score': grid_cv_grad_sii.cv_results_[\"mean_test_score\"]})\n",
    "\n",
    "# Compute a new collumn that is the ratio of mean_train_score to mean_test_score\n",
    "grad_sii_results_df['ratio'] = grad_sii_results_df['mean_train_score']/grad_sii_results_df['mean_test_score']\n",
    "\n",
    "# Identify outliers in ratio\n",
    "Q1 = grad_sii_results_df['ratio'].quantile(0.25)\n",
    "Q3 = grad_sii_results_df['ratio'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = grad_sii_results_df[(grad_results_df['ratio'] < (Q1 - 1.5 * IQR)) | (grad_sii_results_df['ratio'] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# Remove the outliers from grad_results_df\n",
    "grad_sii_results_df = grad_results_df[~grad_results_df['ratio'].isin(outliers['ratio'])]\n",
    "\n",
    "# Create a histogram of ratio\n",
    "plt.hist(grad_sii_results_df['ratio'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The ratio of train kappas to test kappas using our \"best\" set of parameters was 1.6208. This seems like it might correspond to overfitting. But it seems in line with the (non-outlier) ratios among all tested sets of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manually Tuning Logistic Regression Inside an Ordinal Classifier**\n",
    "\n",
    "GridSearchCV doesn't seem to be able to pass parameter values into a model wrapped in an ordinal classifier. So we'll tune this manually.\n",
    "\n",
    "We're only going to do this for logistic regression (for now) due to time constraints. But a next step would be to do it for gradient boosting inside an ordinal classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## import kfold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create a custom scorer that first rounds the values of sii and then applies a cohen_kappa_score\n",
    "def sii_kappa(y_true, y_pred):\n",
    "    y_pred_round = np.round(y_pred)\n",
    "    return cohen_kappa_score(y_true, y_pred_round, weights='quadratic')\n",
    "\n",
    "kappa_scorer = make_scorer(sii_kappa)\n",
    "\n",
    "siiratios = {0: 1228, 1: 619, 2:315, 3:128}\n",
    "oversample = SMOTE(sampling_strategy=siiratios)\n",
    "\n",
    "## set the number of CV folds\n",
    "n_splits = 5\n",
    "\n",
    "## Make the kfold object\n",
    "kfold = StratifiedKFold(n_splits, shuffle=True)\n",
    "\n",
    "C_params = [0.001,0.01,0.1,0.5, 1,5, 10,20, 50, 70, 100, 150, 200]\n",
    "\n",
    "lr_test_kappas = np.zeros((n_splits, len(C_params)))\n",
    "lr_train_kappas = np.zeros((n_splits, len(C_params)))\n",
    "\n",
    "for i,(train_index, test_index) in enumerate(kfold.split(train_cleaned[predictors], train_cleaned['sii'])):\n",
    "    train_tt = train_cleaned.iloc[train_index]\n",
    "    train_ho = train_cleaned.iloc[test_index]\n",
    "\n",
    "    # Do the duplication here\n",
    "\n",
    "    for j, cval in enumerate(C_params):\n",
    "        #print(i,j)\n",
    "        ordinal_logistic_pipe = Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "            ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "            ('over', oversample),\n",
    "            ('scale', StandardScaler()),\n",
    "            ('logistic_oc', OrdinalClassifier(LogisticRegression(max_iter=1000, C=cval)))])\n",
    "                                        \n",
    "        ordinal_logistic_pipe.fit(train_tt[predictors], train_tt['sii'])\n",
    "        \n",
    "        pred_test = ordinal_logistic_pipe.predict(train_ho[predictors])\n",
    "        pred_train = ordinal_logistic_pipe.predict(train_tt[predictors])\n",
    "        \n",
    "        lr_test_kappas[i,j] = sii_kappa(train_ho['sii'],  pred_test)\n",
    "        lr_train_kappas[i,j] = sii_kappa(train_tt['sii'],  pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Get optimal value of C\n",
    "max_index = np.unravel_index(np.argmax(np.mean(lr_test_kappas, axis=0)), \n",
    "                                       np.mean(lr_test_kappas, axis=0).shape)\n",
    "\n",
    "\n",
    "print(C_params[max_index[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best parameters**\n",
    "\n",
    "We have run the logistic-in-ordinal loop several times and the \"optimal\" value of C appears to vary quite a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for Overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means of C-values of [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 20, 50, 70, 100, 150, 200] for test set are [0.17680043 0.36780617 0.37241579 0.38013313 0.38252283 0.39055904\n",
      " 0.38868231 0.38303997 0.3933233  0.39050204 0.40019627 0.39185387\n",
      " 0.37875083]\n",
      "Means of C-values of [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 20, 50, 70, 100, 150, 200] for train set are [0.17680043 0.36780617 0.37241579 0.38013313 0.38252283 0.39055904\n",
      " 0.38868231 0.38303997 0.3933233  0.39050204 0.40019627 0.39185387\n",
      " 0.37875083]\n"
     ]
    }
   ],
   "source": [
    "# Compare kappas\n",
    "mean_test_kappas = np.mean(lr_test_kappas, axis=0)\n",
    "mean_train_kappas = np.mean(lr_test_kappas, axis=0)\n",
    "print('Means of C-values of', C_params,'for test set are',mean_test_kappas)\n",
    "print('Means of C-values of', C_params,'for train set are',mean_train_kappas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The kappa values for the train and test sets are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retesting with Optimized Parameters**\n",
    "\n",
    "We'll use the models generated above through the tuning process to compare with our original candidates and against each other.\n",
    "\n",
    "We note that the models above were all models for regression rather than classification. So for the models we're using inside the ordinal classifiers, we'll manually input the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from OrdinalClassifier import *\n",
    "\n",
    "# Create classifiers to use as inputs to ordinal classifiers\n",
    "\n",
    "logisticc = LogisticRegression(max_iter=1000, C=100)\n",
    "gradc = GradientBoostingClassifier()\n",
    "gradc_pciat = GradientBoostingClassifier(learning_rate=0.05, max_depth= 3, max_features= 15, min_samples_leaf= 11, min_samples_split= 6, n_estimators= 100)\n",
    "gradc_sii = GradientBoostingClassifier(learning_rate=0.1, max_depth= 3, max_features= 8, min_samples_leaf= 8, min_samples_split= 2, n_estimators= 100)\n",
    "xgbc = XGBClassifier()\n",
    "\n",
    "\n",
    "models = {\n",
    "'slr_pipe' : Pipeline([\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', ['PreInt_EduHx-computerinternet_hoursday'])], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())]),\n",
    "\n",
    "'mlr_key_pipe' : Pipeline([\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', keyfeatures)], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())]),\n",
    "\n",
    "'mlr_all_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', predictors_less)], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())]),\n",
    "\n",
    "'rf': RandomForestRegressor(),\n",
    "'rf_pciat': RandomForestRegressor(max_depth=5, min_samples_split= 4, n_estimators=200),\n",
    "'rf_sii': RandomForestRegressor(max_depth=6, min_samples_split= 2, n_estimators=100),\n",
    "\n",
    "'ada' : AdaBoostRegressor(),\n",
    "\n",
    "'grad' : GradientBoostingRegressor(),\n",
    "'grad_pciat': GradientBoostingRegressor(learning_rate=0.1, max_depth= 3, max_features= 10, min_samples_leaf= 8, min_samples_split= 3, n_estimators= 50),\n",
    "'gradc_sii' : GradientBoostingRegressor(learning_rate=0.1, max_depth= 3, max_features= 8, min_samples_leaf= 8, min_samples_split= 2, n_estimators= 100),\n",
    "\n",
    "'xgb': XGBRegressor(),\n",
    "\n",
    "'ordinal_logistic_pipe' : Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('logistic_oc', OrdinalClassifier(logisticc))]),\n",
    "\n",
    "'ordinal_grad': OrdinalClassifier(gradc),\n",
    "'ordinal_grad_pciat': OrdinalClassifier(gradc_pciat),\n",
    "'ordinal_grad_sii': OrdinalClassifier(gradc_sii),\n",
    "\n",
    "'ordinal_xgb': OrdinalClassifier(xgbc)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Set up SMOTE to create 128 (rather than 32) instances of sii=3\n",
    "siiratios = {0: 1228, 1: 619, 2:315, 3:128}\n",
    "oversample = SMOTE(sampling_strategy=siiratios)\n",
    "\n",
    "# Set up a list of the models and methods to organize the computation of means in the kfold split\n",
    "modellist = []\n",
    "for pipeline_name, pipeline_obj in models.items():\n",
    "    modellist.append(pipeline_name)\n",
    "\n",
    "methodlist = ['Compute SII from PCIAT (Standard Bins) (kappa)', \n",
    "                'Compute SII from PCIAT (Modified Bins) (kappa)',\n",
    "                'Predict SII (rounded) (kappa)']\n",
    "\n",
    "num_splits = 5\n",
    "\n",
    "# Create an array with len(modellist) rows and len(methodlist) columns\n",
    "output = np.zeros((len(methodlist), len(modellist), num_splits))\n",
    "\n",
    "#Make a StratifiedKFold object stratified by the variable sii\n",
    "# This is necessary due to the small number of sii=3 values\n",
    "kfold = StratifiedKFold(n_splits=num_splits, shuffle=True)\n",
    "\n",
    "## i will count the split number \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(train_cleaned, train_cleaned['sii']):\n",
    "    train_tt = train_cleaned.iloc[train_index]\n",
    "    train_ho = train_cleaned.iloc[test_index]\n",
    "\n",
    "    #The next four lines will use SMOTE to oversample \n",
    "    mice = Custom_MICE_Imputer()\n",
    "    train_tt = mice.fit_transform(train_tt)\n",
    "    train_tt = zone_encoder(train_tt)\n",
    "    X, y = oversample.fit_resample(train_tt[predictors_plus], train_tt['sii'])\n",
    "\n",
    "    train_ho = mice.fit_transform(train_ho)\n",
    "    train_ho = zone_encoder(train_ho)\n",
    "\n",
    "    # j will enumerate the model\n",
    "    j=0\n",
    "\n",
    "    for pipeline_name, pipeline_obj in models.items():\n",
    "        # The ordinal predictors can't predict PCIAT scores, so we'll leave them out of the first round of computations\n",
    "        if 'ordinal' in pipeline_name:\n",
    "            kappa_sii_comp = 0\n",
    "            kappa_sii_comp_mod = 0\n",
    "        else:\n",
    "            # Fit and make predictions of PCIAT_Total\n",
    "            pipeline_obj.fit(X[predictors_less], X['PCIAT-PCIAT_Total'])\n",
    "            pred = pipeline_obj.predict(train_ho[predictors_less])\n",
    "\n",
    "            # Compute sii based on PCIAT\n",
    "            bins = [0, 30, 49,79,100]\n",
    "            pred_bin = np.digitize(pred, bins)-1\n",
    "\n",
    "            # Try a slightly different set of bins suggested by the \"tuning\" below\n",
    "            bins_mod = [0, 27, 39, 79, 100]\n",
    "            pred_bin_mod = np.digitize(pred, bins_mod)-1\n",
    "\n",
    "            # Compute kappa values\n",
    "            kappa_sii_comp = cohen_kappa_score(train_ho['sii'], pred_bin, weights='quadratic')\n",
    "            kappa_sii_comp_mod = cohen_kappa_score(train_ho['sii'], pred_bin_mod, weights='quadratic')\n",
    "        \n",
    "        # Store the kappa values in the output array\n",
    "        output[0,j,i] = kappa_sii_comp\n",
    "        output[1,j,i] = kappa_sii_comp_mod\n",
    "        j=j+1\n",
    "\n",
    "    j=0\n",
    "    for pipeline_name, pipeline_obj in models.items():\n",
    "        # Fit and make predictions of sii\n",
    "        pipeline_obj.fit(X[predictors], y)\n",
    "        pred = pipeline_obj.predict(train_ho[predictors])\n",
    "\n",
    "        # Round the predictors to compute kappa\n",
    "        pred_round = np.round(pred)\n",
    "\n",
    "        # Compute and record the kappa values\n",
    "        kappa_sii_round = cohen_kappa_score(train_ho['sii'], pred_round, weights='quadratic')\n",
    "\n",
    "        output[2,j,i] = kappa_sii_round\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "\n",
    "# Create a new array by computing the average of the values in output along the third axis\n",
    "output_tuned_avg = np.mean(output, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slr_pipe</th>\n",
       "      <th>mlr_key_pipe</th>\n",
       "      <th>mlr_all_pipe</th>\n",
       "      <th>rf</th>\n",
       "      <th>rf_pciat</th>\n",
       "      <th>rf_sii</th>\n",
       "      <th>ada</th>\n",
       "      <th>grad</th>\n",
       "      <th>grad_pciat</th>\n",
       "      <th>gradc_sii</th>\n",
       "      <th>xgb</th>\n",
       "      <th>ordinal_logistic_pipe</th>\n",
       "      <th>ordinal_grad</th>\n",
       "      <th>ordinal_grad_pciat</th>\n",
       "      <th>ordinal_grad_sii</th>\n",
       "      <th>ordinal_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Compute SII from PCIAT (Standard Bins) (kappa)</th>\n",
       "      <td>0.273194</td>\n",
       "      <td>0.434728</td>\n",
       "      <td>0.348193</td>\n",
       "      <td>0.403914</td>\n",
       "      <td>0.412772</td>\n",
       "      <td>0.426744</td>\n",
       "      <td>0.377264</td>\n",
       "      <td>0.403243</td>\n",
       "      <td>0.409499</td>\n",
       "      <td>0.410318</td>\n",
       "      <td>0.356853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compute SII from PCIAT (Modified Bins) (kappa)</th>\n",
       "      <td>0.301702</td>\n",
       "      <td>0.444401</td>\n",
       "      <td>0.383093</td>\n",
       "      <td>0.419950</td>\n",
       "      <td>0.429164</td>\n",
       "      <td>0.424323</td>\n",
       "      <td>0.396684</td>\n",
       "      <td>0.437358</td>\n",
       "      <td>0.448010</td>\n",
       "      <td>0.444204</td>\n",
       "      <td>0.368767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predict SII (rounded) (kappa)</th>\n",
       "      <td>0.280164</td>\n",
       "      <td>0.411745</td>\n",
       "      <td>0.333130</td>\n",
       "      <td>0.389833</td>\n",
       "      <td>0.407565</td>\n",
       "      <td>0.405852</td>\n",
       "      <td>0.199699</td>\n",
       "      <td>0.405979</td>\n",
       "      <td>0.410163</td>\n",
       "      <td>0.399711</td>\n",
       "      <td>0.348015</td>\n",
       "      <td>0.289887</td>\n",
       "      <td>0.392171</td>\n",
       "      <td>0.416182</td>\n",
       "      <td>0.416411</td>\n",
       "      <td>0.374339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                slr_pipe  mlr_key_pipe  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)  0.273194      0.434728   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)  0.301702      0.444401   \n",
       "Predict SII (rounded) (kappa)                   0.280164      0.411745   \n",
       "\n",
       "                                                mlr_all_pipe        rf  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)      0.348193  0.403914   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)      0.383093  0.419950   \n",
       "Predict SII (rounded) (kappa)                       0.333130  0.389833   \n",
       "\n",
       "                                                rf_pciat    rf_sii       ada  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)  0.412772  0.426744  0.377264   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)  0.429164  0.424323  0.396684   \n",
       "Predict SII (rounded) (kappa)                   0.407565  0.405852  0.199699   \n",
       "\n",
       "                                                    grad  grad_pciat  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)  0.403243    0.409499   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)  0.437358    0.448010   \n",
       "Predict SII (rounded) (kappa)                   0.405979    0.410163   \n",
       "\n",
       "                                                gradc_sii       xgb  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)   0.410318  0.356853   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)   0.444204  0.368767   \n",
       "Predict SII (rounded) (kappa)                    0.399711  0.348015   \n",
       "\n",
       "                                                ordinal_logistic_pipe  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)               0.000000   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)               0.000000   \n",
       "Predict SII (rounded) (kappa)                                0.289887   \n",
       "\n",
       "                                                ordinal_grad  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)      0.000000   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)      0.000000   \n",
       "Predict SII (rounded) (kappa)                       0.392171   \n",
       "\n",
       "                                                ordinal_grad_pciat  \\\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)            0.000000   \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)            0.000000   \n",
       "Predict SII (rounded) (kappa)                             0.416182   \n",
       "\n",
       "                                                ordinal_grad_sii  ordinal_xgb  \n",
       "Compute SII from PCIAT (Standard Bins) (kappa)          0.000000     0.000000  \n",
       "Compute SII from PCIAT (Modified Bins) (kappa)          0.000000     0.000000  \n",
       "Predict SII (rounded) (kappa)                           0.416411     0.374339  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data frame from output using modellist as the names of the columns and methodlist as the names of the rows\n",
    "output_tuned_df = pd.DataFrame(output_tuned_avg, columns=modellist, index=methodlist)\n",
    "\n",
    "output_tuned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection Results**\n",
    "\n",
    "The largest kappa scores were from predicting PCIAT and then using modified bins to compute sii values. The best results all came from gradient boosting (using the PCIAT tuned parameters increased performance slightly, but not too much). However, using the keyfeatures with linear regression was close behind, followed by the tuned random forest.\n",
    "\n",
    "When predicting PCIAT using the standard bins, the best result came from using linear regression with keyfeatures, followed by using gradient boosting tuned for sii prediction.\n",
    "\n",
    "When predicting sii directly, the best results came from gradient boosting within an ordinal classifier (tuned for predicting sii), followed by non-ordinal (untuned) gradient boosting, and then tuned gradient boosting and linear regression with keyfeatures.\n",
    "\n",
    "For the purposes of the Erdos Institute project, we will pick gradient boost, predicting PCIAT and then modified bins for sii score, as a final model. (For the purposes of the Kaggle competition, these results suggest to us multiple models in the running, all of them worthy of a submission.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
