{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the starting data.\n",
    "train_cleaned=pd.read_csv('train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I am going to impute input variables. \n",
    "I'm doing this before I remove the cases for which we can't compute sii scores, so that we have all data available.\n",
    "I am doing this in groups: For example, I will use only physical data to impute physical data values. This seems reasonable to do, although perhaps we might get more accurate results if we used more variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Because we will be using multiple imputation strategies, \n",
    "# I am going to define a new dataframe that will record all of the imputations using KNN.\n",
    "\n",
    "train_imp_KNN=train_cleaned.copy()\n",
    "\n",
    "# define a pipe that first scales the variables and then does a KNN imputation. \n",
    "# Note that when there is a case with no values at all, KNNImputer replaces fills in each variable with the group average.\n",
    "\n",
    "Number_Neighbors=5\n",
    "impute_pipe = Pipeline([('scale', StandardScaler()),\n",
    "                 ('KNN_impute', KNNImputer(n_neighbors=Number_Neighbors, weights='uniform', metric='nan_euclidean'))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Basic_nan_count\n",
       "0    3168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have complete information for the basic demographics variables, age and gender.\n",
    "\n",
    "Basic_Demos = [col for col in train_imp_KNN.columns if 'Basic' in col]\n",
    "Basic_Demos.remove('Basic_Demos-Enroll_Season')\n",
    "train_imp_KNN['Basic_nan_count'] = train_imp_KNN[Basic_Demos].isna().sum(axis=1)\n",
    "train_imp_KNN['Basic_nan_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical_nan_count\n",
      "1    1663\n",
      "7     716\n",
      "0     664\n",
      "6      45\n",
      "4      30\n",
      "3      27\n",
      "2      22\n",
      "5       1\n",
      "Name: count, dtype: int64\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#Next we'll consider the physical variables. There are many missing values here, including 688 cases with no values at all. We will do imputation.\n",
    "#Because age and gender are likely to be related to the Physical variables, I add these to the mix for imputation.\n",
    "#Note also that I have removed the season variable. I did this because it is not quantitative, so I can't easily run the imputation using this variable. \n",
    "#But this might be something to go back to later.\n",
    "\n",
    "Physical = [col for col in train_imp_KNN.columns if 'Physical' in col]\n",
    "Physical.remove('Physical-Season')\n",
    "Physical=Physical+Basic_Demos\n",
    "train_imp_KNN['Physical_nan_count'] = train_imp_KNN[Physical].isna().sum(axis=1)\n",
    "print(train_imp_KNN['Physical_nan_count'].value_counts())\n",
    "print(len(Physical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Physical-BMI                  3168 non-null   float64\n",
      " 1   Physical-Height               3168 non-null   float64\n",
      " 2   Physical-Weight               3168 non-null   float64\n",
      " 3   Physical-Waist_Circumference  3168 non-null   float64\n",
      " 4   Physical-Diastolic_BP         3168 non-null   float64\n",
      " 5   Physical-HeartRate            3168 non-null   float64\n",
      " 6   Physical-Systolic_BP          3168 non-null   float64\n",
      " 7   Basic_Demos-Age               3168 non-null   float64\n",
      " 8   Basic_Demos-Sex               3168 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 222.9 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for these variables. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[Physical]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "#Also, I reverse-transformed the data. My reasoning for doing this is that we want it in terms of the original scale to be able to make sense of things. \n",
    "#But since we are scaling twice, more rounding issues arise.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_physical=impute_pipe.transform(df)\n",
    "imputation_physical=impute_pipe.named_steps['scale'].inverse_transform(imputation_physical)\n",
    "df2 = pd.DataFrame(imputation_physical, columns=Physical)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[Physical]=train_imp_KNN[Physical].fillna(df2[Physical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness_nan_count\n",
      "17    1306\n",
      "3      649\n",
      "7      549\n",
      "4      433\n",
      "0      152\n",
      "5       24\n",
      "9       18\n",
      "8       10\n",
      "11       7\n",
      "12       6\n",
      "2        5\n",
      "14       3\n",
      "6        2\n",
      "13       2\n",
      "16       1\n",
      "15       1\n",
      "Name: count, dtype: int64\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#Next we'll consider the fitness test variables. \n",
    "# There are many missing values here, although it looks like we have at least some values for every case.\n",
    "#I kept in all of the zone variables, which means they have the same weight as the actual measurements. It seems like I shouldn't do this.\n",
    "\n",
    "Fitness = [col for col in train_imp_KNN.columns if 'Fitness' in col]+[col for col in train_imp_KNN.columns if 'FGC' in col]\n",
    "Fitness.remove('Fitness_Endurance-Season')\n",
    "Fitness.remove('FGC-Season')\n",
    "Fitness=Fitness+Basic_Demos\n",
    "train_imp_KNN['Fitness_nan_count'] = train_imp_KNN[Fitness].isna().sum(axis=1)\n",
    "print(train_imp_KNN['Fitness_nan_count'].value_counts())\n",
    "print(len(Fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 19 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Fitness_Endurance-Max_Stage  3168 non-null   float64\n",
      " 1   Fitness_Endurance-Time_Mins  3168 non-null   float64\n",
      " 2   Fitness_Endurance-Time_Sec   3168 non-null   float64\n",
      " 3   FGC-FGC_CU                   3168 non-null   float64\n",
      " 4   FGC-FGC_CU_Zone              3168 non-null   float64\n",
      " 5   FGC-FGC_GSND                 3168 non-null   float64\n",
      " 6   FGC-FGC_GSND_Zone            3168 non-null   float64\n",
      " 7   FGC-FGC_GSD                  3168 non-null   float64\n",
      " 8   FGC-FGC_GSD_Zone             3168 non-null   float64\n",
      " 9   FGC-FGC_PU                   3168 non-null   float64\n",
      " 10  FGC-FGC_PU_Zone              3168 non-null   float64\n",
      " 11  FGC-FGC_SRL                  3168 non-null   float64\n",
      " 12  FGC-FGC_SRL_Zone             3168 non-null   float64\n",
      " 13  FGC-FGC_SRR                  3168 non-null   float64\n",
      " 14  FGC-FGC_SRR_Zone             3168 non-null   float64\n",
      " 15  FGC-FGC_TL                   3168 non-null   float64\n",
      " 16  FGC-FGC_TL_Zone              3168 non-null   float64\n",
      " 17  Basic_Demos-Age              3168 non-null   float64\n",
      " 18  Basic_Demos-Sex              3168 non-null   float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 470.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for these variables. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[Fitness]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_fitness=impute_pipe.transform(df)\n",
    "imputation_fitness=impute_pipe.named_steps['scale'].inverse_transform(imputation_fitness)\n",
    "df2 = pd.DataFrame(imputation_fitness, columns=Fitness)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[Fitness]=train_imp_KNN[Fitness].fillna(df2[Fitness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIA_nan_count\n",
      "16    1575\n",
      "0     1527\n",
      "1       30\n",
      "2       21\n",
      "12       7\n",
      "3        5\n",
      "4        2\n",
      "5        1\n",
      "Name: count, dtype: int64\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#Next we'll consider the BIA variables. \n",
    "\n",
    "BIA = [col for col in train_imp_KNN.columns if 'BIA' in col]\n",
    "BIA.remove('BIA-Season')\n",
    "BIA=BIA+Basic_Demos\n",
    "train_imp_KNN['BIA_nan_count'] = train_imp_KNN[BIA].isna().sum(axis=1)\n",
    "print(train_imp_KNN['BIA_nan_count'].value_counts())\n",
    "print(len(BIA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 18 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   BIA-BIA_Activity_Level_num  3168 non-null   float64\n",
      " 1   BIA-BIA_BMC                 3168 non-null   float64\n",
      " 2   BIA-BIA_BMI                 3168 non-null   float64\n",
      " 3   BIA-BIA_BMR                 3168 non-null   float64\n",
      " 4   BIA-BIA_DEE                 3168 non-null   float64\n",
      " 5   BIA-BIA_ECW                 3168 non-null   float64\n",
      " 6   BIA-BIA_FFM                 3168 non-null   float64\n",
      " 7   BIA-BIA_FFMI                3168 non-null   float64\n",
      " 8   BIA-BIA_FMI                 3168 non-null   float64\n",
      " 9   BIA-BIA_Fat                 3168 non-null   float64\n",
      " 10  BIA-BIA_Frame_num           3168 non-null   float64\n",
      " 11  BIA-BIA_ICW                 3168 non-null   float64\n",
      " 12  BIA-BIA_LDM                 3168 non-null   float64\n",
      " 13  BIA-BIA_LST                 3168 non-null   float64\n",
      " 14  BIA-BIA_SMM                 3168 non-null   float64\n",
      " 15  BIA-BIA_TBW                 3168 non-null   float64\n",
      " 16  Basic_Demos-Age             3168 non-null   float64\n",
      " 17  Basic_Demos-Sex             3168 non-null   float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 445.6 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for these variables. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[BIA]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_BIA=impute_pipe.transform(df)\n",
    "imputation_BIA=impute_pipe.named_steps['scale'].inverse_transform(imputation_BIA)\n",
    "df2 = pd.DataFrame(imputation_BIA, columns=BIA)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[BIA]=train_imp_KNN[BIA].fillna(df2[BIA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGAS_nan_count\n",
      "0    1950\n",
      "1    1218\n",
      "Name: count, dtype: int64\n",
      "3\n",
      "['CGAS-CGAS_Score', 'Basic_Demos-Age', 'Basic_Demos-Sex']\n"
     ]
    }
   ],
   "source": [
    "#Next we consider CGAS (Children's Global Assessment Score). This measure comes from an evaluation by a trained professional. \n",
    "#Looking at the description, it seems reasonable that it is related to gender and age, so I am going to do KNN with those variables. \n",
    "\n",
    "CGAS = ['CGAS-CGAS_Score']+Basic_Demos\n",
    "train_imp_KNN['CGAS_nan_count'] = train_imp_KNN[CGAS].isna().sum(axis=1)\n",
    "print(train_imp_KNN['CGAS_nan_count'].value_counts())\n",
    "print(len(CGAS))\n",
    "print(CGAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CGAS-CGAS_Score  3168 non-null   float64\n",
      " 1   Basic_Demos-Age  3168 non-null   float64\n",
      " 2   Basic_Demos-Sex  3168 non-null   float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 74.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for this variable. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[CGAS]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_CGAS=impute_pipe.transform(df)\n",
    "imputation_CGAS=impute_pipe.named_steps['scale'].inverse_transform(imputation_CGAS)\n",
    "df2 = pd.DataFrame(imputation_CGAS, columns=CGAS)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[CGAS]=train_imp_KNN[CGAS].fillna(df2[CGAS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntHrs_nan_count\n",
      "0    2633\n",
      "1     535\n",
      "Name: count, dtype: int64\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Next we consider  PreInt_EduHx-computerinternet_hoursday. \n",
    "#It seems reasonable that it is related to gender and age, so I am going to do KNN with those variables. \n",
    "\n",
    "IntHrs = ['PreInt_EduHx-computerinternet_hoursday']+Basic_Demos\n",
    "train_imp_KNN['IntHrs_nan_count'] = train_imp_KNN[IntHrs].isna().sum(axis=1)\n",
    "print(train_imp_KNN['IntHrs_nan_count'].value_counts())\n",
    "print(len(IntHrs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   PreInt_EduHx-computerinternet_hoursday  3168 non-null   float64\n",
      " 1   Basic_Demos-Age                         3168 non-null   float64\n",
      " 2   Basic_Demos-Sex                         3168 non-null   float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 74.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for this variable. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[IntHrs]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_IntHrs=impute_pipe.transform(df)\n",
    "imputation_IntHrs=impute_pipe.named_steps['scale'].inverse_transform(imputation_IntHrs)\n",
    "df2 = pd.DataFrame(imputation_IntHrs, columns=IntHrs)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[IntHrs]=train_imp_KNN[IntHrs].fillna(df2[IntHrs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the file focus on imputing values for the PCIAT questionaire, based on other responses to the questionaire, using k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN rates in original data:  pciatsnotna_sum\n",
      "20    2130\n",
      "0      974\n",
      "19      52\n",
      "18       9\n",
      "10       1\n",
      "15       1\n",
      "17       1\n",
      "Name: count, dtype: int64\n",
      "NaN rates after the non-responders have been removed: pciatsnotna_sum\n",
      "20    2130\n",
      "19      52\n",
      "18       9\n",
      "10       1\n",
      "15       1\n",
      "17       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#First we identify the columns of interest to search for NaN variables.\n",
    "\n",
    "pciats = [col for col in train_imp_KNN.columns if 'PCIAT' in col]\n",
    "pciats.remove('PCIAT-Season')\n",
    "pciats.remove('PCIAT-PCIAT_Total')\n",
    "\n",
    "# Create 20 new variables that indicate whether or not PCIAT-PCIAT_01 through PCIAT-PCIAT_20 were NaN\n",
    "\n",
    "for pciat in pciats:\n",
    "    train_imp_KNN[pciat + '_isnotna'] = train_imp_KNN[pciat].notna().astype(int)\n",
    "\n",
    "    \n",
    "\n",
    "#Create new variable that represents the sum of the questions answered.\n",
    "\n",
    "pciatsnotna = [col for col in train_imp_KNN.columns if 'isnotna' in col]\n",
    "train_imp_KNN['pciatsnotna_sum'] = train_imp_KNN[pciatsnotna].sum(axis=1)\n",
    "\n",
    "#Here, we can see NaN rates. Note that there are almost 1000 cases where the participants did not respond to any PCIAT questions. \n",
    "#These participants are eliminated. Note that when rows are eliminated, the original row indexing is preserved; therefore, I reset the index. \n",
    "#(This step is important to make sure indices match up when I later replace NaN entries with their imputed values.)\n",
    "\n",
    "print(\"NaN rates in original data: \",train_imp_KNN['pciatsnotna_sum'].value_counts())\n",
    "train_imp_KNN = train_imp_KNN[train_imp_KNN['pciatsnotna_sum'] != 0]\n",
    "train_imp_KNN.reset_index(drop=True, inplace=True)\n",
    "print(\"NaN rates after the non-responders have been removed:\",train_imp_KNN['pciatsnotna_sum'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we use KNN to impute the missing values.\n",
    "\n",
    "\n",
    "# define imputer\n",
    "Number_Neighbors=5\n",
    "imputer = KNNImputer(n_neighbors=Number_Neighbors, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "#The imputer.fit_transform function outputs a numpy array. So first I do the fitting, then convert the output back to a pandas dataframe.\n",
    "\n",
    "imputations=imputer.fit_transform(train_imp_KNN[pciats])\n",
    "df2 = pd.DataFrame(imputations, columns=pciats)\n",
    "\n",
    "#Next take the result and insert into the original dataframe. \n",
    "\n",
    "train_imp_KNN[pciats]=train_imp_KNN[pciats].fillna(df2[pciats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2194 entries, 0 to 2193\n",
      "Data columns (total 90 columns):\n",
      " #   Column                                  Non-Null Count  Dtype   \n",
      "---  ------                                  --------------  -----   \n",
      " 0   id                                      2194 non-null   object  \n",
      " 1   Basic_Demos-Enroll_Season               2194 non-null   object  \n",
      " 2   Basic_Demos-Age                         2194 non-null   int64   \n",
      " 3   Basic_Demos-Sex                         2194 non-null   int64   \n",
      " 4   CGAS-Season                             1893 non-null   object  \n",
      " 5   CGAS-CGAS_Score                         2194 non-null   float64 \n",
      " 6   Physical-Season                         2074 non-null   object  \n",
      " 7   Physical-BMI                            2194 non-null   float64 \n",
      " 8   Physical-Height                         2194 non-null   float64 \n",
      " 9   Physical-Weight                         2194 non-null   float64 \n",
      " 10  Physical-Waist_Circumference            2194 non-null   float64 \n",
      " 11  Physical-Diastolic_BP                   2194 non-null   float64 \n",
      " 12  Physical-HeartRate                      2194 non-null   float64 \n",
      " 13  Physical-Systolic_BP                    2194 non-null   float64 \n",
      " 14  Fitness_Endurance-Season                1019 non-null   object  \n",
      " 15  Fitness_Endurance-Max_Stage             2194 non-null   float64 \n",
      " 16  Fitness_Endurance-Time_Mins             2194 non-null   float64 \n",
      " 17  Fitness_Endurance-Time_Sec              2194 non-null   float64 \n",
      " 18  FGC-Season                              2122 non-null   object  \n",
      " 19  FGC-FGC_CU                              2194 non-null   float64 \n",
      " 20  FGC-FGC_CU_Zone                         2194 non-null   float64 \n",
      " 21  FGC-FGC_GSND                            2194 non-null   float64 \n",
      " 22  FGC-FGC_GSND_Zone                       2194 non-null   float64 \n",
      " 23  FGC-FGC_GSD                             2194 non-null   float64 \n",
      " 24  FGC-FGC_GSD_Zone                        2194 non-null   float64 \n",
      " 25  FGC-FGC_PU                              2194 non-null   float64 \n",
      " 26  FGC-FGC_PU_Zone                         2194 non-null   float64 \n",
      " 27  FGC-FGC_SRL                             2194 non-null   float64 \n",
      " 28  FGC-FGC_SRL_Zone                        2194 non-null   float64 \n",
      " 29  FGC-FGC_SRR                             2194 non-null   float64 \n",
      " 30  FGC-FGC_SRR_Zone                        2194 non-null   float64 \n",
      " 31  FGC-FGC_TL                              2194 non-null   float64 \n",
      " 32  FGC-FGC_TL_Zone                         2194 non-null   float64 \n",
      " 33  BIA-Season                              1475 non-null   object  \n",
      " 34  BIA-BIA_Activity_Level_num              2194 non-null   float64 \n",
      " 35  BIA-BIA_BMC                             2194 non-null   float64 \n",
      " 36  BIA-BIA_BMI                             2194 non-null   float64 \n",
      " 37  BIA-BIA_BMR                             2194 non-null   float64 \n",
      " 38  BIA-BIA_DEE                             2194 non-null   float64 \n",
      " 39  BIA-BIA_ECW                             2194 non-null   float64 \n",
      " 40  BIA-BIA_FFM                             2194 non-null   float64 \n",
      " 41  BIA-BIA_FFMI                            2194 non-null   float64 \n",
      " 42  BIA-BIA_FMI                             2194 non-null   float64 \n",
      " 43  BIA-BIA_Fat                             2194 non-null   float64 \n",
      " 44  BIA-BIA_Frame_num                       2194 non-null   float64 \n",
      " 45  BIA-BIA_ICW                             2194 non-null   float64 \n",
      " 46  BIA-BIA_LDM                             2194 non-null   float64 \n",
      " 47  BIA-BIA_LST                             2194 non-null   float64 \n",
      " 48  BIA-BIA_SMM                             2194 non-null   float64 \n",
      " 49  BIA-BIA_TBW                             2194 non-null   float64 \n",
      " 50  PAQ_A-Season                            289 non-null    object  \n",
      " 51  PAQ_A-PAQ_A_Total                       289 non-null    float64 \n",
      " 52  PAQ_C-Season                            1153 non-null   object  \n",
      " 53  PAQ_C-PAQ_C_Total                       1153 non-null   float64 \n",
      " 54  PCIAT-Season                            2194 non-null   object  \n",
      " 55  PCIAT-PCIAT_01                          2194 non-null   float64 \n",
      " 56  PCIAT-PCIAT_02                          2194 non-null   float64 \n",
      " 57  PCIAT-PCIAT_03                          2194 non-null   float64 \n",
      " 58  PCIAT-PCIAT_04                          2194 non-null   float64 \n",
      " 59  PCIAT-PCIAT_05                          2194 non-null   float64 \n",
      " 60  PCIAT-PCIAT_06                          2194 non-null   float64 \n",
      " 61  PCIAT-PCIAT_07                          2194 non-null   float64 \n",
      " 62  PCIAT-PCIAT_08                          2194 non-null   float64 \n",
      " 63  PCIAT-PCIAT_09                          2194 non-null   float64 \n",
      " 64  PCIAT-PCIAT_10                          2194 non-null   float64 \n",
      " 65  PCIAT-PCIAT_11                          2194 non-null   float64 \n",
      " 66  PCIAT-PCIAT_12                          2194 non-null   float64 \n",
      " 67  PCIAT-PCIAT_13                          2194 non-null   float64 \n",
      " 68  PCIAT-PCIAT_14                          2194 non-null   float64 \n",
      " 69  PCIAT-PCIAT_15                          2194 non-null   float64 \n",
      " 70  PCIAT-PCIAT_16                          2194 non-null   float64 \n",
      " 71  PCIAT-PCIAT_17                          2194 non-null   float64 \n",
      " 72  PCIAT-PCIAT_18                          2194 non-null   float64 \n",
      " 73  PCIAT-PCIAT_19                          2194 non-null   float64 \n",
      " 74  PCIAT-PCIAT_20                          2194 non-null   float64 \n",
      " 75  PCIAT-PCIAT_Total                       2194 non-null   float64 \n",
      " 76  SDS-Season                              2028 non-null   object  \n",
      " 77  SDS-SDS_Total_Raw                       2027 non-null   float64 \n",
      " 78  SDS-SDS_Total_T                         2026 non-null   float64 \n",
      " 79  PreInt_EduHx-Season                     2179 non-null   object  \n",
      " 80  PreInt_EduHx-computerinternet_hoursday  2194 non-null   float64 \n",
      " 81  sii                                     2194 non-null   float64 \n",
      " 82  Basic_nan_count                         2194 non-null   int64   \n",
      " 83  Physical_nan_count                      2194 non-null   int64   \n",
      " 84  Fitness_nan_count                       2194 non-null   int64   \n",
      " 85  BIA_nan_count                           2194 non-null   int64   \n",
      " 86  CGAS_nan_count                          2194 non-null   int64   \n",
      " 87  IntHrs_nan_count                        2194 non-null   int64   \n",
      " 88  PCIAT_Total_Imputed                     2194 non-null   float64 \n",
      " 89  sii_Imputed                             2194 non-null   category\n",
      "dtypes: category(1), float64(69), int64(8), object(12)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#I recalculate the PCIAT total score. I also drop the variables that were added to detect NaN in the PCIAT data, just to tidy up a bit.\n",
    "\n",
    "train_imp_KNN['PCIAT_Total_Imputed'] = train_imp_KNN[pciats].sum(axis=1)\n",
    "train_imp_KNN = train_imp_KNN.drop(columns=pciatsnotna)\n",
    "train_imp_KNN = train_imp_KNN.drop(columns=['pciatsnotna_sum'])\n",
    "\n",
    "\n",
    "#Now we can calculate a new sii score with the imputed values. \n",
    "\n",
    "bins = [0, 30, 49,79,100]\n",
    "labels = [0,1,2,3]\n",
    "train_imp_KNN['sii_Imputed'] = pd.cut(train_imp_KNN['PCIAT_Total_Imputed'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "print(train_imp_KNN.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imp_KNN.to_csv('train_imp_KNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'm working on imputation using MICE. As you'll see below, I will use MICE to impute the missing input values, provided the variables are quantitative or categorical binary or ordinal (which are treated as integers in the data). This doesn't necessarily seem like the best idea for the ordinal data. Also, imputation can't directly handle non-ordinal categorical variables with more than 2 categories. In this case, the issue only affects seasons. I could work around this, but for now I just ignored these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
      "       'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
      "       'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
      "       'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
      "       'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
      "       'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
      "       'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
      "       'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
      "       'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
      "       'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
      "       'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
      "       'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
      "       'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
      "       'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
      "       'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
      "       'PAQ_C-PAQ_C_Total', 'PCIAT-Season', 'PCIAT-PCIAT_01', 'PCIAT-PCIAT_02',\n",
      "       'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06',\n",
      "       'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10',\n",
      "       'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14',\n",
      "       'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18',\n",
      "       'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total', 'SDS-Season',\n",
      "       'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
      "       'PreInt_EduHx-computerinternet_hoursday', 'sii'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# I am going to define a new dataframe that will record all of the imputations using MICE. I only want to apply MICE to the input variables, so I separate those out.\n",
    "#Also, MICE doesn't like categorical variables. I have just removed those--the seasons--for now.\n",
    "\n",
    "train_imp_MICE=train_cleaned.copy()\n",
    "\n",
    "print(train_imp_MICE.columns)\n",
    "\n",
    "features=['Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "        'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "       'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "       'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "        'Fitness_Endurance-Max_Stage',\n",
    "       'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "        'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "       'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "       'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "       'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', \n",
    "       'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "       'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "       'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "       'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "       'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total', \n",
    "       'PAQ_C-PAQ_C_Total',\n",
    "       'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', \n",
    "       'PreInt_EduHx-computerinternet_hoursday']\n",
    "\n",
    "df=train_imp_MICE[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New packages needed.\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IterativeImputer has a bunch of options, including what type of regression is used for the imputation. Here, I've just gone with the default.\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=497)\n",
    "\n",
    "df2= imputer.fit_transform(df)\n",
    "\n",
    "df3 = pd.DataFrame(df2, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I fill in the missing values in train_imp_MICE with the MICE-imputed values. I am still using KNN for the pciats values. \n",
    "\n",
    "train_imp_MICE[features]=train_imp_MICE[features].fillna(df3[features])\n",
    "train_imp_MICE[pciats]=train_imp_KNN[pciats]\n",
    "train_imp_MICE['PCIAT_Total_Imputed']=train_imp_KNN['PCIAT_Total_Imputed']\n",
    "train_imp_MICE['sii_Imputed']=train_imp_KNN['sii_Imputed']\n",
    "\n",
    "#Now I can export to a csv.\n",
    "\n",
    "train_imp_MICE.to_csv('train_imp_MICE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 84 columns):\n",
      " #   Column                                  Non-Null Count  Dtype   \n",
      "---  ------                                  --------------  -----   \n",
      " 0   id                                      3168 non-null   object  \n",
      " 1   Basic_Demos-Enroll_Season               3168 non-null   object  \n",
      " 2   Basic_Demos-Age                         3168 non-null   int64   \n",
      " 3   Basic_Demos-Sex                         3168 non-null   int64   \n",
      " 4   CGAS-Season                             2065 non-null   object  \n",
      " 5   CGAS-CGAS_Score                         3168 non-null   float64 \n",
      " 6   Physical-Season                         2642 non-null   object  \n",
      " 7   Physical-BMI                            3168 non-null   float64 \n",
      " 8   Physical-Height                         3168 non-null   float64 \n",
      " 9   Physical-Weight                         3168 non-null   float64 \n",
      " 10  Physical-Waist_Circumference            3168 non-null   float64 \n",
      " 11  Physical-Diastolic_BP                   3168 non-null   float64 \n",
      " 12  Physical-HeartRate                      3168 non-null   float64 \n",
      " 13  Physical-Systolic_BP                    3168 non-null   float64 \n",
      " 14  Fitness_Endurance-Season                1060 non-null   object  \n",
      " 15  Fitness_Endurance-Max_Stage             3168 non-null   float64 \n",
      " 16  Fitness_Endurance-Time_Mins             3168 non-null   float64 \n",
      " 17  Fitness_Endurance-Time_Sec              3168 non-null   float64 \n",
      " 18  FGC-Season                              2674 non-null   object  \n",
      " 19  FGC-FGC_CU                              3168 non-null   float64 \n",
      " 20  FGC-FGC_CU_Zone                         3168 non-null   float64 \n",
      " 21  FGC-FGC_GSND                            3168 non-null   float64 \n",
      " 22  FGC-FGC_GSND_Zone                       3168 non-null   float64 \n",
      " 23  FGC-FGC_GSD                             3168 non-null   float64 \n",
      " 24  FGC-FGC_GSD_Zone                        3168 non-null   float64 \n",
      " 25  FGC-FGC_PU                              3168 non-null   float64 \n",
      " 26  FGC-FGC_PU_Zone                         3168 non-null   float64 \n",
      " 27  FGC-FGC_SRL                             3168 non-null   float64 \n",
      " 28  FGC-FGC_SRL_Zone                        3168 non-null   float64 \n",
      " 29  FGC-FGC_SRR                             3168 non-null   float64 \n",
      " 30  FGC-FGC_SRR_Zone                        3168 non-null   float64 \n",
      " 31  FGC-FGC_TL                              3168 non-null   float64 \n",
      " 32  FGC-FGC_TL_Zone                         3168 non-null   float64 \n",
      " 33  BIA-Season                              1712 non-null   object  \n",
      " 34  BIA-BIA_Activity_Level_num              3168 non-null   float64 \n",
      " 35  BIA-BIA_BMC                             3168 non-null   float64 \n",
      " 36  BIA-BIA_BMI                             3168 non-null   float64 \n",
      " 37  BIA-BIA_BMR                             3168 non-null   float64 \n",
      " 38  BIA-BIA_DEE                             3168 non-null   float64 \n",
      " 39  BIA-BIA_ECW                             3168 non-null   float64 \n",
      " 40  BIA-BIA_FFM                             3168 non-null   float64 \n",
      " 41  BIA-BIA_FFMI                            3168 non-null   float64 \n",
      " 42  BIA-BIA_FMI                             3168 non-null   float64 \n",
      " 43  BIA-BIA_Fat                             3168 non-null   float64 \n",
      " 44  BIA-BIA_Frame_num                       3168 non-null   float64 \n",
      " 45  BIA-BIA_ICW                             3168 non-null   float64 \n",
      " 46  BIA-BIA_LDM                             3168 non-null   float64 \n",
      " 47  BIA-BIA_LST                             3168 non-null   float64 \n",
      " 48  BIA-BIA_SMM                             3168 non-null   float64 \n",
      " 49  BIA-BIA_TBW                             3168 non-null   float64 \n",
      " 50  PAQ_A-Season                            382 non-null    object  \n",
      " 51  PAQ_A-PAQ_A_Total                       3168 non-null   float64 \n",
      " 52  PAQ_C-Season                            1373 non-null   object  \n",
      " 53  PAQ_C-PAQ_C_Total                       3168 non-null   float64 \n",
      " 54  PCIAT-Season                            2195 non-null   object  \n",
      " 55  PCIAT-PCIAT_01                          2194 non-null   float64 \n",
      " 56  PCIAT-PCIAT_02                          2194 non-null   float64 \n",
      " 57  PCIAT-PCIAT_03                          2194 non-null   float64 \n",
      " 58  PCIAT-PCIAT_04                          2194 non-null   float64 \n",
      " 59  PCIAT-PCIAT_05                          2194 non-null   float64 \n",
      " 60  PCIAT-PCIAT_06                          2194 non-null   float64 \n",
      " 61  PCIAT-PCIAT_07                          2194 non-null   float64 \n",
      " 62  PCIAT-PCIAT_08                          2194 non-null   float64 \n",
      " 63  PCIAT-PCIAT_09                          2194 non-null   float64 \n",
      " 64  PCIAT-PCIAT_10                          2194 non-null   float64 \n",
      " 65  PCIAT-PCIAT_11                          2194 non-null   float64 \n",
      " 66  PCIAT-PCIAT_12                          2194 non-null   float64 \n",
      " 67  PCIAT-PCIAT_13                          2194 non-null   float64 \n",
      " 68  PCIAT-PCIAT_14                          2194 non-null   float64 \n",
      " 69  PCIAT-PCIAT_15                          2194 non-null   float64 \n",
      " 70  PCIAT-PCIAT_16                          2194 non-null   float64 \n",
      " 71  PCIAT-PCIAT_17                          2194 non-null   float64 \n",
      " 72  PCIAT-PCIAT_18                          2194 non-null   float64 \n",
      " 73  PCIAT-PCIAT_19                          2194 non-null   float64 \n",
      " 74  PCIAT-PCIAT_20                          2194 non-null   float64 \n",
      " 75  PCIAT-PCIAT_Total                       2195 non-null   float64 \n",
      " 76  SDS-Season                              2103 non-null   object  \n",
      " 77  SDS-SDS_Total_Raw                       3168 non-null   float64 \n",
      " 78  SDS-SDS_Total_T                         3168 non-null   float64 \n",
      " 79  PreInt_EduHx-Season                     2823 non-null   object  \n",
      " 80  PreInt_EduHx-computerinternet_hoursday  3168 non-null   float64 \n",
      " 81  sii                                     2195 non-null   float64 \n",
      " 82  PCIAT_Total_Imputed                     2194 non-null   float64 \n",
      " 83  sii_Imputed                             2194 non-null   category\n",
      "dtypes: category(1), float64(69), int64(2), object(12)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#We have now imputed all missing data except for seasons.\n",
    " \n",
    "train_imp_MICE.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
