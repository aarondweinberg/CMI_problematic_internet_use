{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Neural Regression to Predict Ordinal Outcomes**\n",
    "\n",
    "It looks like we could also use \"neural regression\" (PyTorch) to do the prediction. \n",
    "\n",
    "Here is a website that describes how to accomplish this: https://visualstudiomagazine.com/articles/2021/10/04/ordinal-classification-pytorch.aspx\n",
    "\n",
    "The code below is copied from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# house_price_ord.py\n",
    "# predict ordinal price from AC, sq ft, style, nearest school\n",
    "# PyTorch 1.8.0-CPU Anaconda3-2020.02  Python 3.7.6\n",
    "# Windows 10 \n",
    "\n",
    "import numpy as np\n",
    "import torch as T\n",
    "device = T.device(\"cpu\")  # apply to Tensor or Module\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class HouseDataset(T.utils.data.Dataset):\n",
    "  # AC  sq ft   style  price   school\n",
    "  # -1  0.2500  0 1 0    3     0 1 0\n",
    "  #  1  0.1275  1 0 0    2     0 0 1\n",
    "  # air condition: -1 = no, +1 = yes\n",
    "  # style: art_deco, bungalow, colonial\n",
    "  # price: k=4: 0 = low, 1 = medium, 2 = high, 3 = very high\n",
    "  # school: johnson, kennedy, lincoln\n",
    "\n",
    "  def __init__(self, src_file, k):\n",
    "    # k for programmtic approach\n",
    "    all_xy = np.loadtxt(src_file, \n",
    "      usecols=[0,1,2,3,4,5,6,7,8], delimiter=\"\\t\",\n",
    "      comments=\"#\", skiprows=0, dtype=np.float32)\n",
    "\n",
    "    tmp_x = all_xy[:,[0,1,2,3,4,6,7,8]]\n",
    "    tmp_y = all_xy[:,5]    # 1D -- 2D will be required\n",
    "\n",
    "    n = len(tmp_y)\n",
    "    for i in range(n):  # hard-coded is easy to understand\n",
    "      if int(tmp_y[i])   == 0: tmp_y[i] = 0.125\n",
    "      elif int(tmp_y[i]) == 1: tmp_y[i] = 0.375\n",
    "      elif int(tmp_y[i]) == 2: tmp_y[i] = 0.625\n",
    "      elif int(tmp_y[i]) == 3: tmp_y[i] = 0.875\n",
    "      else: print(\"Fatal logic error \")\n",
    "\n",
    "    tmp_y = np.reshape(tmp_y, (-1,1))  # 2D    \n",
    "\n",
    "    self.x_data = T.tensor(tmp_x, \\\n",
    "      dtype=T.float32).to(device)\n",
    "    self.y_data = T.tensor(tmp_y, \\\n",
    "      dtype=T.float32).to(device)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    preds = self.x_data[idx,:]  # or just [idx]\n",
    "    price = self.y_data[idx,:] \n",
    "    return (preds, price)       # tuple of two matrices \n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.hid1 = T.nn.Linear(8, 10)  # 8-(10-10)-1\n",
    "    self.hid2 = T.nn.Linear(10, 10)\n",
    "    self.oupt = T.nn.Linear(10, 1)  # [0.0 to 1.0]\n",
    "\n",
    "    T.nn.init.xavier_uniform_(self.hid1.weight)\n",
    "    T.nn.init.zeros_(self.hid1.bias)\n",
    "    T.nn.init.xavier_uniform_(self.hid2.weight)\n",
    "    T.nn.init.zeros_(self.hid2.bias)\n",
    "    T.nn.init.xavier_uniform_(self.oupt.weight)\n",
    "    T.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = T.tanh(self.hid1(x))\n",
    "    z = T.tanh(self.hid2(z))\n",
    "    z = T.sigmoid(self.oupt(z))  # \n",
    "    return z\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def accuracy(model, ds, k):\n",
    "  n_correct = 0; n_wrong = 0\n",
    "  acc_delta = (1.0 / k) / 2   # if k=4 delta = 0.125\n",
    "  for i in range(len(ds)):    # each input\n",
    "    (X, y) = ds[i]            # (predictors, target)\n",
    "    with T.no_grad():         # y target is like 0.375\n",
    "      oupt = model(X)         # oupt is in [0.0, 1.0]\n",
    "\n",
    "    if T.abs(oupt - y) <= acc_delta:\n",
    "      n_correct += 1\n",
    "    else:\n",
    "      n_wrong += 1\n",
    "\n",
    "  acc = (n_correct * 1.0) / (n_correct + n_wrong)\n",
    "  return acc\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def accuracy_old(model, ds, k):\n",
    "  model.eval()\n",
    "  n_correct = 0; n_wrong = 0\n",
    "  for i in range(len(ds)):\n",
    "    (X, Y) = ds[i]            # (predictors, target)\n",
    "    with T.no_grad():\n",
    "      oupt = model(X)         # computed is in 0.0 to 1.0\n",
    "    if oupt >= 0.0 and oupt < 0.25 and Y == 0.125:  # ugly\n",
    "      n_correct += 1\n",
    "    elif oupt >= 0.25 and oupt < 0.50 and Y == 0.375:\n",
    "      n_correct += 1\n",
    "    elif oupt >= 0.50 and oupt < 0.75 and Y == 0.625:\n",
    "      n_correct += 1\n",
    "    elif oupt >= 0.75 and Y == 0.875:\n",
    "      n_correct += 1\n",
    "    else:\n",
    "      n_wrong += 1\n",
    "  acc = (n_correct * 1.0) / (n_correct + n_wrong)\n",
    "  return acc\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def train(net, ds, bs, lr, me, le):\n",
    "  # network, dataset, batch_size, learn_rate, \n",
    "  # max_epochs, log_every\n",
    "  train_ldr = T.utils.data.DataLoader(ds,\n",
    "    batch_size=bs, shuffle=True)\n",
    "  loss_func = T.nn.MSELoss()\n",
    "  opt = T.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "  for epoch in range(0, me):\n",
    "    # T.manual_seed(1+epoch)  # recovery reproducibility\n",
    "    epoch_loss = 0  # for one full epoch\n",
    "\n",
    "    for (b_idx, batch) in enumerate(train_ldr):\n",
    "      (X, y) = batch           # (predictors, targets)\n",
    "      opt.zero_grad()          # prepare gradients\n",
    "      oupt = net(X)            # predicted prices\n",
    "\n",
    "      loss_val = loss_func(oupt, y)  # a tensor\n",
    "      epoch_loss += loss_val.item()  # accumulate\n",
    "      loss_val.backward()  # compute gradients\n",
    "      opt.step()           # update weights\n",
    "\n",
    "    if epoch % le == 0:\n",
    "      print(\"epoch = %4d   loss = %0.4f\" % \\\n",
    "       (epoch, epoch_loss))\n",
    "      # TODO: save checkpoint\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def float_oupt_to_class(oupt, k):\n",
    "  end_pts = np.zeros(k+1, dtype=np.float32) \n",
    "  delta = 1.0 / k\n",
    "  for i in range(k):\n",
    "    end_pts[i] = i * delta\n",
    "  end_pts[k] = 1.0\n",
    "  # if k=4, [0.0, 0.25, 0.50, 0.75, 1.0] \n",
    "\n",
    "  for i in range(k):\n",
    "    if oupt >= end_pts[i] and oupt <= end_pts[i+1]:\n",
    "      return i\n",
    "  return -1  # fatal error \n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "  # 0. get started\n",
    "  print(\"\\nBegin predict House ordinal price \\n\")\n",
    "  T.manual_seed(1)  # representative results \n",
    "  np.random.seed(1)\n",
    "  \n",
    "  # 1. create Dataset objects\n",
    "  print(\"Creating Houses Dataset objects \")\n",
    "  print(\"Converting ordinal labels to float targets \")\n",
    "  train_file = \".\\\\Data\\\\houses_train_ord.txt\"\n",
    "  train_ds = HouseDataset(train_file, k=4)  # 200 rows\n",
    "\n",
    "  test_file = \".\\\\Data\\\\houses_test_ord.txt\"\n",
    "  test_ds = HouseDataset(test_file, k=4)  # 40 rows\n",
    "\n",
    "  # 2. create network\n",
    "  print(\"\\nCreating 8-10-10-1 neural network \")\n",
    "  net = Net().to(device)\n",
    "  net.train()   # set mode\n",
    "\n",
    "  # 3. train model\n",
    "  bat_size = 10\n",
    "  lrn_rate = 0.010\n",
    "  max_epochs = 500\n",
    "  log_every = 100\n",
    "\n",
    "  print(\"\\nbat_size = %3d \" % bat_size)\n",
    "  print(\"lrn_rate = %0.3f \" % lrn_rate)\n",
    "  print(\"loss = MSELoss \")\n",
    "  print(\"optimizer = Adam \")\n",
    "  print(\"max_epochs = %3d \" % max_epochs)\n",
    "\n",
    "  print(\"\\nStarting training \")\n",
    "  train(net, train_ds, bat_size, lrn_rate, \n",
    "    max_epochs, log_every)\n",
    "  print(\"Training complete \")\n",
    "\n",
    "  # 4. evaluate model accuracy\n",
    "  print(\"\\nComputing model accuracy\")\n",
    "  net.eval()  # set mode\n",
    "  acc_train = accuracy(net, train_ds, k=4) \n",
    "  print(\"Accuracy on train data = %0.4f\" % \\\n",
    "    acc_train)\n",
    "\n",
    "  acc_test = accuracy(net, test_ds, k=4) \n",
    "  print(\"Accuracy on test data  = %0.4f\" % \\\n",
    "    acc_test)\n",
    "\n",
    "  # 5. save trained model (TODO)\n",
    "  print(\"\\nSaving trained model as houses_model.h5 \")\n",
    "  # model.save_weights(\".\\\\Models\\\\houses_model_wts.h5\")\n",
    "  # model.save(\".\\\\Models\\\\houses_model.h5\")\n",
    "\n",
    "  # 6. make a prediction\n",
    "  print(\"\\nPredicting house price for AC=no, sqft=2300, \")\n",
    "  print(\" style=colonial, school=kennedy: \")\n",
    "  unk = np.array([[-1, 0.2300,  0,0,1,  0,1,0]],\n",
    "    dtype=np.float32)\n",
    "  unk = T.tensor(unk, dtype=T.float32).to(device) \n",
    "\n",
    "  with T.no_grad():\n",
    "    pred_price = net(unk)\n",
    "  pred_price = pred_price.item()  # scalar 0.0 to 1.0\n",
    "  print(\"\\nPredicted price raw output: %0.4f\" % \\\n",
    "    pred_price)\n",
    "\n",
    "  labels = [\"low\", \"medium\", \"high\", \"very high\"]\n",
    "  c = float_oupt_to_class(pred_price, k=4)\n",
    "  print(\"Predicted price ordinal label: %d \" % c)\n",
    "  print(\"Predicted price friendly class: %s \" % \\\n",
    "    labels[c])\n",
    "\n",
    "  print(\"\\nEnd House ordinal price demo\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "\n",
    "# ===========\n",
    "# houses_train_ord.txt\n",
    "# AC (-1 = no), sq_ft, style (one-hot)\n",
    "# price (0=low, 1=med, 2=high, 3=v. high), \n",
    "# school (one-hot)\n",
    "#   -1   0.1275   0   1   0   0   0   0   1\n",
    "#    1   0.1100   1   0   0   0   1   0   0\n",
    "#   -1   0.1375   0   0   1   0   0   1   0\n",
    "#    1   0.1975   0   1   0   2   0   0   1\n",
    "#   -1   0.1200   0   0   1   0   1   0   0\n",
    "#   -1   0.2500   0   1   0   2   0   1   0\n",
    "#    1   0.1275   1   0   0   1   0   0   1\n",
    "#   -1   0.1750   0   0   1   1   0   0   1\n",
    "#   -1   0.2500   0   1   0   2   0   0   1\n",
    "#    1   0.1800   0   1   0   1   1   0   0\n",
    "#    1   0.0975   1   0   0   0   0   0   1\n",
    "#   -1   0.1100   0   1   0   0   0   1   0\n",
    "#    1   0.1975   0   0   1   1   0   0   1\n",
    "#   -1   0.3175   1   0   0   3   0   1   0\n",
    "#   -1   0.1700   0   1   0   1   1   0   0\n",
    "#    1   0.1650   0   1   0   1   0   1   0\n",
    "#   -1   0.2250   0   1   0   2   0   1   0\n",
    "#   -1   0.2125   0   1   0   2   0   1   0\n",
    "#    1   0.1675   0   1   0   1   0   1   0\n",
    "#    1   0.1550   1   0   0   1   0   1   0\n",
    "#   -1   0.1375   0   0   1   0   1   0   0\n",
    "#   -1   0.2425   0   1   0   2   1   0   0\n",
    "#    1   0.3200   0   0   1   3   0   1   0\n",
    "#   -1   0.3075   1   0   0   3   0   1   0\n",
    "#   -1   0.2700   1   0   0   2   0   0   1\n",
    "#    1   0.1700   0   1   0   1   0   0   1\n",
    "#   -1   0.1475   1   0   0   1   1   0   0\n",
    "#   -1   0.2500   0   1   0   2   0   0   1\n",
    "#   -1   0.2750   1   0   0   2   0   0   1\n",
    "#   -1   0.2000   1   0   0   2   1   0   0\n",
    "#   -1   0.1100   0   0   1   0   1   0   0\n",
    "#   -1   0.3400   1   0   0   3   0   1   0\n",
    "#    1   0.3000   0   0   1   3   1   0   0\n",
    "#    1   0.1550   0   1   0   1   0   1   0\n",
    "#   -1   0.2150   0   1   0   1   0   0   1\n",
    "#   -1   0.2900   0   0   1   3   0   1   0\n",
    "#    1   0.2750   0   0   1   2   0   1   0\n",
    "#    1   0.2175   0   1   0   2   0   1   0\n",
    "#    1   0.2150   0   1   0   2   0   0   1\n",
    "#    1   0.1050   1   0   0   1   1   0   0\n",
    "#   -1   0.2775   1   0   0   2   0   0   1\n",
    "#   -1   0.3225   1   0   0   3   0   1   0\n",
    "#    1   0.2075   0   1   0   2   1   0   0\n",
    "#   -1   0.3225   1   0   0   3   0   0   1\n",
    "#    1   0.2800   0   0   1   3   0   0   1\n",
    "#   -1   0.1575   0   1   0   1   0   0   1\n",
    "#    1   0.3250   0   0   1   3   0   0   1\n",
    "#   -1   0.2750   1   0   0   2   0   0   1\n",
    "#    1   0.1250   1   0   0   1   1   0   0\n",
    "#   -1   0.2325   0   1   0   2   0   0   1\n",
    "#    1   0.1825   1   0   0   2   1   0   0\n",
    "#   -1   0.2600   0   1   0   2   0   1   0\n",
    "#   -1   0.3075   1   0   0   3   0   0   1\n",
    "#   -1   0.2875   1   0   0   3   0   0   1\n",
    "#    1   0.2300   0   1   0   2   0   1   0\n",
    "#    1   0.3100   0   0   1   3   1   0   0\n",
    "#   -1   0.2750   1   0   0   2   0   0   1\n",
    "#    1   0.1125   0   1   0   0   0   0   1\n",
    "#    1   0.2525   1   0   0   2   1   0   0\n",
    "#    1   0.1625   0   1   0   1   0   1   0\n",
    "#    1   0.1075   1   0   0   1   0   0   1\n",
    "#   -1   0.2200   0   1   0   2   0   1   0\n",
    "#   -1   0.2300   0   1   0   2   0   1   0\n",
    "#   -1   0.3100   1   0   0   3   0   1   0\n",
    "#   -1   0.2875   1   0   0   3   0   1   0\n",
    "#    1   0.3375   0   0   1   3   0   0   1\n",
    "#   -1   0.1450   0   0   1   0   1   0   0\n",
    "#   -1   0.2650   1   0   0   2   1   0   0\n",
    "#    1   0.2225   0   1   0   2   1   0   0\n",
    "#   -1   0.2300   0   1   0   2   0   1   0\n",
    "#    1   0.1025   0   1   0   0   0   1   0\n",
    "#    1   0.1925   0   1   0   2   1   0   0\n",
    "#   -1   0.2525   0   1   0   2   0   1   0\n",
    "#   -1   0.1650   0   1   0   1   0   1   0\n",
    "#    1   0.1650   0   1   0   1   0   1   0\n",
    "#   -1   0.1300   1   0   0   1   0   1   0\n",
    "#   -1   0.2900   1   0   0   3   1   0   0\n",
    "#   -1   0.2175   0   1   0   1   0   0   1\n",
    "#    1   0.2300   1   0   0   2   1   0   0\n",
    "#   -1   0.3000   1   0   0   3   1   0   0\n",
    "#    1   0.2125   0   1   0   1   1   0   0\n",
    "#    1   0.2825   0   0   1   2   0   0   1\n",
    "#    1   0.3125   0   0   1   3   0   1   0\n",
    "#    1   0.2500   0   1   0   2   1   0   0\n",
    "#   -1   0.2375   0   1   0   2   0   0   1\n",
    "#    1   0.3375   0   0   1   3   0   1   0\n",
    "#    1   0.2000   0   1   0   2   0   0   1\n",
    "#   -1   0.2100   0   1   0   1   0   1   0\n",
    "#   -1   0.3225   1   0   0   3   1   0   0\n",
    "#    1   0.2375   0   0   1   2   1   0   0\n",
    "#   -1   0.2250   0   1   0   2   0   1   0\n",
    "#    1   0.1250   1   0   0   1   0   0   1\n",
    "#   -1   0.1925   1   0   0   1   1   0   0\n",
    "#   -1   0.2750   0   1   0   2   0   0   1\n",
    "#    1   0.2200   0   1   0   2   1   0   0\n",
    "#   -1   0.1675   0   1   0   1   1   0   0\n",
    "#   -1   0.1700   0   1   0   1   0   0   1\n",
    "#   -1   0.1350   0   0   1   0   0   1   0\n",
    "#   -1   0.1600   0   1   0   1   0   1   0\n",
    "#   -1   0.2125   0   1   0   1   0   0   1\n",
    "#    1   0.1200   1   0   0   1   0   0   1\n",
    "#   -1   0.2100   0   1   0   2   0   1   0\n",
    "#   -1   0.1250   0   0   1   0   0   0   1\n",
    "#   -1   0.2550   0   1   0   2   0   1   0\n",
    "#    1   0.2750   0   0   1   2   0   1   0\n",
    "#   -1   0.2200   0   0   1   1   1   0   0\n",
    "#    1   0.0925   1   0   0   1   1   0   0\n",
    "#    1   0.3350   0   0   1   3   0   1   0\n",
    "#   -1   0.2250   0   1   0   2   0   0   1\n",
    "#   -1   0.2425   0   1   0   2   1   0   0\n",
    "#    1   0.1275   0   1   0   1   0   1   0\n",
    "#    1   0.3350   0   1   0   3   1   0   0\n",
    "#   -1   0.1850   0   1   0   1   0   0   1\n",
    "#    1   0.1600   0   1   0   1   1   0   0\n",
    "#   -1   0.2400   0   1   0   2   1   0   0\n",
    "#    1   0.3300   0   0   1   3   0   0   1\n",
    "#   -1   0.3075   1   0   0   3   1   0   0\n",
    "#    1   0.2900   0   1   0   3   0   0   1\n",
    "#   -1   0.0950   0   0   1   0   1   0   0\n",
    "#   -1   0.1900   0   1   0   1   0   0   1\n",
    "#    1   0.1375   0   1   0   1   1   0   0\n",
    "#   -1   0.2100   0   1   0   1   1   0   0\n",
    "#   -1   0.3025   1   0   0   3   1   0   0\n",
    "#    1   0.1375   1   0   0   0   0   0   1\n",
    "#   -1   0.1475   1   0   0   1   0   1   0\n",
    "#    1   0.2150   0   1   0   2   1   0   0\n",
    "#   -1   0.2400   0   1   0   2   1   0   0\n",
    "#   -1   0.1375   0   0   1   0   0   0   1\n",
    "#    1   0.2200   1   0   0   2   1   0   0\n",
    "#   -1   0.1150   0   0   1   0   0   1   0\n",
    "#    1   0.1825   0   0   1   2   0   1   0\n",
    "#   -1   0.3225   1   0   0   3   0   0   1\n",
    "#   -1   0.1450   0   0   1   0   0   0   1\n",
    "#    1   0.1675   0   1   0   1   1   0   0\n",
    "#    1   0.3325   0   0   1   3   0   1   0\n",
    "#    1   0.1075   1   0   0   0   0   0   1\n",
    "#   -1   0.1350   0   0   1   0   1   0   0\n",
    "#   -1   0.1450   0   0   1   0   1   0   0\n",
    "#    1   0.1575   0   1   0   1   1   0   0\n",
    "#   -1   0.1825   0   1   0   1   0   0   1\n",
    "#   -1   0.2450   0   1   0   2   0   1   0\n",
    "#    1   0.1425   1   0   0   1   1   0   0\n",
    "#    1   0.2175   0   1   0   2   0   0   1\n",
    "#    1   0.2325   0   1   0   2   0   1   0\n",
    "#   -1   0.2875   1   0   0   3   1   0   0\n",
    "#    1   0.2625   0   1   0   2   0   0   1\n",
    "#    1   0.1575   0   1   0   1   0   0   1\n",
    "#    1   0.2750   0   0   1   2   1   0   0\n",
    "#   -1   0.2500   0   1   0   2   1   0   0\n",
    "#   -1   0.2400   0   1   0   2   0   1   0\n",
    "#    1   0.1100   1   0   0   0   0   0   1\n",
    "#   -1   0.2975   1   0   0   3   0   0   1\n",
    "#   -1   0.1725   0   0   1   1   1   0   0\n",
    "#    1   0.3225   0   0   1   3   1   0   0\n",
    "#   -1   0.1450   0   0   1   0   0   0   1\n",
    "#    1   0.1725   0   1   0   1   0   1   0\n",
    "#    1   0.3050   0   0   1   3   1   0   0\n",
    "#   -1   0.3200   1   0   0   3   0   0   1\n",
    "#    1   0.1450   1   0   0   1   1   0   0\n",
    "#   -1   0.3175   1   0   0   3   0   1   0\n",
    "#    1   0.1475   1   0   0   1   0   1   0\n",
    "#    1   0.2575   0   1   0   2   1   0   0\n",
    "#    1   0.1200   1   0   0   1   0   0   1\n",
    "#   -1   0.2425   0   1   0   2   0   1   0\n",
    "#   -1   0.0900   1   0   0   0   1   0   0\n",
    "#   -1   0.0925   0   0   1   0   1   0   0\n",
    "#   -1   0.1650   0   0   1   1   0   1   0\n",
    "#    1   0.1025   1   0   0   0   0   0   1\n",
    "#   -1   0.1475   0   0   1   0   0   0   1\n",
    "#    1   0.2225   1   0   0   2   0   0   1\n",
    "#    1   0.3250   1   0   0   3   0   0   1\n",
    "#    1   0.2800   0   0   1   2   1   0   0\n",
    "#    1   0.2625   0   1   0   2   0   0   1\n",
    "#    1   0.1450   1   0   0   1   0   1   0\n",
    "#    1   0.2350   0   1   0   2   0   1   0\n",
    "#   -1   0.3425   0   0   1   3   1   0   0\n",
    "#   -1   0.1575   0   1   0   1   0   0   1\n",
    "#   -1   0.3075   0   0   1   2   0   1   0\n",
    "#   -1   0.0950   0   0   1   0   0   1   0\n",
    "#   -1   0.1925   0   1   0   1   0   0   1\n",
    "#    1   0.1300   1   0   0   1   1   0   0\n",
    "#   -1   0.3075   1   0   0   3   0   1   0\n",
    "#   -1   0.2000   0   1   0   1   1   0   0\n",
    "#    1   0.2475   0   1   0   3   1   0   0\n",
    "#   -1   0.2825   1   0   0   3   1   0   0\n",
    "#    1   0.2425   0   1   0   3   0   1   0\n",
    "#   -1   0.2625   0   0   1   2   1   0   0\n",
    "#    1   0.0900   1   0   0   0   1   0   0\n",
    "#    1   0.2800   0   0   1   2   0   0   1\n",
    "#    1   0.2600   0   1   0   2   0   1   0\n",
    "#    1   0.0900   0   1   0   0   0   1   0\n",
    "#    1   0.2900   0   0   1   3   1   0   0\n",
    "#    1   0.1950   0   1   0   2   0   1   0\n",
    "#    1   0.2325   0   1   0   2   1   0   0\n",
    "#    1   0.2025   0   1   0   1   0   1   0\n",
    "#    1   0.3025   0   0   1   3   1   0   0\n",
    "#   -1   0.1800   0   0   1   1   0   1   0\n",
    "#   -1   0.2225   0   1   0   2   1   0   0\n",
    "#   -1   0.1425   0   0   1   0   1   0   0\n",
    "#   -1   0.2725   1   0   0   2   0   0   1\n",
    "#  \n",
    "# houses_test_ord.txt                          \n",
    "#    1   0.2550   0   1   0   2   1   0   0\n",
    "#    1   0.1625   0   1   0   1   0   1   0\n",
    "#   -1   0.2750   1   0   0   2   1   0   0\n",
    "#   -1   0.1275   0   0   1   0   0   0   1\n",
    "#   -1   0.1650   0   0   1   1   0   0   1\n",
    "#    1   0.1450   1   0   0   1   0   1   0\n",
    "#   -1   0.3275   1   0   0   3   1   0   0\n",
    "#    1   0.2175   0   1   0   2   0   1   0\n",
    "#    1   0.2725   0   0   1   2   0   1   0\n",
    "#   -1   0.3075   1   0   0   3   0   1   0\n",
    "#   -1   0.2600   1   0   0   2   0   1   0\n",
    "#   -1   0.1525   0   0   1   0   0   1   0\n",
    "#   -1   0.1450   0   0   1   0   1   0   0\n",
    "#    1   0.2375   0   1   0   2   0   0   1\n",
    "#   -1   0.1950   0   1   0   1   0   1   0\n",
    "#   -1   0.2375   0   1   0   2   0   0   1\n",
    "#    1   0.2475   0   1   0   2   1   0   0\n",
    "#    1   0.3150   0   0   1   3   0   0   1\n",
    "#    1   0.1525   1   0   0   1   1   0   0\n",
    "#    1   0.3050   0   0   1   3   0   0   1\n",
    "#    1   0.2350   0   1   0   2   0   0   1\n",
    "#   -1   0.1525   0   0   1   0   0   0   1\n",
    "#    1   0.2550   0   1   0   2   0   0   1\n",
    "#    1   0.1200   0   1   0   1   1   0   0\n",
    "#    1   0.2450   0   1   0   2   1   0   0\n",
    "#   -1   0.3300   1   0   0   3   0   0   1\n",
    "#    1   0.3275   1   0   0   3   1   0   0\n",
    "#    1   0.2300   1   0   0   2   0   1   0\n",
    "#    1   0.2275   0   1   0   2   0   0   1\n",
    "#    1   0.2350   1   0   0   2   1   0   0\n",
    "#    1   0.1475   1   0   0   1   1   0   0\n",
    "#    1   0.2850   0   0   1   3   0   0   1\n",
    "#    1   0.1000   0   0   1   0   1   0   0\n",
    "#    1   0.1750   0   1   0   1   1   0   0\n",
    "#    1   0.3075   0   0   1   3   0   0   1\n",
    "#    1   0.1550   0   1   0   1   0   0   1\n",
    "#   -1   0.0925   0   0   1   0   1   0   0\n",
    "#   -1   0.1300   0   0   1   0   0   0   1\n",
    "#    1   0.1425   0   0   1   1   1   0   0\n",
    "#    1   0.2975   0   0   1   3   0   0   1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
