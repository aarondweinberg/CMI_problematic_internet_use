{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to extend the alternative method for counting instances of moderate/vigorous physical activity [MVPA] to other participants\n",
    "\n",
    "1. Segment each day into 5-minute \"bouts\"\n",
    "2. Identify each day as having had the accelerometer on enough to believe that it was on for most/all waking hours\n",
    "3. Counting the number of such days\n",
    "4. Counting the number of MVPA bouts on these days and identifying them as \"active\" days\n",
    "5. Computing the average MVPA bouts per active day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing packages we'll need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the folders to make sure none of the names will be problematic\n",
    "\n",
    "folders = os.listdir('series_train.parquet/')\n",
    "\n",
    "# convert folders to a data frame\n",
    "folders_df = pd.DataFrame(folders, columns=['folder'])\n",
    "\n",
    "# save folders_df as a csv\n",
    "folders_df.to_csv('folders.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/nhwg0cqn70nf3n1xr6j68x440000gp/T/ipykernel_51829/3532959024.py:119: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Specify cutoffs\n",
    "\n",
    "#ENMO cutoffs in mg for MVPA\n",
    "mvpa_cutoff1 = 0.192\n",
    "mvpa_cutoff2 = 0.110\n",
    "\n",
    "# Number of 'active' bouts required for a day to count as 'active'\n",
    "active_bout_cutoff = 150\n",
    "\n",
    "# Specify the length of the bouts\n",
    "boutlength = '5min'\n",
    "\n",
    "# Maximum number of 5-minute bouts that can be imputed as zeroes to account for the accelerometer not collected data when at rest\n",
    "impute_max = 6\n",
    "\n",
    "# Minimum number of 5-second intervals (within a 5-minute bout) that need to have data for the bout to be counted\n",
    "impute_sec_min = 29\n",
    "\n",
    "# First try this with just one folder\n",
    "#folders = ['id=0a418b57', 'id=0a431608', 'id=0b7d7aec', 'id=0b7d9da6', 'id=0b50f3fa']\n",
    "\n",
    "# Get a list of all folders in the series_train.parquet/ folder\n",
    "folders = os.listdir('series_train.parquet/')\n",
    "\n",
    "# Remove the item '.DS_Store' from folders\n",
    "folders = [folder for folder in folders if folder != '.DS_Store']\n",
    "\n",
    "# Remove the first three characters from each item in folders\n",
    "folders = [folder[3:] for folder in folders]\n",
    "\n",
    "# Create a new data frame with columns 'ID', 'ENMO_Avg_Active_Days_MVPA192', 'ENMO_Avg_Active_Days_MVPA110', 'ENMO_Avg_All_Days_MVPA192', 'ENMO_Avg_All_Days_MVPA110'\n",
    "df = pd.DataFrame(columns=['ID', 'ENMO_Avg_Active_Days_MVPA192', 'ENMO_Avg_Active_Days_MVPA110', 'ENMO_Avg_All_Days_MVPA192', 'ENMO_Avg_All_Days_MVPA110', 'Positive_Anglez_Active_Days','Positive_Anglez_All_Days'])\n",
    "df['ID'] = folders\n",
    "\n",
    "# Set the ID column as the index\n",
    "df.set_index('ID', inplace=True)\n",
    "\n",
    "# Iterate through the folders\n",
    "for id in folders:\n",
    "    # Create the filename to load and load the file\n",
    "    fileloc = 'series_train.parquet/id='+str(id)+'/part-0.parquet'\n",
    "    data = pd.read_parquet(fileloc)\n",
    "\n",
    "    # Remove any rows where the variable non-wear_flag is nonzero\n",
    "    data = data[data['non-wear_flag'] == 0]\n",
    "\n",
    "    # Change the time_of_day variable to a datetime and make it into the index\n",
    "    data['dt'] = pd.to_datetime(data['time_of_day'])\n",
    "    data['dt_mod'] = data['dt'] + pd.to_timedelta(data['relative_date_PCIAT'], unit='D')\n",
    "    data.set_index('dt_mod', inplace=True)\n",
    "\n",
    "    # Create a new data frame that counts the number of valid data points within each 5-minute ('boutlength') interval\n",
    "    # This will later be used to exclude intervals that had fewer than 30 (out of 60) valid data points\n",
    "    data['count'] = 1\n",
    "    number_of_data_points = data.resample(boutlength).agg({'count':'sum'})\n",
    "    data.drop('count', axis=1, inplace=True)\n",
    "\n",
    "    # Create 5-minute \"bouts\" of averaged data and incorporate the number of valid data points within each interval as a new variable 'count'\n",
    "    data_resampled_5min = data.resample(boutlength).mean()\n",
    "    data_resampled_5min = data_resampled_5min.merge(number_of_data_points, left_index=True, right_index=True)\n",
    "\n",
    "    # Some of the accelerometers stopped collecting data if they were stationary (but still on/worn)\n",
    "    # This next section is an attempt to identify and fill in these seemingly missing values with \"0\" for the enmo value\n",
    "    # It does this by identifying the length of each sequence of NaN values and filling them with 0 if thery are at most 30 minutes long\n",
    "    # This also restricts this process to 5-minute bouts that had data for at least 30 of the 5-second-intervals within the bout\n",
    "    data_resampled_5min['enmogroup'] = data_resampled_5min['enmo'].notna().cumsum()\n",
    "    enmogroupcount = data_resampled_5min.groupby(by=[\"enmogroup\"]).size().to_frame()\n",
    "    enmogroupcount = enmogroupcount.rename(columns={0: 'enmogroupsize'})\n",
    "    data_resampled_5min = data_resampled_5min.merge(enmogroupcount, how='left', left_on='enmogroup', right_index=True)\n",
    "    data_resampled_5min['smallinterval'] = (data_resampled_5min['enmogroupsize'] < impute_max+2) & (data_resampled_5min['count']>impute_sec_min)\n",
    "    data_resampled_5min['filled_enmo'] = np.where(data_resampled_5min.smallinterval, data_resampled_5min.enmo.fillna(0), data_resampled_5min.enmo)\n",
    "\n",
    "    # Also fill in only anglez values where the count is large enough\n",
    "    data_resampled_5min['filled_anglez'] = np.where(data_resampled_5min['count']>impute_sec_min, data_resampled_5min.anglez, np.nan)\n",
    "\n",
    "    # The next code chunk will create a new data frame that lists the total number of valid bouts for the participant\n",
    "    # and will count the number of bouts with filled_enmo values over a particular threshold\n",
    "    # and then count the number of bouts with positive anglez values\n",
    "\n",
    "    # Start by counting the number of valid bouts in each day as a data frame\n",
    "    boutcount_filled = data_resampled_5min.groupby(data_resampled_5min.index.date).count()['filled_enmo'].to_frame()\n",
    "    boutcount_filled = boutcount_filled.rename(columns={'filled_enmo': 'valid_bouts'})\n",
    "\n",
    "    # Count the number of bouts in each day with filled_enmo at least mvpa_cutoff1\n",
    "    boutcount_MVPA1 = data_resampled_5min[data_resampled_5min['filled_enmo'] >= mvpa_cutoff1].groupby(data_resampled_5min[data_resampled_5min['filled_enmo'] >= mvpa_cutoff1].index.date).count()['filled_enmo'].to_frame()\n",
    "    boutcount_MVPA1 = boutcount_MVPA1.rename(columns={'filled_enmo': 'MVPA_bouts_over_cutoff1'})\n",
    "    boutcount = boutcount_filled.merge(boutcount_MVPA1, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    # Count the number of bouts in each day with filled_enmo at least mvpa_cutoff2\n",
    "    boutcount_MVPA2 = data_resampled_5min[data_resampled_5min['filled_enmo'] >= mvpa_cutoff2].groupby(data_resampled_5min[data_resampled_5min['filled_enmo'] >= mvpa_cutoff2].index.date).count()['filled_enmo'].to_frame()\n",
    "    boutcount_MVPA2 = boutcount_MVPA2.rename(columns={'filled_enmo': 'MVPA_bouts_over_cutoff2'})\n",
    "    boutcount = boutcount.merge(boutcount_MVPA2, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    # Count the number of bouts in each day with anglez at least 0\n",
    "    boutcount_anglez = data_resampled_5min[data_resampled_5min['filled_anglez'] > 0].groupby(data_resampled_5min[data_resampled_5min['filled_anglez'] > 0].index.date).count()['filled_anglez'].to_frame()\n",
    "    boutcount_anglez = boutcount_anglez.rename(columns={'filled_anglez': 'Positive_Anglez_Bouts'})\n",
    "    boutcount = boutcount.merge(boutcount_anglez, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    # Compute a new variable 'included_day' to be True if valid_bouts is at least active_bout_cutoff\n",
    "    boutcount['included_day'] = boutcount['valid_bouts'] >= active_bout_cutoff\n",
    "\n",
    "    # Compute the mean of MVPA bouts over each cutoff\n",
    "    MVPA_mean1 = boutcount[boutcount['included_day'] == True]['MVPA_bouts_over_cutoff1'].mean()\n",
    "    MVPA_mean2 = boutcount[boutcount['included_day'] == True]['MVPA_bouts_over_cutoff2'].mean()\n",
    "    MVPA_mean3 = boutcount['MVPA_bouts_over_cutoff1'].mean()\n",
    "    MVPA_mean4 = boutcount['MVPA_bouts_over_cutoff2'].mean()\n",
    "    Anglez_mean1 = boutcount[boutcount['included_day'] == True]['Positive_Anglez_Bouts'].mean()\n",
    "    Anglez_mean2 = boutcount['Positive_Anglez_Bouts'].mean()\n",
    "\n",
    "    # Copy the values into the data frame\n",
    "    df.at[id, 'ENMO_Avg_Active_Days_MVPA192'] = MVPA_mean1\n",
    "    df.at[id, 'ENMO_Avg_Active_Days_MVPA110'] = MVPA_mean2\n",
    "    df.at[id, 'ENMO_Avg_All_Days_MVPA192'] = MVPA_mean3\n",
    "    df.at[id, 'ENMO_Avg_All_Days_MVPA110'] = MVPA_mean4\n",
    "    df.at[id, 'Positive_Anglez_Active_Days'] = Anglez_mean1\n",
    "    df.at[id, 'Positive_Anglez_All_Days'] = Anglez_mean2\n",
    "\n",
    "    # Replace any NaN values in df with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "# Export df as a csv file\n",
    "df.to_csv('Accelerometer_enmo_anglez_daily_averages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENMO_Avg_Active_Days_MVPA192</th>\n",
       "      <th>ENMO_Avg_Active_Days_MVPA110</th>\n",
       "      <th>ENMO_Avg_All_Days_MVPA192</th>\n",
       "      <th>ENMO_Avg_All_Days_MVPA110</th>\n",
       "      <th>Positive_Anglez_Active_Days</th>\n",
       "      <th>Positive_Anglez_All_Days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0a418b57</th>\n",
       "      <td>8.294118</td>\n",
       "      <td>21.764706</td>\n",
       "      <td>8.454545</td>\n",
       "      <td>17.444444</td>\n",
       "      <td>19.058824</td>\n",
       "      <td>17.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0a431608</th>\n",
       "      <td>6.846154</td>\n",
       "      <td>14.142857</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>124.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b7d7aec</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b7d9da6</th>\n",
       "      <td>14.727273</td>\n",
       "      <td>32.391304</td>\n",
       "      <td>12.555556</td>\n",
       "      <td>27.310345</td>\n",
       "      <td>20.521739</td>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b50f3fa</th>\n",
       "      <td>18.200000</td>\n",
       "      <td>30.562500</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>134.437500</td>\n",
       "      <td>117.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ENMO_Avg_Active_Days_MVPA192  ENMO_Avg_Active_Days_MVPA110  \\\n",
       "ID                                                                     \n",
       "0a418b57                      8.294118                     21.764706   \n",
       "0a431608                      6.846154                     14.142857   \n",
       "0b7d7aec                      0.000000                      0.000000   \n",
       "0b7d9da6                     14.727273                     32.391304   \n",
       "0b50f3fa                     18.200000                     30.562500   \n",
       "\n",
       "          ENMO_Avg_All_Days_MVPA192  ENMO_Avg_All_Days_MVPA110  \\\n",
       "ID                                                               \n",
       "0a418b57                   8.454545                  17.444444   \n",
       "0a431608                   6.428571                  13.636364   \n",
       "0b7d7aec                   0.000000                   0.000000   \n",
       "0b7d9da6                  12.555556                  27.310345   \n",
       "0b50f3fa                  17.250000                  27.500000   \n",
       "\n",
       "          Positive_Anglez_Active_Days  Positive_Anglez_All_Days  \n",
       "ID                                                               \n",
       "0a418b57                    19.058824                 17.071429  \n",
       "0a431608                   133.000000                124.160000  \n",
       "0b7d7aec                     0.000000                  8.000000  \n",
       "0b7d9da6                    20.521739                 19.500000  \n",
       "0b50f3fa                   134.437500                117.285714  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Below is the original code copied from Accelerometer_exploration_6. It can be ignored.\n",
    "\n",
    "# Load the parquet data file\n",
    "data = pd.read_parquet('series_train.parquet/id=0b4014f0/part-0.parquet')\n",
    "\n",
    "# Add a new column that converts time_of_day into datetime\n",
    "data['dt'] = pd.to_datetime(data['time_of_day'])\n",
    "\n",
    "# Change the day in the dt variable to be equal to the relative_date_PCIAT value\n",
    "data['dt_mod'] = data['dt'] + pd.to_timedelta(data['relative_date_PCIAT'], unit='D')\n",
    "\n",
    "# Use dt_mod as the index. This will help with the resampling\n",
    "data.set_index('dt_mod', inplace=True)\n",
    "\n",
    "# Create a new data frame by grouping the observations into 5-minute intervals and computing the mean of each interval\n",
    "data_resampled_5min = data.resample('5min').mean()\n",
    "\n",
    "# Create a new variable called 'enmogroup' that increases by 1 each time the value of enmo is numerical\n",
    "data_resampled_5min['enmogroup'] = data_resampled_5min['enmo'].notna().cumsum()\n",
    "\n",
    "# Create a new data frame that lists the number of rows in each value of enmogroup\n",
    "enmogroupcount = data_resampled_5min.groupby(by=[\"enmogroup\"]).size().to_frame()\n",
    "\n",
    "# Rename the column 0 as 'enmogroupsize'\n",
    "enmogroupcount = enmogroupcount.rename(columns={0: 'enmogroupsize'})\n",
    "\n",
    "# Merge data_resampled_5min and enmogroupcount on the variable enmogroup, keeping the index of data_resampled_5min\n",
    "data_resampled_5min = data_resampled_5min.merge(enmogroupcount, how='left', left_on='enmogroup', right_index=True)\n",
    "\n",
    "# Add a new variable 'smallinterval' when enmogroupsize is less than 7\n",
    "data_resampled_5min['smallinterval'] = data_resampled_5min['enmogroupsize'] < 8\n",
    "\n",
    "# When smallinterval is true, fill the NaN values; otherwise, retain the original enmo values (including NaN)\n",
    "data_resampled_5min['filled_enmo'] = np.where(data_resampled_5min.smallinterval, data_resampled_5min.enmo.ffill(), data_resampled_5min.enmo)\n",
    "\n",
    "# The code here will create a new data frame that lists the total number of valid bouts for the participant\n",
    "# and will count the number of bouts with filled_enmo values over a particular threshold\n",
    "\n",
    "# Start by counting the number of valid bouts in each day as a data frame\n",
    "boutcount_filled = data_resampled_5min.groupby(data_resampled_5min.index.date).count()['filled_enmo'].to_frame()\n",
    "\n",
    "# Rename filled_enmo as valid_bouts\n",
    "boutcount_filled = boutcount_filled.rename(columns={'filled_enmo': 'valid_bouts'})\n",
    "\n",
    "# Count the number of bouts in each day with filled_enmo at least 0.192\n",
    "boutcount_MVPA = data_resampled_5min[data_resampled_5min['filled_enmo'] >= 0.192].groupby(data_resampled_5min[data_resampled_5min['filled_enmo'] >= 0.192].index.date).count()['filled_enmo'].to_frame()\n",
    "\n",
    "# Rename filled_enmo as MVPA_bouts\n",
    "boutcount_MVPA = boutcount_MVPA.rename(columns={'filled_enmo': 'MVPA_bouts'})\n",
    "\n",
    "# Merge boutcount_filled and boutcount_MVPA\n",
    "boutcount = boutcount_filled.merge(boutcount_MVPA, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Compute a new variable 'included_day' to be True if valid_bouts is at least 150\n",
    "boutcount['included_day'] = boutcount['valid_bouts'] >= 150\n",
    "\n",
    "# Compute the mean of MVPA_bouts for all days where included_day is True\n",
    "MVPA_mean = boutcount[boutcount['included_day'] == True]['MVPA_bouts'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
