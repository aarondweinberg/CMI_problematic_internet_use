{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first section focuses on removing \"bad\" values: obvious outliers and nonsensical values from the BIA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The original data has been named train_original\n",
    "#Here I am splitting the data into a train and test set. I want to stratify by age. \n",
    "# Then I export as csv files, since we are working over multiple jupiter notebooks.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_original=pd.read_csv('train_original.csv')\n",
    "\n",
    "seed=1275\n",
    "train, test = train_test_split(train_original, test_size=0.2, random_state=seed, stratify=train_original['Basic_Demos-Age'])\n",
    "\n",
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 82 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   id                                      3168 non-null   object \n",
      " 1   Basic_Demos-Enroll_Season               3168 non-null   object \n",
      " 2   Basic_Demos-Age                         3168 non-null   int64  \n",
      " 3   Basic_Demos-Sex                         3168 non-null   int64  \n",
      " 4   CGAS-Season                             2065 non-null   object \n",
      " 5   CGAS-CGAS_Score                         1951 non-null   float64\n",
      " 6   Physical-Season                         2642 non-null   object \n",
      " 7   Physical-BMI                            2401 non-null   float64\n",
      " 8   Physical-Height                         2404 non-null   float64\n",
      " 9   Physical-Weight                         2446 non-null   float64\n",
      " 10  Physical-Waist_Circumference            695 non-null    float64\n",
      " 11  Physical-Diastolic_BP                   2347 non-null   float64\n",
      " 12  Physical-HeartRate                      2357 non-null   float64\n",
      " 13  Physical-Systolic_BP                    2347 non-null   float64\n",
      " 14  Fitness_Endurance-Season                1060 non-null   object \n",
      " 15  Fitness_Endurance-Max_Stage             609 non-null    float64\n",
      " 16  Fitness_Endurance-Time_Mins             607 non-null    float64\n",
      " 17  Fitness_Endurance-Time_Sec              606 non-null    float64\n",
      " 18  FGC-Season                              2674 non-null   object \n",
      " 19  FGC-FGC_CU                              1855 non-null   float64\n",
      " 20  FGC-FGC_CU_Zone                         1822 non-null   float64\n",
      " 21  FGC-FGC_GSND                            850 non-null    float64\n",
      " 22  FGC-FGC_GSND_Zone                       840 non-null    float64\n",
      " 23  FGC-FGC_GSD                             849 non-null    float64\n",
      " 24  FGC-FGC_GSD_Zone                        839 non-null    float64\n",
      " 25  FGC-FGC_PU                              1846 non-null   float64\n",
      " 26  FGC-FGC_PU_Zone                         1814 non-null   float64\n",
      " 27  FGC-FGC_SRL                             1842 non-null   float64\n",
      " 28  FGC-FGC_SRL_Zone                        1811 non-null   float64\n",
      " 29  FGC-FGC_SRR                             1844 non-null   float64\n",
      " 30  FGC-FGC_SRR_Zone                        1813 non-null   float64\n",
      " 31  FGC-FGC_TL                              1855 non-null   float64\n",
      " 32  FGC-FGC_TL_Zone                         1823 non-null   float64\n",
      " 33  BIA-Season                              1712 non-null   object \n",
      " 34  BIA-BIA_Activity_Level_num              1593 non-null   float64\n",
      " 35  BIA-BIA_BMC                             1593 non-null   float64\n",
      " 36  BIA-BIA_BMI                             1593 non-null   float64\n",
      " 37  BIA-BIA_BMR                             1593 non-null   float64\n",
      " 38  BIA-BIA_DEE                             1593 non-null   float64\n",
      " 39  BIA-BIA_ECW                             1593 non-null   float64\n",
      " 40  BIA-BIA_FFM                             1593 non-null   float64\n",
      " 41  BIA-BIA_FFMI                            1593 non-null   float64\n",
      " 42  BIA-BIA_FMI                             1593 non-null   float64\n",
      " 43  BIA-BIA_Fat                             1593 non-null   float64\n",
      " 44  BIA-BIA_Frame_num                       1593 non-null   float64\n",
      " 45  BIA-BIA_ICW                             1593 non-null   float64\n",
      " 46  BIA-BIA_LDM                             1593 non-null   float64\n",
      " 47  BIA-BIA_LST                             1593 non-null   float64\n",
      " 48  BIA-BIA_SMM                             1593 non-null   float64\n",
      " 49  BIA-BIA_TBW                             1593 non-null   float64\n",
      " 50  PAQ_A-Season                            382 non-null    object \n",
      " 51  PAQ_A-PAQ_A_Total                       382 non-null    float64\n",
      " 52  PAQ_C-Season                            1373 non-null   object \n",
      " 53  PAQ_C-PAQ_C_Total                       1373 non-null   float64\n",
      " 54  PCIAT-Season                            2195 non-null   object \n",
      " 55  PCIAT-PCIAT_01                          2192 non-null   float64\n",
      " 56  PCIAT-PCIAT_02                          2193 non-null   float64\n",
      " 57  PCIAT-PCIAT_03                          2190 non-null   float64\n",
      " 58  PCIAT-PCIAT_04                          2191 non-null   float64\n",
      " 59  PCIAT-PCIAT_05                          2190 non-null   float64\n",
      " 60  PCIAT-PCIAT_06                          2192 non-null   float64\n",
      " 61  PCIAT-PCIAT_07                          2190 non-null   float64\n",
      " 62  PCIAT-PCIAT_08                          2190 non-null   float64\n",
      " 63  PCIAT-PCIAT_09                          2189 non-null   float64\n",
      " 64  PCIAT-PCIAT_10                          2192 non-null   float64\n",
      " 65  PCIAT-PCIAT_11                          2193 non-null   float64\n",
      " 66  PCIAT-PCIAT_12                          2190 non-null   float64\n",
      " 67  PCIAT-PCIAT_13                          2189 non-null   float64\n",
      " 68  PCIAT-PCIAT_14                          2191 non-null   float64\n",
      " 69  PCIAT-PCIAT_15                          2190 non-null   float64\n",
      " 70  PCIAT-PCIAT_16                          2188 non-null   float64\n",
      " 71  PCIAT-PCIAT_17                          2185 non-null   float64\n",
      " 72  PCIAT-PCIAT_18                          2187 non-null   float64\n",
      " 73  PCIAT-PCIAT_19                          2190 non-null   float64\n",
      " 74  PCIAT-PCIAT_20                          2192 non-null   float64\n",
      " 75  PCIAT-PCIAT_Total                       2195 non-null   float64\n",
      " 76  SDS-Season                              2103 non-null   object \n",
      " 77  SDS-SDS_Total_Raw                       2095 non-null   float64\n",
      " 78  SDS-SDS_Total_T                         2092 non-null   float64\n",
      " 79  PreInt_EduHx-Season                     2823 non-null   object \n",
      " 80  PreInt_EduHx-computerinternet_hoursday  2633 non-null   float64\n",
      " 81  sii                                     2195 non-null   float64\n",
      "dtypes: float64(68), int64(2), object(12)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#This is the starting data.\n",
    "\n",
    "train=pd.read_csv('train.csv')\n",
    "train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float columns: Index(['CGAS-CGAS_Score', 'Physical-BMI', 'Physical-Height', 'Physical-Weight',\n",
      "       'Physical-Waist_Circumference', 'Physical-Diastolic_BP',\n",
      "       'Physical-HeartRate', 'Physical-Systolic_BP',\n",
      "       'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins',\n",
      "       'Fitness_Endurance-Time_Sec', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone',\n",
      "       'FGC-FGC_GSND', 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone',\n",
      "       'FGC-FGC_PU', 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone',\n",
      "       'FGC-FGC_SRR', 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n",
      "       'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
      "       'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
      "       'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
      "       'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
      "       'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total', 'PAQ_C-PAQ_C_Total',\n",
      "       'PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04',\n",
      "       'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08',\n",
      "       'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12',\n",
      "       'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16',\n",
      "       'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20',\n",
      "       'PCIAT-PCIAT_Total', 'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T',\n",
      "       'PreInt_EduHx-computerinternet_hoursday', 'sii'],\n",
      "      dtype='object')\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "#I only want to include quantitative variables for possible analysis for outliers, so first I identify the float variables.\n",
    "\n",
    "float_columns = train.select_dtypes(include=['float']).columns\n",
    "print(\"Float columns:\", float_columns)\n",
    "print(len(float_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[515, 1541, 1542, 3080, 2061, 2078, 1054, 1058, 1067, 3120, 1076, 573, 2116, 1092, 3142, 73, 76, 78, 3150, 1621, 92, 1119, 2656, 610, 2658, 101, 107, 2171, 1663, 127, 1671, 2185, 657, 1683, 2720, 2723, 1188, 1205, 2249, 1234, 2265, 2276, 1766, 2287, 2799, 2804, 2296, 1274, 1791, 1287, 777, 786, 790, 793, 797, 2853, 1320, 1836, 2862, 2350, 2352, 306, 2870, 2875, 2363, 2366, 2881, 329, 1354, 1867, 2387, 1893, 872, 2412, 371, 1399, 2425, 2954, 2446, 1427, 2966, 411, 1441, 1955, 2486, 962, 3012, 2518, 2525, 992, 997, 3047, 488, 498, 2042]\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "#This generates a list of indices for extreme outliers or negative values that should not be negative. \n",
    "#In particular, BIA_BIA_Fat, which measures body fat percentage, has a bunch of negative values.\n",
    "threshold=5\n",
    "index_set=[]\n",
    "for i in range(len(float_columns)):\n",
    "    #print(float_columns[i])\n",
    "    z=np.abs(stats.zscore(train[[float_columns[i]]],nan_policy='omit'))\n",
    "    indices_large_z = np.where(np.all(z > threshold, axis=1))[0].flatten().tolist()\n",
    "    indices_negative=np.where(np.all(train[[float_columns[i]]]<0, axis=1))[0].flatten().tolist()\n",
    "    index_set=index_set+indices_large_z+indices_negative\n",
    "    #print(indices_large_z)\n",
    "    #print(indices_negative)\n",
    "    i+=1\n",
    "\n",
    "index_set_neg_largez=list(set(index_set))\n",
    "print(index_set_neg_largez)\n",
    "print(len(index_set_neg_largez))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sii\n",
      "0.0    38\n",
      "1.0    21\n",
      "2.0    20\n",
      "3.0     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#This defines a new dataframe with the the entire case removed, where there is an extreme outlier or a nonsensical negative value.\n",
    "train_no_outliers_no_negatives=train.drop(index_set_neg_largez)\n",
    "\n",
    "#Here's a quick look at the effect of this cleaning. The first entry shows how many rows have been affected in each sii category. \n",
    "\n",
    "print(train['sii'].value_counts()-train_no_outliers_no_negatives['sii'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This takes extreme outliers and nonsensical negative values and replaces them with NaN.\n",
    "\n",
    "train_outliers_neg_to_NaN=train\n",
    "for i in range(len(float_columns)):\n",
    "    index_set=[]\n",
    "    z=np.abs(stats.zscore(train[[float_columns[i]]],nan_policy='omit'))\n",
    "    indices_large_z = np.where(np.all(z > threshold, axis=1))[0].flatten().tolist()\n",
    "    indices_negative=np.where(np.all(train[[float_columns[i]]]<0, axis=1))[0].flatten().tolist()\n",
    "    index_set=indices_large_z+indices_negative\n",
    "    #print(len(index_set))\n",
    "    for j in index_set:\n",
    "        train_outliers_neg_to_NaN.at[j, float_columns[i]] = np.nan\n",
    "        j+=1\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 82 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   id                                      3168 non-null   object \n",
      " 1   Basic_Demos-Enroll_Season               3168 non-null   object \n",
      " 2   Basic_Demos-Age                         3168 non-null   int64  \n",
      " 3   Basic_Demos-Sex                         3168 non-null   int64  \n",
      " 4   CGAS-Season                             2065 non-null   object \n",
      " 5   CGAS-CGAS_Score                         1950 non-null   float64\n",
      " 6   Physical-Season                         2642 non-null   object \n",
      " 7   Physical-BMI                            2395 non-null   float64\n",
      " 8   Physical-Height                         2404 non-null   float64\n",
      " 9   Physical-Weight                         2445 non-null   float64\n",
      " 10  Physical-Waist_Circumference            695 non-null    float64\n",
      " 11  Physical-Diastolic_BP                   2343 non-null   float64\n",
      " 12  Physical-HeartRate                      2357 non-null   float64\n",
      " 13  Physical-Systolic_BP                    2345 non-null   float64\n",
      " 14  Fitness_Endurance-Season                1060 non-null   object \n",
      " 15  Fitness_Endurance-Max_Stage             607 non-null    float64\n",
      " 16  Fitness_Endurance-Time_Mins             607 non-null    float64\n",
      " 17  Fitness_Endurance-Time_Sec              606 non-null    float64\n",
      " 18  FGC-Season                              2674 non-null   object \n",
      " 19  FGC-FGC_CU                              1846 non-null   float64\n",
      " 20  FGC-FGC_CU_Zone                         1822 non-null   float64\n",
      " 21  FGC-FGC_GSND                            846 non-null    float64\n",
      " 22  FGC-FGC_GSND_Zone                       840 non-null    float64\n",
      " 23  FGC-FGC_GSD                             847 non-null    float64\n",
      " 24  FGC-FGC_GSD_Zone                        839 non-null    float64\n",
      " 25  FGC-FGC_PU                              1842 non-null   float64\n",
      " 26  FGC-FGC_PU_Zone                         1814 non-null   float64\n",
      " 27  FGC-FGC_SRL                             1842 non-null   float64\n",
      " 28  FGC-FGC_SRL_Zone                        1811 non-null   float64\n",
      " 29  FGC-FGC_SRR                             1844 non-null   float64\n",
      " 30  FGC-FGC_SRR_Zone                        1813 non-null   float64\n",
      " 31  FGC-FGC_TL                              1855 non-null   float64\n",
      " 32  FGC-FGC_TL_Zone                         1823 non-null   float64\n",
      " 33  BIA-Season                              1712 non-null   object \n",
      " 34  BIA-BIA_Activity_Level_num              1593 non-null   float64\n",
      " 35  BIA-BIA_BMC                             1567 non-null   float64\n",
      " 36  BIA-BIA_BMI                             1589 non-null   float64\n",
      " 37  BIA-BIA_BMR                             1592 non-null   float64\n",
      " 38  BIA-BIA_DEE                             1592 non-null   float64\n",
      " 39  BIA-BIA_ECW                             1592 non-null   float64\n",
      " 40  BIA-BIA_FFM                             1592 non-null   float64\n",
      " 41  BIA-BIA_FFMI                            1586 non-null   float64\n",
      " 42  BIA-BIA_FMI                             1564 non-null   float64\n",
      " 43  BIA-BIA_Fat                             1566 non-null   float64\n",
      " 44  BIA-BIA_Frame_num                       1593 non-null   float64\n",
      " 45  BIA-BIA_ICW                             1592 non-null   float64\n",
      " 46  BIA-BIA_LDM                             1592 non-null   float64\n",
      " 47  BIA-BIA_LST                             1592 non-null   float64\n",
      " 48  BIA-BIA_SMM                             1592 non-null   float64\n",
      " 49  BIA-BIA_TBW                             1592 non-null   float64\n",
      " 50  PAQ_A-Season                            382 non-null    object \n",
      " 51  PAQ_A-PAQ_A_Total                       382 non-null    float64\n",
      " 52  PAQ_C-Season                            1373 non-null   object \n",
      " 53  PAQ_C-PAQ_C_Total                       1373 non-null   float64\n",
      " 54  PCIAT-Season                            2195 non-null   object \n",
      " 55  PCIAT-PCIAT_01                          2192 non-null   float64\n",
      " 56  PCIAT-PCIAT_02                          2193 non-null   float64\n",
      " 57  PCIAT-PCIAT_03                          2190 non-null   float64\n",
      " 58  PCIAT-PCIAT_04                          2191 non-null   float64\n",
      " 59  PCIAT-PCIAT_05                          2190 non-null   float64\n",
      " 60  PCIAT-PCIAT_06                          2192 non-null   float64\n",
      " 61  PCIAT-PCIAT_07                          2190 non-null   float64\n",
      " 62  PCIAT-PCIAT_08                          2190 non-null   float64\n",
      " 63  PCIAT-PCIAT_09                          2189 non-null   float64\n",
      " 64  PCIAT-PCIAT_10                          2192 non-null   float64\n",
      " 65  PCIAT-PCIAT_11                          2193 non-null   float64\n",
      " 66  PCIAT-PCIAT_12                          2178 non-null   float64\n",
      " 67  PCIAT-PCIAT_13                          2189 non-null   float64\n",
      " 68  PCIAT-PCIAT_14                          2191 non-null   float64\n",
      " 69  PCIAT-PCIAT_15                          2190 non-null   float64\n",
      " 70  PCIAT-PCIAT_16                          2188 non-null   float64\n",
      " 71  PCIAT-PCIAT_17                          2185 non-null   float64\n",
      " 72  PCIAT-PCIAT_18                          2187 non-null   float64\n",
      " 73  PCIAT-PCIAT_19                          2190 non-null   float64\n",
      " 74  PCIAT-PCIAT_20                          2192 non-null   float64\n",
      " 75  PCIAT-PCIAT_Total                       2195 non-null   float64\n",
      " 76  SDS-Season                              2103 non-null   object \n",
      " 77  SDS-SDS_Total_Raw                       2094 non-null   float64\n",
      " 78  SDS-SDS_Total_T                         2092 non-null   float64\n",
      " 79  PreInt_EduHx-Season                     2823 non-null   object \n",
      " 80  PreInt_EduHx-computerinternet_hoursday  2633 non-null   float64\n",
      " 81  sii                                     2195 non-null   float64\n",
      "dtypes: float64(68), int64(2), object(12)\n",
      "memory usage: 2.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Now I replace the original train dataframe with the new cleaned data frame (where I've replaced bad values with NaN.)\n",
    "\n",
    "train=train_outliers_neg_to_NaN\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll export the dataframe to a csv.\n",
    "\n",
    "train_cleaned=train\n",
    "train_cleaned.to_csv('train_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I am going to impute input variables. \n",
    "I'm doing this before I remove the cases for which we can't compute sii scores, so that we have all data available.\n",
    "I am doing this in groups: For example, I will use only physical data to impute physical data values. This seems reasonable to do, although perhaps we might get more accurate results if we used more variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Because we will be using multiple imputation strategies, \n",
    "# I am going to define a new dataframe that will record all of the imputations using KNN.\n",
    "\n",
    "train_imp_KNN=train_cleaned.copy()\n",
    "\n",
    "# define a pipe that first scales the variables and then does a KNN imputation. \n",
    "# Note that when there is a case with no values at all, KNNImputer replaces fills in each variable with the group average.\n",
    "\n",
    "Number_Neighbors=5\n",
    "impute_pipe = Pipeline([('scale', StandardScaler()),\n",
    "                 ('KNN_impute', KNNImputer(n_neighbors=Number_Neighbors, weights='uniform', metric='nan_euclidean'))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Basic_nan_count\n",
       "0    3168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have complete information for the basic demographics variables, age and gender.\n",
    "\n",
    "Basic_Demos = [col for col in train_imp_KNN.columns if 'Basic' in col]\n",
    "Basic_Demos.remove('Basic_Demos-Enroll_Season')\n",
    "train_imp_KNN['Basic_nan_count'] = train_imp_KNN[Basic_Demos].isna().sum(axis=1)\n",
    "train_imp_KNN['Basic_nan_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical_nan_count\n",
      "1    1664\n",
      "7     716\n",
      "0     665\n",
      "6      45\n",
      "4      30\n",
      "3      27\n",
      "2      20\n",
      "5       1\n",
      "Name: count, dtype: int64\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#Next we'll consider the physical variables. There are many missing values here, including 688 cases with no values at all. We will do imputation.\n",
    "#Because age and gender are likely to be related to the Physical variables, I add these to the mix for imputation.\n",
    "#Note also that I have removed the season variable. I did this because it is not quantitative, so I can't easily run the imputation using this variable. \n",
    "#But this might be something to go back to later.\n",
    "\n",
    "Physical = [col for col in train_imp_KNN.columns if 'Physical' in col]\n",
    "Physical.remove('Physical-Season')\n",
    "Physical=Physical+Basic_Demos\n",
    "train_imp_KNN['Physical_nan_count'] = train_imp_KNN[Physical].isna().sum(axis=1)\n",
    "print(train_imp_KNN['Physical_nan_count'].value_counts())\n",
    "print(len(Physical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Physical-BMI                  3168 non-null   float64\n",
      " 1   Physical-Height               3168 non-null   float64\n",
      " 2   Physical-Weight               3168 non-null   float64\n",
      " 3   Physical-Waist_Circumference  3168 non-null   float64\n",
      " 4   Physical-Diastolic_BP         3168 non-null   float64\n",
      " 5   Physical-HeartRate            3168 non-null   float64\n",
      " 6   Physical-Systolic_BP          3168 non-null   float64\n",
      " 7   Basic_Demos-Age               3168 non-null   float64\n",
      " 8   Basic_Demos-Sex               3168 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 222.9 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for these variables. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[Physical]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "#Also, I reverse-transformed the data. My reasoning for doing this is that we want it in terms of the original scale to be able to make sense of things. \n",
    "#But since we are scaling twice, more rounding issues arise.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_physical=impute_pipe.transform(df)\n",
    "imputation_physical=impute_pipe.named_steps['scale'].inverse_transform(imputation_physical)\n",
    "df2 = pd.DataFrame(imputation_physical, columns=Physical)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[Physical]=train_imp_KNN[Physical].fillna(df2[Physical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness_nan_count\n",
      "17    1306\n",
      "3      650\n",
      "7      549\n",
      "4      435\n",
      "0      152\n",
      "5       21\n",
      "9       18\n",
      "8       10\n",
      "11       7\n",
      "12       6\n",
      "2        5\n",
      "14       3\n",
      "6        2\n",
      "13       2\n",
      "16       1\n",
      "15       1\n",
      "Name: count, dtype: int64\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#Next we'll consider the fitness test variables. \n",
    "# There are many missing values here, although it looks like we have at least some values for every case.\n",
    "#I kept in all of the zone variables, which means they have the same weight as the actual measurements. It seems like I shouldn't do this.\n",
    "\n",
    "Fitness = [col for col in train_imp_KNN.columns if 'Fitness' in col]+[col for col in train_imp_KNN.columns if 'FGC' in col]\n",
    "Fitness.remove('Fitness_Endurance-Season')\n",
    "Fitness.remove('FGC-Season')\n",
    "Fitness=Fitness+Basic_Demos\n",
    "train_imp_KNN['Fitness_nan_count'] = train_imp_KNN[Fitness].isna().sum(axis=1)\n",
    "print(train_imp_KNN['Fitness_nan_count'].value_counts())\n",
    "print(len(Fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 19 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Fitness_Endurance-Max_Stage  3168 non-null   float64\n",
      " 1   Fitness_Endurance-Time_Mins  3168 non-null   float64\n",
      " 2   Fitness_Endurance-Time_Sec   3168 non-null   float64\n",
      " 3   FGC-FGC_CU                   3168 non-null   float64\n",
      " 4   FGC-FGC_CU_Zone              3168 non-null   float64\n",
      " 5   FGC-FGC_GSND                 3168 non-null   float64\n",
      " 6   FGC-FGC_GSND_Zone            3168 non-null   float64\n",
      " 7   FGC-FGC_GSD                  3168 non-null   float64\n",
      " 8   FGC-FGC_GSD_Zone             3168 non-null   float64\n",
      " 9   FGC-FGC_PU                   3168 non-null   float64\n",
      " 10  FGC-FGC_PU_Zone              3168 non-null   float64\n",
      " 11  FGC-FGC_SRL                  3168 non-null   float64\n",
      " 12  FGC-FGC_SRL_Zone             3168 non-null   float64\n",
      " 13  FGC-FGC_SRR                  3168 non-null   float64\n",
      " 14  FGC-FGC_SRR_Zone             3168 non-null   float64\n",
      " 15  FGC-FGC_TL                   3168 non-null   float64\n",
      " 16  FGC-FGC_TL_Zone              3168 non-null   float64\n",
      " 17  Basic_Demos-Age              3168 non-null   float64\n",
      " 18  Basic_Demos-Sex              3168 non-null   float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 470.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for these variables. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[Fitness]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_fitness=impute_pipe.transform(df)\n",
    "imputation_fitness=impute_pipe.named_steps['scale'].inverse_transform(imputation_fitness)\n",
    "df2 = pd.DataFrame(imputation_fitness, columns=Fitness)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[Fitness]=train_imp_KNN[Fitness].fillna(df2[Fitness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIA_nan_count\n",
      "16    1575\n",
      "0     1537\n",
      "1       27\n",
      "2       21\n",
      "3        7\n",
      "12       1\n",
      "Name: count, dtype: int64\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#Next we'll consider the BIA variables. \n",
    "\n",
    "BIA = [col for col in train_imp_KNN.columns if 'BIA' in col]\n",
    "BIA.remove('BIA-Season')\n",
    "BIA=BIA+Basic_Demos\n",
    "train_imp_KNN['BIA_nan_count'] = train_imp_KNN[BIA].isna().sum(axis=1)\n",
    "print(train_imp_KNN['BIA_nan_count'].value_counts())\n",
    "print(len(BIA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 18 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   BIA-BIA_Activity_Level_num  3168 non-null   float64\n",
      " 1   BIA-BIA_BMC                 3168 non-null   float64\n",
      " 2   BIA-BIA_BMI                 3168 non-null   float64\n",
      " 3   BIA-BIA_BMR                 3168 non-null   float64\n",
      " 4   BIA-BIA_DEE                 3168 non-null   float64\n",
      " 5   BIA-BIA_ECW                 3168 non-null   float64\n",
      " 6   BIA-BIA_FFM                 3168 non-null   float64\n",
      " 7   BIA-BIA_FFMI                3168 non-null   float64\n",
      " 8   BIA-BIA_FMI                 3168 non-null   float64\n",
      " 9   BIA-BIA_Fat                 3168 non-null   float64\n",
      " 10  BIA-BIA_Frame_num           3168 non-null   float64\n",
      " 11  BIA-BIA_ICW                 3168 non-null   float64\n",
      " 12  BIA-BIA_LDM                 3168 non-null   float64\n",
      " 13  BIA-BIA_LST                 3168 non-null   float64\n",
      " 14  BIA-BIA_SMM                 3168 non-null   float64\n",
      " 15  BIA-BIA_TBW                 3168 non-null   float64\n",
      " 16  Basic_Demos-Age             3168 non-null   float64\n",
      " 17  Basic_Demos-Sex             3168 non-null   float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 445.6 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for these variables. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[BIA]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_BIA=impute_pipe.transform(df)\n",
    "imputation_BIA=impute_pipe.named_steps['scale'].inverse_transform(imputation_BIA)\n",
    "df2 = pd.DataFrame(imputation_BIA, columns=BIA)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[BIA]=train_imp_KNN[BIA].fillna(df2[BIA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGAS_nan_count\n",
      "0    1950\n",
      "1    1218\n",
      "Name: count, dtype: int64\n",
      "3\n",
      "['CGAS-CGAS_Score', 'Basic_Demos-Age', 'Basic_Demos-Sex']\n"
     ]
    }
   ],
   "source": [
    "#Next we consider CGAS (Children's Global Assessment Score). This measure comes from an evaluation by a trained professional. \n",
    "#Looking at the description, it seems reasonable that it is related to gender and age, so I am going to do KNN with those variables. \n",
    "\n",
    "CGAS = ['CGAS-CGAS_Score']+Basic_Demos\n",
    "train_imp_KNN['CGAS_nan_count'] = train_imp_KNN[CGAS].isna().sum(axis=1)\n",
    "print(train_imp_KNN['CGAS_nan_count'].value_counts())\n",
    "print(len(CGAS))\n",
    "print(CGAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CGAS-CGAS_Score  3168 non-null   float64\n",
      " 1   Basic_Demos-Age  3168 non-null   float64\n",
      " 2   Basic_Demos-Sex  3168 non-null   float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 74.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for this variable. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[CGAS]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_CGAS=impute_pipe.transform(df)\n",
    "imputation_CGAS=impute_pipe.named_steps['scale'].inverse_transform(imputation_CGAS)\n",
    "df2 = pd.DataFrame(imputation_CGAS, columns=CGAS)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[CGAS]=train_imp_KNN[CGAS].fillna(df2[CGAS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntHrs_nan_count\n",
      "0    2633\n",
      "1     535\n",
      "Name: count, dtype: int64\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Next we consider  PreInt_EduHx-computerinternet_hoursday. \n",
    "#It seems reasonable that it is related to gender and age, so I am going to do KNN with those variables. \n",
    "\n",
    "IntHrs = ['PreInt_EduHx-computerinternet_hoursday']+Basic_Demos\n",
    "train_imp_KNN['IntHrs_nan_count'] = train_imp_KNN[IntHrs].isna().sum(axis=1)\n",
    "print(train_imp_KNN['IntHrs_nan_count'].value_counts())\n",
    "print(len(IntHrs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   PreInt_EduHx-computerinternet_hoursday  3168 non-null   float64\n",
      " 1   Basic_Demos-Age                         3168 non-null   float64\n",
      " 2   Basic_Demos-Sex                         3168 non-null   float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 74.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Now I will impute values for this variable. First I'll define a new dataframe to work on.\n",
    "\n",
    "df=train_imp_KNN[IntHrs]\n",
    "\n",
    "#Now I run the impute pipe on this dataframe. First I fit the pipe to the data. I record the transform of the dataframe as imputation. \n",
    "# Imputation is a numpy array, so it needs to be converted back to a pandas dataframe.\n",
    "\n",
    "impute_pipe.fit(df)\n",
    "\n",
    "imputation_IntHrs=impute_pipe.transform(df)\n",
    "imputation_IntHrs=impute_pipe.named_steps['scale'].inverse_transform(imputation_IntHrs)\n",
    "df2 = pd.DataFrame(imputation_IntHrs, columns=IntHrs)\n",
    "df2.info()\n",
    "\n",
    "#Lastly, I replace the original values in the dataframe with the newly imputed values.\n",
    "\n",
    "train_imp_KNN[IntHrs]=train_imp_KNN[IntHrs].fillna(df2[IntHrs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the file focus on imputing values for the PCIAT questionaire, based on other responses to the questionaire, using k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN rates in original data:  0        True\n",
      "1       False\n",
      "2       False\n",
      "3        True\n",
      "4       False\n",
      "        ...  \n",
      "3163     True\n",
      "3164     True\n",
      "3165    False\n",
      "3166     True\n",
      "3167    False\n",
      "Name: pciatsnotna_sum, Length: 3168, dtype: bool\n",
      "NaN rates after the non-responders have been removed: pciatsnotna_sum\n",
      "20    2130\n",
      "0      974\n",
      "19      52\n",
      "18       9\n",
      "10       1\n",
      "15       1\n",
      "17       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#First we identify the columns of interest to search for NaN variables.\n",
    "\n",
    "pciats = [col for col in train_imp_KNN.columns if 'PCIAT' in col]\n",
    "pciats.remove('PCIAT-Season')\n",
    "pciats.remove('PCIAT-PCIAT_Total')\n",
    "\n",
    "# Create 20 new variables that indicate whether or not PCIAT-PCIAT_01 through PCIAT-PCIAT_20 were NaN\n",
    "\n",
    "for pciat in pciats:\n",
    "    train_imp_KNN[pciat + '_isnotna'] = train_imp_KNN[pciat].notna().astype(int)\n",
    "\n",
    "    \n",
    "\n",
    "#Create new variable that represents the sum of the questions answered.\n",
    "\n",
    "pciatsnotna = [col for col in train_imp_KNN.columns if 'isnotna' in col]\n",
    "train_imp_KNN['pciatsnotna_sum'] = train_imp_KNN[pciatsnotna].sum(axis=1)\n",
    "\n",
    "#Here, we can see NaN rates. Note that there are almost 1000 cases where the participants did not respond to any PCIAT questions. \n",
    "#These participants are eliminated. Note that when rows are eliminated, the original row indexing is preserved; therefore, I reset the index. \n",
    "#(This step is important to make sure indices match up when I later replace NaN entries with their imputed values.)\n",
    "\n",
    "print(\"NaN rates in original data: \",train_imp_KNN['pciatsnotna_sum'] != 0)\n",
    "train_imp_KNN.reset_index(drop=True, inplace=True)\n",
    "print(\"NaN rates after the non-responders have been removed:\",train_imp_KNN['pciatsnotna_sum'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we use KNN to impute the missing values.\n",
    "\n",
    "\n",
    "# define imputer\n",
    "Number_Neighbors=5\n",
    "imputer = KNNImputer(n_neighbors=Number_Neighbors, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "#The imputer.fit_transform function outputs a numpy array. So first I do the fitting, then convert the output back to a pandas dataframe.\n",
    "\n",
    "imputations=imputer.fit_transform(train_imp_KNN[pciats])\n",
    "df2 = pd.DataFrame(imputations, columns=pciats)\n",
    "\n",
    "#Next take the result and insert into the original dataframe. \n",
    "\n",
    "train_imp_KNN[pciats]=train_imp_KNN[pciats].fillna(df2[pciats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 90 columns):\n",
      " #   Column                                  Non-Null Count  Dtype   \n",
      "---  ------                                  --------------  -----   \n",
      " 0   id                                      3168 non-null   object  \n",
      " 1   Basic_Demos-Enroll_Season               3168 non-null   object  \n",
      " 2   Basic_Demos-Age                         3168 non-null   int64   \n",
      " 3   Basic_Demos-Sex                         3168 non-null   int64   \n",
      " 4   CGAS-Season                             2065 non-null   object  \n",
      " 5   CGAS-CGAS_Score                         3168 non-null   float64 \n",
      " 6   Physical-Season                         2642 non-null   object  \n",
      " 7   Physical-BMI                            3168 non-null   float64 \n",
      " 8   Physical-Height                         3168 non-null   float64 \n",
      " 9   Physical-Weight                         3168 non-null   float64 \n",
      " 10  Physical-Waist_Circumference            3168 non-null   float64 \n",
      " 11  Physical-Diastolic_BP                   3168 non-null   float64 \n",
      " 12  Physical-HeartRate                      3168 non-null   float64 \n",
      " 13  Physical-Systolic_BP                    3168 non-null   float64 \n",
      " 14  Fitness_Endurance-Season                1060 non-null   object  \n",
      " 15  Fitness_Endurance-Max_Stage             3168 non-null   float64 \n",
      " 16  Fitness_Endurance-Time_Mins             3168 non-null   float64 \n",
      " 17  Fitness_Endurance-Time_Sec              3168 non-null   float64 \n",
      " 18  FGC-Season                              2674 non-null   object  \n",
      " 19  FGC-FGC_CU                              3168 non-null   float64 \n",
      " 20  FGC-FGC_CU_Zone                         3168 non-null   float64 \n",
      " 21  FGC-FGC_GSND                            3168 non-null   float64 \n",
      " 22  FGC-FGC_GSND_Zone                       3168 non-null   float64 \n",
      " 23  FGC-FGC_GSD                             3168 non-null   float64 \n",
      " 24  FGC-FGC_GSD_Zone                        3168 non-null   float64 \n",
      " 25  FGC-FGC_PU                              3168 non-null   float64 \n",
      " 26  FGC-FGC_PU_Zone                         3168 non-null   float64 \n",
      " 27  FGC-FGC_SRL                             3168 non-null   float64 \n",
      " 28  FGC-FGC_SRL_Zone                        3168 non-null   float64 \n",
      " 29  FGC-FGC_SRR                             3168 non-null   float64 \n",
      " 30  FGC-FGC_SRR_Zone                        3168 non-null   float64 \n",
      " 31  FGC-FGC_TL                              3168 non-null   float64 \n",
      " 32  FGC-FGC_TL_Zone                         3168 non-null   float64 \n",
      " 33  BIA-Season                              1712 non-null   object  \n",
      " 34  BIA-BIA_Activity_Level_num              3168 non-null   float64 \n",
      " 35  BIA-BIA_BMC                             3168 non-null   float64 \n",
      " 36  BIA-BIA_BMI                             3168 non-null   float64 \n",
      " 37  BIA-BIA_BMR                             3168 non-null   float64 \n",
      " 38  BIA-BIA_DEE                             3168 non-null   float64 \n",
      " 39  BIA-BIA_ECW                             3168 non-null   float64 \n",
      " 40  BIA-BIA_FFM                             3168 non-null   float64 \n",
      " 41  BIA-BIA_FFMI                            3168 non-null   float64 \n",
      " 42  BIA-BIA_FMI                             3168 non-null   float64 \n",
      " 43  BIA-BIA_Fat                             3168 non-null   float64 \n",
      " 44  BIA-BIA_Frame_num                       3168 non-null   float64 \n",
      " 45  BIA-BIA_ICW                             3168 non-null   float64 \n",
      " 46  BIA-BIA_LDM                             3168 non-null   float64 \n",
      " 47  BIA-BIA_LST                             3168 non-null   float64 \n",
      " 48  BIA-BIA_SMM                             3168 non-null   float64 \n",
      " 49  BIA-BIA_TBW                             3168 non-null   float64 \n",
      " 50  PAQ_A-Season                            382 non-null    object  \n",
      " 51  PAQ_A-PAQ_A_Total                       382 non-null    float64 \n",
      " 52  PAQ_C-Season                            1373 non-null   object  \n",
      " 53  PAQ_C-PAQ_C_Total                       1373 non-null   float64 \n",
      " 54  PCIAT-Season                            2195 non-null   object  \n",
      " 55  PCIAT-PCIAT_01                          3168 non-null   float64 \n",
      " 56  PCIAT-PCIAT_02                          3168 non-null   float64 \n",
      " 57  PCIAT-PCIAT_03                          3168 non-null   float64 \n",
      " 58  PCIAT-PCIAT_04                          3168 non-null   float64 \n",
      " 59  PCIAT-PCIAT_05                          3168 non-null   float64 \n",
      " 60  PCIAT-PCIAT_06                          3168 non-null   float64 \n",
      " 61  PCIAT-PCIAT_07                          3168 non-null   float64 \n",
      " 62  PCIAT-PCIAT_08                          3168 non-null   float64 \n",
      " 63  PCIAT-PCIAT_09                          3168 non-null   float64 \n",
      " 64  PCIAT-PCIAT_10                          3168 non-null   float64 \n",
      " 65  PCIAT-PCIAT_11                          3168 non-null   float64 \n",
      " 66  PCIAT-PCIAT_12                          3168 non-null   float64 \n",
      " 67  PCIAT-PCIAT_13                          3168 non-null   float64 \n",
      " 68  PCIAT-PCIAT_14                          3168 non-null   float64 \n",
      " 69  PCIAT-PCIAT_15                          3168 non-null   float64 \n",
      " 70  PCIAT-PCIAT_16                          3168 non-null   float64 \n",
      " 71  PCIAT-PCIAT_17                          3168 non-null   float64 \n",
      " 72  PCIAT-PCIAT_18                          3168 non-null   float64 \n",
      " 73  PCIAT-PCIAT_19                          3168 non-null   float64 \n",
      " 74  PCIAT-PCIAT_20                          3168 non-null   float64 \n",
      " 75  PCIAT-PCIAT_Total                       2195 non-null   float64 \n",
      " 76  SDS-Season                              2103 non-null   object  \n",
      " 77  SDS-SDS_Total_Raw                       2094 non-null   float64 \n",
      " 78  SDS-SDS_Total_T                         2092 non-null   float64 \n",
      " 79  PreInt_EduHx-Season                     2823 non-null   object  \n",
      " 80  PreInt_EduHx-computerinternet_hoursday  3168 non-null   float64 \n",
      " 81  sii                                     2195 non-null   float64 \n",
      " 82  Basic_nan_count                         3168 non-null   int64   \n",
      " 83  Physical_nan_count                      3168 non-null   int64   \n",
      " 84  Fitness_nan_count                       3168 non-null   int64   \n",
      " 85  BIA_nan_count                           3168 non-null   int64   \n",
      " 86  CGAS_nan_count                          3168 non-null   int64   \n",
      " 87  IntHrs_nan_count                        3168 non-null   int64   \n",
      " 88  PCIAT_Total_Imputed                     3168 non-null   float64 \n",
      " 89  sii_Imputed                             3168 non-null   category\n",
      "dtypes: category(1), float64(69), int64(8), object(12)\n",
      "memory usage: 2.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#I recalculate the PCIAT total score. I also drop the variables that were added to detect NaN in the PCIAT data, just to tidy up a bit.\n",
    "\n",
    "train_imp_KNN['PCIAT_Total_Imputed'] = train_imp_KNN[pciats].sum(axis=1)\n",
    "train_imp_KNN = train_imp_KNN.drop(columns=pciatsnotna)\n",
    "train_imp_KNN = train_imp_KNN.drop(columns=['pciatsnotna_sum'])\n",
    "\n",
    "\n",
    "#Now we can calculate a new sii score with the imputed values. \n",
    "\n",
    "bins = [0, 30, 49,79,100]\n",
    "labels = [0,1,2,3]\n",
    "train_imp_KNN['sii_Imputed'] = pd.cut(train_imp_KNN['PCIAT_Total_Imputed'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "print(train_imp_KNN.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imp_KNN.to_csv('train_imp_KNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'm working on imputation using MICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
      "       'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
      "       'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
      "       'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
      "       'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
      "       'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
      "       'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
      "       'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
      "       'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
      "       'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
      "       'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
      "       'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
      "       'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
      "       'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
      "       'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
      "       'PAQ_C-PAQ_C_Total', 'PCIAT-Season', 'PCIAT-PCIAT_01', 'PCIAT-PCIAT_02',\n",
      "       'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06',\n",
      "       'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10',\n",
      "       'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14',\n",
      "       'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18',\n",
      "       'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total', 'SDS-Season',\n",
      "       'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
      "       'PreInt_EduHx-computerinternet_hoursday', 'sii'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# I am going to define a new dataframe that will record all of the imputations using MICE. I only want to apply MICE to the input variables, so I separate those out.\n",
    "#Also, MICE doesn't like categorical variables. I have just removed those--the seasons--for now.\n",
    "\n",
    "train_imp_MICE=train_cleaned.copy()\n",
    "\n",
    "print(train_imp_MICE.columns)\n",
    "\n",
    "features=['Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "        'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "       'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "       'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "        'Fitness_Endurance-Max_Stage',\n",
    "       'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "        'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "       'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "       'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "       'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', \n",
    "       'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "       'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "       'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "       'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "       'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total', \n",
    "       'PAQ_C-PAQ_C_Total',\n",
    "       'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', \n",
    "       'PreInt_EduHx-computerinternet_hoursday']\n",
    "\n",
    "df=train_imp_MICE[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New packages needed.\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(max_iter=10, random_state=497)\n",
    "\n",
    "df2= imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[353], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Now I fill in the missing values in train_imp_MICE with the MICE-imputed values. I am still using KNN for the pciats values. Then I export.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_imp_MICE[features]\u001b[38;5;241m=\u001b[39mtrain_imp_MICE[features]\u001b[38;5;241m.\u001b[39mfillna(\u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m train_imp_KNN[pciats]\u001b[38;5;241m=\u001b[39mtrain_imp_KNN[pciats]\u001b[38;5;241m.\u001b[39mfillna(train_imp_KNN[pciats])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Now I can export to a csv.\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "#Now I fill in the missing values in train_imp_MICE with the MICE-imputed values. I am still using KNN for the pciats values. Then I export.\n",
    "\n",
    "train_imp_MICE[features]=train_imp_MICE[features].fillna(df2[features])\n",
    "train_imp_KNN[pciats]=train_imp_KNN[pciats].fillna(train_imp_KNN[pciats])\n",
    "\n",
    "#Now I can export to a csv.\n",
    "\n",
    "train_imp_MICE.to_csv('train_imp_MICE.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
