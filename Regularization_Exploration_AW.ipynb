{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the data and separating out the three subsets of variables we'll be regressing: physical, fitness, and BIA\n",
    "\n",
    "Big question (for our mentor): for ridge regression, do we actually want to split this up three ways...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "# Note that (ridge) regression can't handle missing values. Since we'll do imputation later, we'll need to drop NaNs\n",
    "\n",
    "# Load the (split) data set train_imp.csv\n",
    "train = pd.read_csv('train_imp.csv')\n",
    "\n",
    "# Create a list of the 'physical' variables. Based on previous exploration, we can remove some variables and observations due to high rates of NaNs\n",
    "physical_vars = [col for col in train.columns if col.startswith('Physical') and train[col].dtype in ['float64', 'int64']]\n",
    "train_physical = train[physical_vars]\n",
    "train_physical = train_physical.drop(columns=['Physical-Waist_Circumference'])\n",
    "train_physical = train_physical.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# Create a list of the 'fitness' variables. Based on previous exploration, we can remove some variables and observations due to high rates of NaNs\n",
    "# Note that the Fitness_Endurance variables and the grip strength variables have too many missing values to include in the list\n",
    "train['FGC_Zone_Total'] = train['FGC-FGC_CU_Zone'] + train['FGC-FGC_PU_Zone'] + train['FGC-FGC_SRL_Zone'] + train['FGC-FGC_SRR_Zone'] + train['FGC-FGC_TL_Zone']\n",
    "fitness_vars = ['FGC-FGC_CU','FGC-FGC_PU','FGC-FGC_SRL','FGC-FGC_SRR','FGC-FGC_TL', 'FGC_Zone_Total']\n",
    "train_fitness = train[fitness_vars]\n",
    "train_fitness = train_fitness.dropna()\n",
    "\n",
    "\n",
    "# Create a new data set from train called train_bia that includes all variables that start with BIA-BIA_\n",
    "train_bia = train[[col for col in train.columns if col.startswith('BIA-BIA_')]]\n",
    "train_bia = train_bia.drop(columns=['BIA-BIA_Activity_Level_num','BIA-BIA_Frame_num'])\n",
    "train_bia = train_bia.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll do some hyperparameter tuning for the ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the hyperparameter is tuned, we'll compare the performance of the ridge regression and a PCA.\n",
    "\n",
    "Note that in previous explorations we've identified n=3 as the \"ideal\" number of PCA components for each set of predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate some models. From previous exploration, we've been using 3 components for the PCA\n",
    "ridge_pipe = Pipeline([('scale', StandardScaler()), ('ridge', Ridge())])\n",
    "pca_pipe = Pipeline([('scale', StandardScaler()), ('pca', PCA(1)), ('reg', LinearRegression())])\n",
    "\n",
    "# Fit the models to the training data\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "pca_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Find the model predictions on the training set\n",
    "lr_train_preds = lr.predict(X_train)\n",
    "ridge_train_preds = ridge_pipe.predict(X_train)\n",
    "pca_train_preds = pca_pipe.predict(X_train)\n",
    "\n",
    "# Find the model predictions on the test set\n",
    "lr_test_preds = lr.predict(X_test)\n",
    "ridge_test_preds = ridge_pipe.predict(X_test)\n",
    "pca_test_preds = pca_pipe.predict(X_test)\n",
    "\n",
    "# Find the mse on the training set\n",
    "lr_train_mse = mse(y_train, lr_train_preds)\n",
    "ridge_train_mse = mse(y_train, ridge_train_preds)\n",
    "pca_train_mse = mse(y_train, pca_train_preds)\n",
    "\n",
    "# Find the mse on the test set\n",
    "lr_test_mse = mse(y_test, lr_test_preds)\n",
    "ridge_test_mse = mse(y_test, ridge_test_preds)\n",
    "pca_test_mse = mse(y_test, pca_test_preds)\n",
    "\n",
    "# Results\n",
    "print(f\"OLS Training MSE: {lr_train_mse}\")\n",
    "print(f\"Ridge Training MSE: {ridge_train_mse}\")\n",
    "print(f\"PCA Training MSE: {pca_train_mse}\")\n",
    "print(f\"OLS Test MSE: {lr_test_mse}\")\n",
    "print(f\"Ridge Test MSE: {ridge_test_mse}\")\n",
    "print(f\"PCA Test MSE: {pca_test_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
