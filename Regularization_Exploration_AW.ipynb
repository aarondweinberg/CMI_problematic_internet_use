{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the data and separating out the three subsets of variables we'll be regressing: physical, fitness, and BIA\n",
    "\n",
    "Big question (for our mentor): for ridge regression, do we actually want to split this up three ways...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9z/6ssrlr3d4ln53k8ljbbv93p00000gn/T/ipykernel_17764/1140224443.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_physical['PCIAT-PCIAT_Total'] = train['PCIAT-PCIAT_Total']\n"
     ]
    }
   ],
   "source": [
    "# Import the data, including the outcome variable (in this case, PCIAT-PCIAT_Total)\n",
    "# Note that (ridge) regression can't handle missing values. Since we'll do imputation later, we'll need to drop NaNs\n",
    "\n",
    "# Load the (split) data set train_imp.csv\n",
    "train = pd.read_csv('train_cleaned.csv')\n",
    "\n",
    "# Create a list of the 'physical' variables. Based on previous exploration, we can remove some variables and observations due to high rates of NaNs\n",
    "physical_vars = [col for col in train.columns if col.startswith('Physical') and train[col].dtype in ['float64', 'int64']]\n",
    "train_physical = train[physical_vars]\n",
    "train_physical['PCIAT-PCIAT_Total'] = train['PCIAT-PCIAT_Total']\n",
    "train_physical = train_physical.drop(columns=['Physical-Waist_Circumference'])\n",
    "train_physical = train_physical.dropna()\n",
    "train_physical.name = 'Physical'\n",
    "\n",
    "# Create a list of the 'fitness' variables. Based on previous exploration, we can remove some variables and observations due to high rates of NaNs\n",
    "# Note that the Fitness_Endurance variables and the grip strength variables have too many missing values to include in the list\n",
    "train['FGC_Zone_Total'] = train['FGC-FGC_CU_Zone'] + train['FGC-FGC_PU_Zone'] + train['FGC-FGC_SRL_Zone'] + train['FGC-FGC_SRR_Zone'] + train['FGC-FGC_TL_Zone']\n",
    "fitness_vars = ['FGC-FGC_CU','FGC-FGC_PU','FGC-FGC_SRL','FGC-FGC_SRR','FGC-FGC_TL', 'FGC_Zone_Total', 'PCIAT-PCIAT_Total']\n",
    "train_fitness = train[fitness_vars]\n",
    "train_fitness = train_fitness.dropna()\n",
    "train_physical.name = 'Fitness'\n",
    "\n",
    "# Create a new data set from train called train_bia that includes all variables that start with BIA-BIA_\n",
    "train_bia = train[[col for col in train.columns if col.startswith('BIA-BIA_')]]\n",
    "train_bia = train_bia.drop(columns=['BIA-BIA_Activity_Level_num','BIA-BIA_Frame_num'])\n",
    "train_bia['PCIAT-PCIAT_Total'] = train['PCIAT-PCIAT_Total']\n",
    "train_bia = train_bia.dropna()\n",
    "train_physical.name = 'BIA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll do some hyperparameter tuning for the ridge regression\n",
    "\n",
    "We'll make a Ridge regression model and compute the MSE for each of several values of alpha\n",
    "\n",
    "We'll do this on a k-fold split of the training data (because that's always a good thing to do?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9z/6ssrlr3d4ln53k8ljbbv93p00000gn/T/ipykernel_17764/1258382530.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Identify the column of min_rmse that contains the minimum value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mbest_alpha_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_rmses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The alpha value with the lowest RMSE for the'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'variables is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_alpha_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Set up the kfold split\n",
    "num_splits = 5\n",
    "kfold = KFold(num_splits, shuffle=True)\n",
    "\n",
    "# Define a range of alpha values\n",
    "alphas = [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000]\n",
    "numalphas = len(alphas)\n",
    "\n",
    "# Create an empty array with num_splits rows and numalphas columns\n",
    "rmses = np.zeros((num_splits, numalphas))\n",
    "\n",
    "# A counter to loop through the splits\n",
    "i = 0\n",
    "\n",
    "# Iterate over the three data sets\n",
    "listofdatasets = [train_physical, train_fitness, train_bia]\n",
    "\n",
    "for df in listofdatasets:\n",
    "    for train_index, test_index in kfold.split(df):\n",
    "        tt_X = df.iloc[train_index].drop(columns=['PCIAT-PCIAT_Total'])\n",
    "        tt_y = df.iloc[train_index]['PCIAT-PCIAT_Total']\n",
    "        ho_X = df.iloc[test_index].drop(columns=['PCIAT-PCIAT_Total'])\n",
    "        ho_y = df.iloc[test_index]['PCIAT-PCIAT_Total']\n",
    "\n",
    "        # Iterate over alpha values with counter j\n",
    "        j = 0\n",
    "        for alpha in alphas:\n",
    "            model = Ridge(alpha=alpha)\n",
    "            model.fit(tt_X, tt_y)\n",
    "            y_pred = model.predict(ho_X)\n",
    "            rmses[i, j] = root_mean_squared_error(ho_y, y_pred)\n",
    "            \n",
    "            j=j+1\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "    # Compute the mean of each column of rmses\n",
    "    mean_rmses = np.mean(rmses, axis=0)\n",
    "\n",
    "    # Identify the column of min_rmse that contains the minimum value\n",
    "    best_alpha_index = np.argmin(mean_rmses)\n",
    "\n",
    "    print('The alpha value with the lowest RMSE for the', df.name, 'variables is', alphas[best_alpha_index])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.64702808, 18.64702808, 18.64702808, 18.64702803, 18.64702759,\n",
       "       18.64702322, 18.64698245, 18.64684388, 18.65627351])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rmses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the hyperparameter is tuned, we'll compare the performance of the ridge regression and a PCA.\n",
    "\n",
    "Note that in previous explorations we've identified n=3 as the \"ideal\" number of PCA components for each set of predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate some models. From previous exploration, we've been using 3 components for the PCA\n",
    "ridge_pipe = Pipeline([('scale', StandardScaler()), ('ridge', Ridge())])\n",
    "pca_pipe = Pipeline([('scale', StandardScaler()), ('pca', PCA(1)), ('reg', LinearRegression())])\n",
    "\n",
    "# Fit the models to the training data\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "pca_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Find the model predictions on the training set\n",
    "lr_train_preds = lr.predict(X_train)\n",
    "ridge_train_preds = ridge_pipe.predict(X_train)\n",
    "pca_train_preds = pca_pipe.predict(X_train)\n",
    "\n",
    "# Find the model predictions on the test set\n",
    "lr_test_preds = lr.predict(X_test)\n",
    "ridge_test_preds = ridge_pipe.predict(X_test)\n",
    "pca_test_preds = pca_pipe.predict(X_test)\n",
    "\n",
    "# Find the mse on the training set\n",
    "lr_train_mse = mse(y_train, lr_train_preds)\n",
    "ridge_train_mse = mse(y_train, ridge_train_preds)\n",
    "pca_train_mse = mse(y_train, pca_train_preds)\n",
    "\n",
    "# Find the mse on the test set\n",
    "lr_test_mse = mse(y_test, lr_test_preds)\n",
    "ridge_test_mse = mse(y_test, ridge_test_preds)\n",
    "pca_test_mse = mse(y_test, pca_test_preds)\n",
    "\n",
    "# Results\n",
    "print(f\"OLS Training MSE: {lr_train_mse}\")\n",
    "print(f\"Ridge Training MSE: {ridge_train_mse}\")\n",
    "print(f\"PCA Training MSE: {pca_train_mse}\")\n",
    "print(f\"OLS Test MSE: {lr_test_mse}\")\n",
    "print(f\"Ridge Test MSE: {ridge_test_mse}\")\n",
    "print(f\"PCA Test MSE: {pca_test_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
