{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals**\n",
    "\n",
    "1. Set up a pipeline to incorporate the imputation\n",
    "2. Do a random forest regressor to identify important features\n",
    "3. Do a test run with one model (linear, most likely) that computes:\n",
    "    - MSE for predicting PCIAT-Total\n",
    "    - MSE for predicting sii when computed from predicted PCIAT-Total\n",
    "    - MSE for predicting sii directly\n",
    "    - kappa for predicting sii when computed from predicted PCIAT-Total\n",
    "    - kappa for predicting sii directly\n",
    "4. After getting the model working, measure these things for out-of-the box:\n",
    "    - multiple linear regression\n",
    "    - knn regression\n",
    "    - random forest\n",
    "    - support vector\n",
    "    - gradient boost\n",
    "    - adaboost\n",
    "    - xgboost\n",
    "5. After identifying a promising out-of-the-box model, try tuning it\n",
    "6. Try implementing a sequential predictor (either logistic regression or random forest) that:\n",
    "    - Starts by predicting 3's vs. non-threes\n",
    "    - Predicts 2's vs. non-twos from the remaining cases\n",
    "    - etc.\n",
    "7. Try using different models for doing this sequential prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from CustomImputers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the Data**\n",
    "\n",
    "For the purpose of developing our model(s), we'll work with data that include the imputed outcome (PCIAT_Total and/or sii) scores AND have cleaned predictors.\n",
    "\n",
    "In the final version of our code, we'll work with data with cleaned predictors but won't have any access to the outcome scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the cleaned & outcome-imputed data\n",
    "train_cleaned=pd.read_csv('train_cleaned_outcome_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an initial list of predictor and outcome columns\n",
    "\n",
    "predictors = train_cleaned.columns.tolist()\n",
    "if 'id' in predictors:\n",
    "    predictors.remove('id')\n",
    "if 'sii' in predictors:\n",
    "    predictors.remove('sii')\n",
    "predictors = [x for x in predictors if 'PCIAT' not in x]\n",
    "predictors = [x for x in predictors if 'Season' not in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constructing a Random Forest for Feature Identification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic_Demos-Age</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physical-Height</td>\n",
       "      <td>0.133568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PreInt_EduHx-computerinternet_hoursday</td>\n",
       "      <td>0.090154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BIA-BIA_FFM</td>\n",
       "      <td>0.078891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SDS-SDS_Total_Raw</td>\n",
       "      <td>0.077490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ENMO_Avg_Active_Days_MVPA110</td>\n",
       "      <td>0.076964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Physical-Weight</td>\n",
       "      <td>0.074631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FGC-FGC_CU</td>\n",
       "      <td>0.037543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIA-BIA_FFMI</td>\n",
       "      <td>0.035215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BIA-BIA_Fat</td>\n",
       "      <td>0.032714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physical-BMI</td>\n",
       "      <td>0.025866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FGC-FGC_PU</td>\n",
       "      <td>0.016861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FGC-FGC_SR</td>\n",
       "      <td>0.016561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Physical-Waist_Circumference</td>\n",
       "      <td>0.014849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CGAS-CGAS_Score</td>\n",
       "      <td>0.013739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PAQ_Total</td>\n",
       "      <td>0.013214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fitness_Endurance-Max_Stage</td>\n",
       "      <td>0.013082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Fitness_Endurance_Total_Time_Sec</td>\n",
       "      <td>0.011283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ENMO_Avg_Active_Days_MVPA192</td>\n",
       "      <td>0.010839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FGC-FGC_TL</td>\n",
       "      <td>0.010569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BIA-BIA_FMI</td>\n",
       "      <td>0.010162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Physical-Systolic_BP</td>\n",
       "      <td>0.010094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Positive_Anglez_Active_Days</td>\n",
       "      <td>0.009720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BIA-BIA_Activity_Level_num</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BIA-BIA_Frame_num</td>\n",
       "      <td>0.008482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Physical-HeartRate</td>\n",
       "      <td>0.008466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Physical-Diastolic_BP</td>\n",
       "      <td>0.007252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic_Demos-Sex</td>\n",
       "      <td>0.004878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FGC-FGC_TL_Zone</td>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FGC-FGC_SR_Zone</td>\n",
       "      <td>0.000819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FGC-FGC_CU_Zone</td>\n",
       "      <td>0.000729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FGC-FGC_PU_Zone</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PAQ_Zone</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   feature  importance_score\n",
       "0                          Basic_Demos-Age          0.145000\n",
       "4                          Physical-Height          0.133568\n",
       "24  PreInt_EduHx-computerinternet_hoursday          0.090154\n",
       "18                             BIA-BIA_FFM          0.078891\n",
       "23                       SDS-SDS_Total_Raw          0.077490\n",
       "26            ENMO_Avg_Active_Days_MVPA110          0.076964\n",
       "5                          Physical-Weight          0.074631\n",
       "11                              FGC-FGC_CU          0.037543\n",
       "19                            BIA-BIA_FFMI          0.035215\n",
       "21                             BIA-BIA_Fat          0.032714\n",
       "3                             Physical-BMI          0.025866\n",
       "13                              FGC-FGC_PU          0.016861\n",
       "28                              FGC-FGC_SR          0.016561\n",
       "6             Physical-Waist_Circumference          0.014849\n",
       "2                          CGAS-CGAS_Score          0.013739\n",
       "30                               PAQ_Total          0.013214\n",
       "10             Fitness_Endurance-Max_Stage          0.013082\n",
       "32        Fitness_Endurance_Total_Time_Sec          0.011283\n",
       "25            ENMO_Avg_Active_Days_MVPA192          0.010839\n",
       "15                              FGC-FGC_TL          0.010569\n",
       "20                             BIA-BIA_FMI          0.010162\n",
       "9                     Physical-Systolic_BP          0.010094\n",
       "27             Positive_Anglez_Active_Days          0.009720\n",
       "17              BIA-BIA_Activity_Level_num          0.008525\n",
       "22                       BIA-BIA_Frame_num          0.008482\n",
       "8                       Physical-HeartRate          0.008466\n",
       "7                    Physical-Diastolic_BP          0.007252\n",
       "1                          Basic_Demos-Sex          0.004878\n",
       "16                         FGC-FGC_TL_Zone          0.001198\n",
       "29                         FGC-FGC_SR_Zone          0.000819\n",
       "12                         FGC-FGC_CU_Zone          0.000729\n",
       "14                         FGC-FGC_PU_Zone          0.000640\n",
       "31                                PAQ_Zone          0.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "pipe_mice = Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                    ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                    ('rf', RandomForestRegressor(n_estimators = 300, max_features = 'sqrt', max_depth = 5, random_state = 216))])\n",
    "\n",
    "pipe_mice.fit(train_cleaned[predictors],train_cleaned['PCIAT-PCIAT_Total'])\n",
    "\n",
    "train_pred_mice = pipe_mice.predict(train_cleaned[predictors])\n",
    "\n",
    "#Get feature importance from the rf inside pipe\n",
    "score_mice_df = pd.DataFrame({'feature':train_cleaned[predictors].columns,\n",
    "                            'importance_score': pipe_mice.named_steps['rf'].feature_importances_})\n",
    "\n",
    "score_mice_df.sort_values('importance_score',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyfeatures = ['Basic_Demos-Age',\n",
    " 'Physical-Height',\n",
    " 'PreInt_EduHx-computerinternet_hoursday',\n",
    " 'BIA-BIA_FFM',\n",
    " 'SDS-SDS_Total_Raw',\n",
    " 'Physical-Weight',\n",
    " 'ENMO_Avg_Active_Days_MVPA110',\n",
    " 'FGC-FGC_CU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trying a Linear Model**\n",
    "\n",
    "In this section, I'll make a linear model with a single predictor (hours spent on the internet)\n",
    "\n",
    "Note: Column selector documented here: https://stackoverflow.com/questions/62416223/how-to-select-only-few-columns-in-scikit-learn-column-selector-pipeline\n",
    "\n",
    "Note: custom loss functions for linear models are documented here: https://alexmiller.phd/posts/linear-model-custom-loss-function-regularization-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(347.8401450953909)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First I'll see if I can get a pipe set up to do prediction on a split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "train_tt, train_ho = train_test_split(train_cleaned, test_size=0.2)\n",
    "\n",
    "slr = Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', ['PreInt_EduHx-computerinternet_hoursday'])], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())])\n",
    "\n",
    "slr.fit(train_tt[predictors], train_tt['PCIAT-PCIAT_Total'])\n",
    "mean_squared_error(train_ho['PCIAT-PCIAT_Total'], slr.predict(train_ho))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An Ordinal (Sequential Binary) Classifier**\n",
    "\n",
    "It looks like our attempts so far have under-predicted sii values of 2 and 3. \n",
    "\n",
    "We'll create a class that first predicts whether or not the sii value is 0, then continues upward...\n",
    "This isn't quite the same as creating four separate binary predictors for 0, 1, 2, and 3 outcomes. We'll need to think about the code more to really know what it's doing.\n",
    "\n",
    "I came up with this idea myself, but I wasn't the first one to do it. It was described on Medium: https://towardsdatascience.com/simple-trick-to-train-an-ordinal-regression-with-any-classifier-6911183d2a3c from an article by Frank and Hal\n",
    "\n",
    "Also described on stackoverflow: https://stackoverflow.com/questions/57561189/multi-class-multi-label-ordinal-classification-with-sklearn\n",
    "\n",
    "Some discussion of the proposed code that highlights some of its issues is on stackoverflow: https://stackoverflow.com/questions/66486947/how-to-use-ordinal-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class OrdinalClassifier():\n",
    "\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "        self.clfs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.unique_class = np.sort(np.unique(y))\n",
    "        if self.unique_class.shape[0] > 2:\n",
    "            for i in range(self.unique_class.shape[0] - 1):\n",
    "                # for each k - 1 ordinal value we fit a binary classification problem\n",
    "                binary_y = (y > self.unique_class[i]).astype(np.uint8)\n",
    "                clf = clone(self.clf)\n",
    "                clf.fit(X, binary_y)\n",
    "                #print('binary_y has been fit for', self.unique_class[i])\n",
    "                self.clfs[i] = clf\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        clfs_predict = {k: v.predict_proba(X) for k, v in self.clfs.items()}\n",
    "        predicted = []\n",
    "        for i, y in enumerate(self.unique_class):\n",
    "            #print('encoding for i=', i)\n",
    "            if i == 0:\n",
    "                # V1 = 1 - Pr(y > V1)\n",
    "                predicted.append(1 - clfs_predict[i][:, 1])\n",
    "            elif y in clfs_predict:\n",
    "                # Vi = Pr(y > Vi-1) - Pr(y > Vi)\n",
    "                predicted.append(clfs_predict[i - 1][:, 1] - clfs_predict[i][:, 1])\n",
    "            else:\n",
    "                # Vk = Pr(y > Vk-1)\n",
    "                predicted.append(clfs_predict[i - 1][:, 1])\n",
    "        return np.vstack(predicted).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.unique_class[np.argmax(self.predict_proba(X), axis=1)]\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Models for Out-of-the-Box Performance**\n",
    "\n",
    "**Part 1: Setting Up Models**\n",
    "\n",
    "In the sections below, we'll set up a collection of un-tuned models and use them to predict sii scores. \n",
    "\n",
    "This first section instantiates the various models inside a dictionary that we'll use in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# Create classifiers to use as inputs to ordinal classifiers\n",
    "\n",
    "# Note that the logistic regression is failing to converge.\n",
    "# This can be addressed - see https://stackoverflow.com/questions/62658215/convergencewarning-lbfgs-failed-to-converge-status-1-stop-total-no-of-iter\n",
    "# Here we're increasing max_iter from its default and also adding a standard scaler into its pipeline\n",
    "# We could also adjust the solver, ad described here: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "logisticc = LogisticRegression(max_iter=1000)\n",
    "\n",
    "knnc=KNeighborsClassifier(10)\n",
    "svc = SVC()\n",
    "rfc = RandomForestClassifier()\n",
    "# Note that the default for adaboost is the SAMME.R algorithm, but this will be deprecated in future releases. Switching to SAMME\n",
    "adac = AdaBoostClassifier(algorithm='SAMME')\n",
    "gradc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n",
    "\n",
    "\n",
    "# List the various models we'll try to identify their \"out of the box\" performance\n",
    "models = {\n",
    "'slr_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', ['PreInt_EduHx-computerinternet_hoursday'])], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())]),\n",
    "\n",
    "'mlr_key_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', keyfeatures)], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())]),\n",
    "\n",
    "'mlr_all_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('linear', LinearRegression())]),\n",
    "\n",
    "'knn_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('knn', KNeighborsRegressor(10))]),\n",
    "\n",
    "'svr_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('rf', SVR())]),\n",
    "\n",
    "'rf_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('rf', RandomForestRegressor())]),\n",
    "\n",
    "'ada_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('ada', AdaBoostRegressor())]),\n",
    "\n",
    "'grad_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('grad', GradientBoostingRegressor())]),\n",
    "\n",
    "'xgb_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('xgb', XGBRegressor())]),\n",
    "\n",
    "'ordinal_logistic_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('scale', StandardScaler()),\n",
    "                ('logistic_oc', OrdinalClassifier(logisticc))]),\n",
    "\n",
    "'ordinal_knn_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('knn_ordinal', OrdinalClassifier(knnc))]),\n",
    "\n",
    "# Note that SVC doesn't have a predict_proba method. This can be manually added later in a custom classifier; removing for now to facilitate completion...\n",
    "#'ordinal_svc_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "#                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "#                ('svc_ordinal', OrdinalClassifier(svc))]),\n",
    "\n",
    "'ordinal_rf_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('rf_ordinal', OrdinalClassifier(rfc))]),\n",
    "\n",
    "'ordinal_ada_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('ada_ordinal', OrdinalClassifier(adac))]),\n",
    "\n",
    "'ordinal_grad_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('grad_ordinal', OrdinalClassifier(gradc))]),\n",
    "\n",
    "'ordinal_xgb_pipe' : Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('xgb_ordinal', OrdinalClassifier(xgbc))]),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Models for Out-of-the-Box Performance**\n",
    "\n",
    "**Part 2: Running Up Models**\n",
    "\n",
    "The second section runs the models through a 5-fold split to compute kappa values.\n",
    "\n",
    "We can predict sii scores in two ways:\n",
    "1. Predict the PCIAT_Total score and then compute sii values\n",
    "2. Predict the sii score directly\n",
    "\n",
    "We can also modify some of these computations by adjusting the bins for computing sii values and by adjusting the computed sii scores manually.\n",
    "\n",
    "One issue here is the extremely small number of sii=3 values in our data set. These are precisely the values we're most interested in predicting, since they most strongly indicate problematic internet use.\n",
    "\n",
    "A suggestion from stackoverflow is to over-sample the sii=3 instances; we've implemented this over-sampling inside the k-fold split to try to avoid data leakage:\n",
    "https://stackoverflow.com/questions/39512140/how-to-deal-with-this-unbalanced-class-skewed-data-set\n",
    "\n",
    "Note: Column selector documented here: https://stackoverflow.com/questions/62416223/how-to-select-only-few-columns-in-scikit-learn-column-selector-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Set up a list of the models and methods to organize the computation of means in the kfold split\n",
    "modellist = []\n",
    "for pipeline_name, pipeline_obj in models.items():\n",
    "    modellist.append(pipeline_name)\n",
    "\n",
    "methodlist = ['Compute SII from PCIAT (Standard Bins) (kappa)', \n",
    "              'Compute SII from PCIAT (Modified Bins) (kappa)',\n",
    "                'Predict SII (rounded) (kappa)',\n",
    "                'Predict SII (+0.1 rounded) (kappa)']\n",
    "\n",
    "num_splits = 5\n",
    "\n",
    "\n",
    "# Create an array with len(modellist) rows and len(methodlist) columns\n",
    "output = np.zeros((len(methodlist), len(modellist), num_splits))\n",
    "\n",
    "#Make a StratifiedKFold object stratified by the variable sii\n",
    "# This is necessary due to the small number of sii=3 values\n",
    "kfold = StratifiedKFold(n_splits=num_splits, shuffle=True)\n",
    "\n",
    "## i will count the split number \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(train_cleaned, train_cleaned['sii']):\n",
    "#for train_index, test_index in kfold.split(train_cleaned):\n",
    "    train_tt = train_cleaned.iloc[train_index]\n",
    "    train_ho = train_cleaned.iloc[test_index]\n",
    "\n",
    "    # The number of sii=3 values is so small, we'll try to boost prediction \n",
    "    # performance by duplicating the rows with this value\n",
    "    train_tt_sii3=train_tt[train_tt['sii']==3]\n",
    "    train_tt_sii3=pd.concat([train_tt_sii3]*4, ignore_index=True)\n",
    "    train_tt=pd.concat([train_tt,train_tt_sii3], ignore_index=True)\n",
    "    train_tt.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # j will enumerate the model\n",
    "    j=0\n",
    "\n",
    "    for pipeline_name, pipeline_obj in models.items():\n",
    "        # The ordinal predictors can't predict PCIAT scores, so we'll leave them out of the first round of computations\n",
    "        if 'ordinal' in pipeline_name:\n",
    "            kappa_sii_comp = 0\n",
    "            kappa_sii_comp_mod = 0\n",
    "        else:\n",
    "            # Fit and make predictions of PCIAT_Total\n",
    "            pipeline_obj.fit(train_tt[predictors], train_tt['PCIAT-PCIAT_Total'])\n",
    "            pred = pipeline_obj.predict(train_ho[predictors])\n",
    "\n",
    "            # Compute sii based on PCIAT and compute mse\n",
    "            bins = [0, 30, 49,79,100]\n",
    "            pred_bin = np.digitize(pred, bins)-1\n",
    "\n",
    "            # Try a slightly different set of bins suggested by the \"tuning\" below\n",
    "            bins_mod = [0, 27, 43, 71, 100]\n",
    "            pred_bin_mod = np.digitize(pred, bins_mod)-1\n",
    "\n",
    "            # Compute kappa values\n",
    "            kappa_sii_comp = cohen_kappa_score(train_ho['sii'], pred_bin, weights='quadratic')\n",
    "            kappa_sii_comp_mod = cohen_kappa_score(train_ho['sii'], pred_bin_mod, weights='quadratic')\n",
    "        \n",
    "        # Store the kappa values in the output array\n",
    "        output[0,j,i] = kappa_sii_comp\n",
    "        output[1,j,i] = kappa_sii_comp_mod\n",
    "        j=j+1\n",
    "\n",
    "    j=0\n",
    "    for pipeline_name, pipeline_obj in models.items():\n",
    "        # Fit and make predictions of sii\n",
    "        pipeline_obj.fit(train_tt[predictors], train_tt['sii'])\n",
    "        pred = pipeline_obj.predict(train_ho[predictors])\n",
    "\n",
    "        # Try two different ways of rounding the predictions\n",
    "        pred_round = np.round(pred)\n",
    "        pred_roundmod = np.round(pred+0.1)\n",
    "\n",
    "        # Compute and record the kappa values\n",
    "        kappa_sii_round = cohen_kappa_score(train_ho['sii'], pred_round, weights='quadratic')\n",
    "        kappa_sii_roundmod = cohen_kappa_score(train_ho['sii'], pred_roundmod, weights='quadratic')\n",
    "\n",
    "        output[2,j,i] = kappa_sii_round\n",
    "        output[3,j,i] = kappa_sii_roundmod\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "\n",
    "# Create a new array by computing the average of the values in output along the third axis\n",
    "output_avg = np.mean(output, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slr_pipe</th>\n",
       "      <th>mlr_key_pipe</th>\n",
       "      <th>mlr_all_pipe</th>\n",
       "      <th>knn_pipe</th>\n",
       "      <th>svr_pipe</th>\n",
       "      <th>rf_pipe</th>\n",
       "      <th>ada_pipe</th>\n",
       "      <th>grad_pipe</th>\n",
       "      <th>xgb_pipe</th>\n",
       "      <th>ordinal_logistic_pipe</th>\n",
       "      <th>ordinal_knn_pipe</th>\n",
       "      <th>ordinal_rf_pipe</th>\n",
       "      <th>ordinal_ada_pipe</th>\n",
       "      <th>ordinal_grad_pipe</th>\n",
       "      <th>ordinal_xgb_pipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Compute SII from PCIAT (Standard Bins) (kappa)</th>\n",
       "      <td>0.326215</td>\n",
       "      <td>0.426822</td>\n",
       "      <td>0.410880</td>\n",
       "      <td>0.291561</td>\n",
       "      <td>0.243216</td>\n",
       "      <td>0.401811</td>\n",
       "      <td>0.356389</td>\n",
       "      <td>0.408368</td>\n",
       "      <td>0.348377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compute SII from PCIAT (Modified Bins) (kappa)</th>\n",
       "      <td>0.347795</td>\n",
       "      <td>0.461043</td>\n",
       "      <td>0.445265</td>\n",
       "      <td>0.338944</td>\n",
       "      <td>0.278466</td>\n",
       "      <td>0.412807</td>\n",
       "      <td>0.417570</td>\n",
       "      <td>0.433329</td>\n",
       "      <td>0.373473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predict SII (rounded) (kappa)</th>\n",
       "      <td>0.279295</td>\n",
       "      <td>0.410669</td>\n",
       "      <td>0.417569</td>\n",
       "      <td>0.311799</td>\n",
       "      <td>0.333834</td>\n",
       "      <td>0.378713</td>\n",
       "      <td>0.252133</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.385170</td>\n",
       "      <td>0.384273</td>\n",
       "      <td>0.253311</td>\n",
       "      <td>0.307794</td>\n",
       "      <td>0.34374</td>\n",
       "      <td>0.426198</td>\n",
       "      <td>0.379592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predict SII (+0.1 rounded) (kappa)</th>\n",
       "      <td>0.329004</td>\n",
       "      <td>0.387273</td>\n",
       "      <td>0.403277</td>\n",
       "      <td>0.302074</td>\n",
       "      <td>0.349448</td>\n",
       "      <td>0.373556</td>\n",
       "      <td>0.196603</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.378786</td>\n",
       "      <td>0.384273</td>\n",
       "      <td>0.253311</td>\n",
       "      <td>0.307794</td>\n",
       "      <td>0.34374</td>\n",
       "      <td>0.426198</td>\n",
       "      <td>0.379592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                slr_pipe  ...  ordinal_xgb_pipe\n",
       "Compute SII from PCIAT (Standard Bins) (kappa)  0.326215  ...          0.000000\n",
       "Compute SII from PCIAT (Modified Bins) (kappa)  0.347795  ...          0.000000\n",
       "Predict SII (rounded) (kappa)                   0.279295  ...          0.379592\n",
       "Predict SII (+0.1 rounded) (kappa)              0.329004  ...          0.379592\n",
       "\n",
       "[4 rows x 15 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data frame from output using modellist as the names of the columns and methodlist as the names of the rows\n",
    "output_df = pd.DataFrame(output_avg, columns=modellist, index=methodlist)\n",
    "\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export output_df to a csv\n",
    "output_df.to_csv('output_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results of OOtB Investigation**\n",
    "\n",
    "* The multiple regression - both using all predictors and using just the \"key\" features had among the largest kappa values.\n",
    "* Gradient Boosting - both as a regressor and inside an ordinal classifier - was at or near the top of kappa values.\n",
    "* Logistic regression inside an ordinal classifier did well\n",
    "* Random forest performed decently for predicting PCIAT scores and then computing sii values\n",
    "* XGBoost performed decently for predicting sii values both via regression and inside an ordinal classifier.\n",
    "\n",
    "In general, adjusting the predicted sii values decreased kappa.\n",
    "\n",
    "Predicting PCIAT and then computing sii benefitted from adjusting the cutpoints.\n",
    "\n",
    "In the sections below, we'll \"tune\" the cutpoints and then try tuning a few of the models and re-testing the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning the Bins**\n",
    "\n",
    "We noticed that our model struggled to predict higher output values.\n",
    "\n",
    "When we adjusted the values for converting PCIAT scores to sii scores, we noticed an improvement in prediction when we lowered the cutpoints.\n",
    "\n",
    "We sought to \"tune\" these cutpoints. However, we need to be mindful of overfitting. \n",
    "\n",
    "We'll look at the combination of cutpoints that maximize kappa, and then from the top 20 (or so) select the cutpoints that are closest to the original ones (as measured by euclidean distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the multiple linear regression with \"key\" features to test the cutpoints\n",
    "# This model performed as good or better than most of the other (untuned) models\n",
    "# Since it is quick to run, it should be a decent choice for doing this tuning\n",
    "\n",
    "# Start by setting up the MLR pipeline\n",
    "mlr_key_pipe=Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('selector', ColumnTransformer([('selector', 'passthrough', keyfeatures)], remainder=\"drop\")),\n",
    "                ('linear', LinearRegression())])\n",
    "\n",
    "# Set the number of k-fold splits\n",
    "num_splits = 5\n",
    "\n",
    "# Set the number of different cutpoints to try\n",
    "num_bincuts=15\n",
    "\n",
    "# Create an array with len(modellist) rows and len(methodlist) columns\n",
    "output = np.zeros((num_bincuts, num_bincuts,num_bincuts, num_splits))\n",
    "\n",
    "#Make a KFold object, stratified on sii=3 values\n",
    "kfold= StratifiedKFold(n_splits=num_splits, shuffle=True)\n",
    "\n",
    "## i will count the split number \n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(train_cleaned, train_cleaned['sii']):\n",
    "    train_tt = train_cleaned.iloc[train_index]\n",
    "    train_ho = train_cleaned.iloc[test_index]\n",
    "\n",
    "    # As above, we're going to \"boost\" the number of observations with sii=3 to try to improve predictive performance\n",
    "    train_tt_sii3=train_tt[train_tt['sii']==3]\n",
    "    train_tt_sii3=pd.concat([train_tt_sii3]*4, ignore_index=True)\n",
    "    train_tt=pd.concat([train_tt,train_tt_sii3], ignore_index=True)\n",
    "    train_tt.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Fit the pipe and make predictions\n",
    "    mlr_key_pipe.fit(train_tt[predictors], train_tt['PCIAT-PCIAT_Total'])\n",
    "    pred = mlr_key_pipe.predict(train_ho[predictors])\n",
    "\n",
    "    # Iterate through values of the three cutpoints    \n",
    "    for r in range(num_bincuts):\n",
    "        for s in range(num_bincuts):\n",
    "            for t in range(num_bincuts):\n",
    "                bins = [0, 30-r, 49-s,79-t,100]\n",
    "                pred_bin_mod = np.digitize(pred, bins)-1\n",
    "                # Compute kappa for the binned predictions\n",
    "                kappa_sii_comp_mod = cohen_kappa_score(train_ho['sii'], pred_bin_mod, weights='quadratic')\n",
    "                output[r,s,t,i]=kappa_sii_comp_mod\n",
    "                \n",
    "    i=i+1\n",
    "\n",
    "# Create a new array by computing the average of the values in output along the third axis\n",
    "output_avg = np.mean(output, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll examine the output of the tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top values: [0.46371448 0.46365268 0.46320111 0.46320111 0.46320111 0.46320111\n",
      " 0.46296255 0.46289302 0.4627613  0.46267516 0.46244046 0.46244046\n",
      " 0.46244046 0.46244046 0.46227087 0.46222172 0.46222172 0.46222172\n",
      " 0.46222172 0.4621337 ]\n",
      "Locations of the top values: [(np.int64(3), np.int64(8), np.int64(13)), (np.int64(3), np.int64(8), np.int64(12)), (np.int64(3), np.int64(8), np.int64(9)), (np.int64(3), np.int64(8), np.int64(11)), (np.int64(3), np.int64(8), np.int64(8)), (np.int64(3), np.int64(8), np.int64(10)), (np.int64(3), np.int64(7), np.int64(13)), (np.int64(3), np.int64(7), np.int64(12)), (np.int64(3), np.int64(6), np.int64(13)), (np.int64(3), np.int64(6), np.int64(12)), (np.int64(3), np.int64(7), np.int64(11)), (np.int64(3), np.int64(7), np.int64(9)), (np.int64(3), np.int64(7), np.int64(8)), (np.int64(3), np.int64(7), np.int64(10)), (np.int64(3), np.int64(8), np.int64(14)), (np.int64(3), np.int64(6), np.int64(10)), (np.int64(3), np.int64(6), np.int64(9)), (np.int64(3), np.int64(6), np.int64(11)), (np.int64(3), np.int64(6), np.int64(8)), (np.int64(3), np.int64(8), np.int64(7))]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the array and sort the indices in descending order\n",
    "sorted_indices_flat = np.argsort(output_avg.ravel())[::-1]\n",
    "\n",
    "#Decide how many top values you want to look at. \n",
    "n=20\n",
    "\n",
    "# Get the flat indices of the top two values\n",
    "top_flat_indices = sorted_indices_flat[:n]\n",
    "\n",
    "# Convert the flat indices to 3D indices\n",
    "top_indices = [np.unravel_index(idx, output_avg.shape) for idx in top_flat_indices]\n",
    "\n",
    "# Retrieve the top two values\n",
    "top_values = output_avg.ravel()[top_flat_indices]\n",
    "\n",
    "print(\"Top values:\", top_values)\n",
    "print(\"Locations of the top values:\", top_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results of Cutpoint Tuning**\n",
    "\n",
    "Of the top 20 cutpoints, the combination that minimizes the Euclidean distance between the original and new cutpoints is:\n",
    "[0, 30-3, 49-6,79-8,100] = [0, 27, 43, 71, 100]\n",
    "\n",
    "We'll circle back around and try this in the loop above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**\n",
    "\n",
    "The models above were run \"out of the box.\" In the next sections, we'll try to tune a few of them (random forest, gradient boost, logistic regression inside an ordinal classifier, and, maybe, xgboost) to see how much we can improve their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning the Random Forest Regressor**\n",
    "\n",
    "In this section, we'll tune the random forest regressor.\n",
    "\n",
    "Note that using a pipeline with gridcvsearch requires slightly different naming conventions for the parameter grid: \n",
    "https://stackoverflow.com/questions/34889110/random-forest-with-gridsearchcv-error-on-param-grid\n",
    "\n",
    "Additional suggestions for only applying preprocessing before doing the gridsearchcv (not sure if we need this):\n",
    "https://stackoverflow.com/questions/43366561/use-sklearns-gridsearchcv-with-a-pipeline-preprocessing-just-once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/numpy/ma/core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x152247b00&gt;)),\n",
       "                                       (&#x27;rf&#x27;, RandomForestRegressor())]),\n",
       "             param_grid={&#x27;rf__max_depth&#x27;: range(1, 2),\n",
       "                         &#x27;rf__min_samples_split&#x27;: [2, 4, 8],\n",
       "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                                       (&#x27;add_zones&#x27;,\n",
       "                                        FunctionTransformer(func=&lt;function zone_encoder at 0x152247b00&gt;)),\n",
       "                                       (&#x27;rf&#x27;, RandomForestRegressor())]),\n",
       "             param_grid={&#x27;rf__max_depth&#x27;: range(1, 2),\n",
       "                         &#x27;rf__min_samples_split&#x27;: [2, 4, 8],\n",
       "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                (&#x27;add_zones&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function zone_encoder at 0x152247b00&gt;)),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor(max_depth=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Custom_MICE_Imputer</label><div class=\"sk-toggleable__content fitted\"><pre>Custom_MICE_Imputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function zone_encoder at 0x152247b00&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('mice_impute', Custom_MICE_Imputer()),\n",
       "                                       ('add_zones',\n",
       "                                        FunctionTransformer(func=<function zone_encoder at 0x152247b00>)),\n",
       "                                       ('rf', RandomForestRegressor())]),\n",
       "             param_grid={'rf__max_depth': range(1, 2),\n",
       "                         'rf__min_samples_split': [2, 4, 8],\n",
       "                         'rf__n_estimators': [50, 100, 200]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#max_depths = range(1, 11)\n",
    "max_depths = range(1, 2)\n",
    "n_trees = [100, 500]\n",
    "\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': range(1,2),\n",
    "    'rf__min_samples_split': [2, 4, 8]\n",
    "}\n",
    "\n",
    "# Cohen's kappa isn't included in the list of metrics by default\n",
    "# We can make a kappa scorer to still use it in GridSearch\n",
    "kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "\n",
    "# Instantiate a random forest pipeline\n",
    "rf_pipe = Pipeline([('mice_impute', Custom_MICE_Imputer()),\n",
    "                ('add_zones', FunctionTransformer(zone_encoder)),\n",
    "                ('rf', RandomForestRegressor())])\n",
    "\n",
    "grid_cv_rf = GridSearchCV(rf_pipe, \n",
    "                          param_grid = param_grid, \n",
    "                          #scoring = kappa_scorer,  #We don't want to use kappa for PCIAT predictions\n",
    "                          cv = 5)\n",
    "\n",
    "#clf_rf = make_pipeline(Custom_MICE_Imputer(),\n",
    "#                       FunctionTransformer(zone_encoder),\n",
    "#                       GridSearchCV(RandomForestRegressor(),\n",
    "#                                 param_grid={'max_depth':max_depths,\n",
    "#                                             'n_estimators': n_trees},\n",
    "#                                scoring=kappa_scorer,\n",
    "#                                cv=5,\n",
    "#                                refit=True))\n",
    "\n",
    "#clf_rf.fit(train_cleaned[predictors], train_cleaned['PCIAT-PCIAT_Total'])\n",
    "#clf_rf.predict()\n",
    "\n",
    "# We'll start by tuning on PCIAT, and can tune separately on sii\n",
    "grid_cv_rf.fit(train_cleaned[predictors], train_cleaned['PCIAT-PCIAT_Total'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You can find the hyperparameter grid point that\n",
    "## gave the best performance like so\n",
    "## .best_params_\n",
    "\n",
    "# Get .best_params from the GridSearchCV inside the clf_rf pipeline\n",
    "grid_cv_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.17582149615134404)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You can find the best score like so\n",
    "## .best_score_\n",
    "grid_cv_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                (&#x27;add_zones&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function zone_encoder at 0x152247b00&gt;)),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor(max_depth=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;mice_impute&#x27;, Custom_MICE_Imputer()),\n",
       "                (&#x27;add_zones&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function zone_encoder at 0x152247b00&gt;)),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor(max_depth=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Custom_MICE_Imputer</label><div class=\"sk-toggleable__content fitted\"><pre>Custom_MICE_Imputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function zone_encoder at 0x152247b00&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=1)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('mice_impute', Custom_MICE_Imputer()),\n",
       "                ('add_zones',\n",
       "                 FunctionTransformer(func=<function zone_encoder at 0x152247b00>)),\n",
       "                ('rf', RandomForestRegressor(max_depth=1))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calling best_estimator_ returns the model with the \n",
    "## best avg cv performance after it has been refit on the\n",
    "## entire data set\n",
    "grid_cv_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_rf.best_estimator_.predict(train_ho[predictors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Neural Regression to Predict Ordinal Outcomes**\n",
    "\n",
    "It looks like we could also use \"neural regression\" (PyTorch) to do the prediction. \n",
    "\n",
    "Here is a website that describes how to accomplish this: https://visualstudiomagazine.com/articles/2021/10/04/ordinal-classification-pytorch.aspx\n",
    "\n",
    "The code below is copied from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# house_price_ord.py\n",
    "# predict ordinal price from AC, sq ft, style, nearest school\n",
    "# PyTorch 1.8.0-CPU Anaconda3-2020.02  Python 3.7.6\n",
    "# Windows 10 \n",
    "\n",
    "import numpy as np\n",
    "import torch as T\n",
    "device = T.device(\"cpu\")  # apply to Tensor or Module\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class HouseDataset(T.utils.data.Dataset):\n",
    "  # AC  sq ft   style  price   school\n",
    "  # -1  0.2500  0 1 0    3     0 1 0\n",
    "  #  1  0.1275  1 0 0    2     0 0 1\n",
    "  # air condition: -1 = no, +1 = yes\n",
    "  # style: art_deco, bungalow, colonial\n",
    "  # price: k=4: 0 = low, 1 = medium, 2 = high, 3 = very high\n",
    "  # school: johnson, kennedy, lincoln\n",
    "\n",
    "  def __init__(self, src_file, k):\n",
    "    # k for programmtic approach\n",
    "    all_xy = np.loadtxt(src_file, \n",
    "      usecols=[0,1,2,3,4,5,6,7,8], delimiter=\"\\t\",\n",
    "      comments=\"#\", skiprows=0, dtype=np.float32)\n",
    "\n",
    "    tmp_x = all_xy[:,[0,1,2,3,4,6,7,8]]\n",
    "    tmp_y = all_xy[:,5]    # 1D -- 2D will be required\n",
    "\n",
    "    n = len(tmp_y)\n",
    "    for i in range(n):  # hard-coded is easy to understand\n",
    "      if int(tmp_y[i])   == 0: tmp_y[i] = 0.125\n",
    "      elif int(tmp_y[i]) == 1: tmp_y[i] = 0.375\n",
    "      elif int(tmp_y[i]) == 2: tmp_y[i] = 0.625\n",
    "      elif int(tmp_y[i]) == 3: tmp_y[i] = 0.875\n",
    "      else: print(\"Fatal logic error \")\n",
    "\n",
    "    tmp_y = np.reshape(tmp_y, (-1,1))  # 2D    \n",
    "\n",
    "    self.x_data = T.tensor(tmp_x, \\\n",
    "      dtype=T.float32).to(device)\n",
    "    self.y_data = T.tensor(tmp_y, \\\n",
    "      dtype=T.float32).to(device)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    preds = self.x_data[idx,:]  # or just [idx]\n",
    "    price = self.y_data[idx,:] \n",
    "    return (preds, price)       # tuple of two matrices \n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.hid1 = T.nn.Linear(8, 10)  # 8-(10-10)-1\n",
    "    self.hid2 = T.nn.Linear(10, 10)\n",
    "    self.oupt = T.nn.Linear(10, 1)  # [0.0 to 1.0]\n",
    "\n",
    "    T.nn.init.xavier_uniform_(self.hid1.weight)\n",
    "    T.nn.init.zeros_(self.hid1.bias)\n",
    "    T.nn.init.xavier_uniform_(self.hid2.weight)\n",
    "    T.nn.init.zeros_(self.hid2.bias)\n",
    "    T.nn.init.xavier_uniform_(self.oupt.weight)\n",
    "    T.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = T.tanh(self.hid1(x))\n",
    "    z = T.tanh(self.hid2(z))\n",
    "    z = T.sigmoid(self.oupt(z))  # \n",
    "    return z\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def accuracy(model, ds, k):\n",
    "  n_correct = 0; n_wrong = 0\n",
    "  acc_delta = (1.0 / k) / 2   # if k=4 delta = 0.125\n",
    "  for i in range(len(ds)):    # each input\n",
    "    (X, y) = ds[i]            # (predictors, target)\n",
    "    with T.no_grad():         # y target is like 0.375\n",
    "      oupt = model(X)         # oupt is in [0.0, 1.0]\n",
    "\n",
    "    if T.abs(oupt - y) <= acc_delta:\n",
    "      n_correct += 1\n",
    "    else:\n",
    "      n_wrong += 1\n",
    "\n",
    "  acc = (n_correct * 1.0) / (n_correct + n_wrong)\n",
    "  return acc\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def accuracy_old(model, ds, k):\n",
    "  model.eval()\n",
    "  n_correct = 0; n_wrong = 0\n",
    "  for i in range(len(ds)):\n",
    "    (X, Y) = ds[i]            # (predictors, target)\n",
    "    with T.no_grad():\n",
    "      oupt = model(X)         # computed is in 0.0 to 1.0\n",
    "    if oupt >= 0.0 and oupt < 0.25 and Y == 0.125:  # ugly\n",
    "      n_correct += 1\n",
    "    elif oupt >= 0.25 and oupt < 0.50 and Y == 0.375:\n",
    "      n_correct += 1\n",
    "    elif oupt >= 0.50 and oupt < 0.75 and Y == 0.625:\n",
    "      n_correct += 1\n",
    "    elif oupt >= 0.75 and Y == 0.875:\n",
    "      n_correct += 1\n",
    "    else:\n",
    "      n_wrong += 1\n",
    "  acc = (n_correct * 1.0) / (n_correct + n_wrong)\n",
    "  return acc\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def train(net, ds, bs, lr, me, le):\n",
    "  # network, dataset, batch_size, learn_rate, \n",
    "  # max_epochs, log_every\n",
    "  train_ldr = T.utils.data.DataLoader(ds,\n",
    "    batch_size=bs, shuffle=True)\n",
    "  loss_func = T.nn.MSELoss()\n",
    "  opt = T.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "  for epoch in range(0, me):\n",
    "    # T.manual_seed(1+epoch)  # recovery reproducibility\n",
    "    epoch_loss = 0  # for one full epoch\n",
    "\n",
    "    for (b_idx, batch) in enumerate(train_ldr):\n",
    "      (X, y) = batch           # (predictors, targets)\n",
    "      opt.zero_grad()          # prepare gradients\n",
    "      oupt = net(X)            # predicted prices\n",
    "\n",
    "      loss_val = loss_func(oupt, y)  # a tensor\n",
    "      epoch_loss += loss_val.item()  # accumulate\n",
    "      loss_val.backward()  # compute gradients\n",
    "      opt.step()           # update weights\n",
    "\n",
    "    if epoch % le == 0:\n",
    "      print(\"epoch = %4d   loss = %0.4f\" % \\\n",
    "       (epoch, epoch_loss))\n",
    "      # TODO: save checkpoint\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def float_oupt_to_class(oupt, k):\n",
    "  end_pts = np.zeros(k+1, dtype=np.float32) \n",
    "  delta = 1.0 / k\n",
    "  for i in range(k):\n",
    "    end_pts[i] = i * delta\n",
    "  end_pts[k] = 1.0\n",
    "  # if k=4, [0.0, 0.25, 0.50, 0.75, 1.0] \n",
    "\n",
    "  for i in range(k):\n",
    "    if oupt >= end_pts[i] and oupt <= end_pts[i+1]:\n",
    "      return i\n",
    "  return -1  # fatal error \n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "  # 0. get started\n",
    "  print(\"\\nBegin predict House ordinal price \\n\")\n",
    "  T.manual_seed(1)  # representative results \n",
    "  np.random.seed(1)\n",
    "  \n",
    "  # 1. create Dataset objects\n",
    "  print(\"Creating Houses Dataset objects \")\n",
    "  print(\"Converting ordinal labels to float targets \")\n",
    "  train_file = \".\\\\Data\\\\houses_train_ord.txt\"\n",
    "  train_ds = HouseDataset(train_file, k=4)  # 200 rows\n",
    "\n",
    "  test_file = \".\\\\Data\\\\houses_test_ord.txt\"\n",
    "  test_ds = HouseDataset(test_file, k=4)  # 40 rows\n",
    "\n",
    "  # 2. create network\n",
    "  print(\"\\nCreating 8-10-10-1 neural network \")\n",
    "  net = Net().to(device)\n",
    "  net.train()   # set mode\n",
    "\n",
    "  # 3. train model\n",
    "  bat_size = 10\n",
    "  lrn_rate = 0.010\n",
    "  max_epochs = 500\n",
    "  log_every = 100\n",
    "\n",
    "  print(\"\\nbat_size = %3d \" % bat_size)\n",
    "  print(\"lrn_rate = %0.3f \" % lrn_rate)\n",
    "  print(\"loss = MSELoss \")\n",
    "  print(\"optimizer = Adam \")\n",
    "  print(\"max_epochs = %3d \" % max_epochs)\n",
    "\n",
    "  print(\"\\nStarting training \")\n",
    "  train(net, train_ds, bat_size, lrn_rate, \n",
    "    max_epochs, log_every)\n",
    "  print(\"Training complete \")\n",
    "\n",
    "  # 4. evaluate model accuracy\n",
    "  print(\"\\nComputing model accuracy\")\n",
    "  net.eval()  # set mode\n",
    "  acc_train = accuracy(net, train_ds, k=4) \n",
    "  print(\"Accuracy on train data = %0.4f\" % \\\n",
    "    acc_train)\n",
    "\n",
    "  acc_test = accuracy(net, test_ds, k=4) \n",
    "  print(\"Accuracy on test data  = %0.4f\" % \\\n",
    "    acc_test)\n",
    "\n",
    "  # 5. save trained model (TODO)\n",
    "  print(\"\\nSaving trained model as houses_model.h5 \")\n",
    "  # model.save_weights(\".\\\\Models\\\\houses_model_wts.h5\")\n",
    "  # model.save(\".\\\\Models\\\\houses_model.h5\")\n",
    "\n",
    "  # 6. make a prediction\n",
    "  print(\"\\nPredicting house price for AC=no, sqft=2300, \")\n",
    "  print(\" style=colonial, school=kennedy: \")\n",
    "  unk = np.array([[-1, 0.2300,  0,0,1,  0,1,0]],\n",
    "    dtype=np.float32)\n",
    "  unk = T.tensor(unk, dtype=T.float32).to(device) \n",
    "\n",
    "  with T.no_grad():\n",
    "    pred_price = net(unk)\n",
    "  pred_price = pred_price.item()  # scalar 0.0 to 1.0\n",
    "  print(\"\\nPredicted price raw output: %0.4f\" % \\\n",
    "    pred_price)\n",
    "\n",
    "  labels = [\"low\", \"medium\", \"high\", \"very high\"]\n",
    "  c = float_oupt_to_class(pred_price, k=4)\n",
    "  print(\"Predicted price ordinal label: %d \" % c)\n",
    "  print(\"Predicted price friendly class: %s \" % \\\n",
    "    labels[c])\n",
    "\n",
    "  print(\"\\nEnd House ordinal price demo\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "\n",
    "# ===========\n",
    "# houses_train_ord.txt\n",
    "# AC (-1 = no), sq_ft, style (one-hot)\n",
    "# price (0=low, 1=med, 2=high, 3=v. high), \n",
    "# school (one-hot)\n",
    "#   -1   0.1275   0   1   0   0   0   0   1\n",
    "#    1   0.1100   1   0   0   0   1   0   0\n",
    "#   -1   0.1375   0   0   1   0   0   1   0\n",
    "#    1   0.1975   0   1   0   2   0   0   1\n",
    "#   -1   0.1200   0   0   1   0   1   0   0\n",
    "#   -1   0.2500   0   1   0   2   0   1   0\n",
    "#    1   0.1275   1   0   0   1   0   0   1\n",
    "#   -1   0.1750   0   0   1   1   0   0   1\n",
    "#   -1   0.2500   0   1   0   2   0   0   1\n",
    "#    1   0.1800   0   1   0   1   1   0   0\n",
    "#    1   0.0975   1   0   0   0   0   0   1\n",
    "#   -1   0.1100   0   1   0   0   0   1   0\n",
    "#    1   0.1975   0   0   1   1   0   0   1\n",
    "#   -1   0.3175   1   0   0   3   0   1   0\n",
    "#   -1   0.1700   0   1   0   1   1   0   0\n",
    "#    1   0.1650   0   1   0   1   0   1   0\n",
    "#   -1   0.2250   0   1   0   2   0   1   0\n",
    "#   -1   0.2125   0   1   0   2   0   1   0\n",
    "#    1   0.1675   0   1   0   1   0   1   0\n",
    "#    1   0.1550   1   0   0   1   0   1   0\n",
    "#   -1   0.1375   0   0   1   0   1   0   0\n",
    "#   -1   0.2425   0   1   0   2   1   0   0\n",
    "#    1   0.3200   0   0   1   3   0   1   0\n",
    "#   -1   0.3075   1   0   0   3   0   1   0\n",
    "#   -1   0.2700   1   0   0   2   0   0   1\n",
    "#    1   0.1700   0   1   0   1   0   0   1\n",
    "#   -1   0.1475   1   0   0   1   1   0   0\n",
    "#   -1   0.2500   0   1   0   2   0   0   1\n",
    "#   -1   0.2750   1   0   0   2   0   0   1\n",
    "#   -1   0.2000   1   0   0   2   1   0   0\n",
    "#   -1   0.1100   0   0   1   0   1   0   0\n",
    "#   -1   0.3400   1   0   0   3   0   1   0\n",
    "#    1   0.3000   0   0   1   3   1   0   0\n",
    "#    1   0.1550   0   1   0   1   0   1   0\n",
    "#   -1   0.2150   0   1   0   1   0   0   1\n",
    "#   -1   0.2900   0   0   1   3   0   1   0\n",
    "#    1   0.2750   0   0   1   2   0   1   0\n",
    "#    1   0.2175   0   1   0   2   0   1   0\n",
    "#    1   0.2150   0   1   0   2   0   0   1\n",
    "#    1   0.1050   1   0   0   1   1   0   0\n",
    "#   -1   0.2775   1   0   0   2   0   0   1\n",
    "#   -1   0.3225   1   0   0   3   0   1   0\n",
    "#    1   0.2075   0   1   0   2   1   0   0\n",
    "#   -1   0.3225   1   0   0   3   0   0   1\n",
    "#    1   0.2800   0   0   1   3   0   0   1\n",
    "#   -1   0.1575   0   1   0   1   0   0   1\n",
    "#    1   0.3250   0   0   1   3   0   0   1\n",
    "#   -1   0.2750   1   0   0   2   0   0   1\n",
    "#    1   0.1250   1   0   0   1   1   0   0\n",
    "#   -1   0.2325   0   1   0   2   0   0   1\n",
    "#    1   0.1825   1   0   0   2   1   0   0\n",
    "#   -1   0.2600   0   1   0   2   0   1   0\n",
    "#   -1   0.3075   1   0   0   3   0   0   1\n",
    "#   -1   0.2875   1   0   0   3   0   0   1\n",
    "#    1   0.2300   0   1   0   2   0   1   0\n",
    "#    1   0.3100   0   0   1   3   1   0   0\n",
    "#   -1   0.2750   1   0   0   2   0   0   1\n",
    "#    1   0.1125   0   1   0   0   0   0   1\n",
    "#    1   0.2525   1   0   0   2   1   0   0\n",
    "#    1   0.1625   0   1   0   1   0   1   0\n",
    "#    1   0.1075   1   0   0   1   0   0   1\n",
    "#   -1   0.2200   0   1   0   2   0   1   0\n",
    "#   -1   0.2300   0   1   0   2   0   1   0\n",
    "#   -1   0.3100   1   0   0   3   0   1   0\n",
    "#   -1   0.2875   1   0   0   3   0   1   0\n",
    "#    1   0.3375   0   0   1   3   0   0   1\n",
    "#   -1   0.1450   0   0   1   0   1   0   0\n",
    "#   -1   0.2650   1   0   0   2   1   0   0\n",
    "#    1   0.2225   0   1   0   2   1   0   0\n",
    "#   -1   0.2300   0   1   0   2   0   1   0\n",
    "#    1   0.1025   0   1   0   0   0   1   0\n",
    "#    1   0.1925   0   1   0   2   1   0   0\n",
    "#   -1   0.2525   0   1   0   2   0   1   0\n",
    "#   -1   0.1650   0   1   0   1   0   1   0\n",
    "#    1   0.1650   0   1   0   1   0   1   0\n",
    "#   -1   0.1300   1   0   0   1   0   1   0\n",
    "#   -1   0.2900   1   0   0   3   1   0   0\n",
    "#   -1   0.2175   0   1   0   1   0   0   1\n",
    "#    1   0.2300   1   0   0   2   1   0   0\n",
    "#   -1   0.3000   1   0   0   3   1   0   0\n",
    "#    1   0.2125   0   1   0   1   1   0   0\n",
    "#    1   0.2825   0   0   1   2   0   0   1\n",
    "#    1   0.3125   0   0   1   3   0   1   0\n",
    "#    1   0.2500   0   1   0   2   1   0   0\n",
    "#   -1   0.2375   0   1   0   2   0   0   1\n",
    "#    1   0.3375   0   0   1   3   0   1   0\n",
    "#    1   0.2000   0   1   0   2   0   0   1\n",
    "#   -1   0.2100   0   1   0   1   0   1   0\n",
    "#   -1   0.3225   1   0   0   3   1   0   0\n",
    "#    1   0.2375   0   0   1   2   1   0   0\n",
    "#   -1   0.2250   0   1   0   2   0   1   0\n",
    "#    1   0.1250   1   0   0   1   0   0   1\n",
    "#   -1   0.1925   1   0   0   1   1   0   0\n",
    "#   -1   0.2750   0   1   0   2   0   0   1\n",
    "#    1   0.2200   0   1   0   2   1   0   0\n",
    "#   -1   0.1675   0   1   0   1   1   0   0\n",
    "#   -1   0.1700   0   1   0   1   0   0   1\n",
    "#   -1   0.1350   0   0   1   0   0   1   0\n",
    "#   -1   0.1600   0   1   0   1   0   1   0\n",
    "#   -1   0.2125   0   1   0   1   0   0   1\n",
    "#    1   0.1200   1   0   0   1   0   0   1\n",
    "#   -1   0.2100   0   1   0   2   0   1   0\n",
    "#   -1   0.1250   0   0   1   0   0   0   1\n",
    "#   -1   0.2550   0   1   0   2   0   1   0\n",
    "#    1   0.2750   0   0   1   2   0   1   0\n",
    "#   -1   0.2200   0   0   1   1   1   0   0\n",
    "#    1   0.0925   1   0   0   1   1   0   0\n",
    "#    1   0.3350   0   0   1   3   0   1   0\n",
    "#   -1   0.2250   0   1   0   2   0   0   1\n",
    "#   -1   0.2425   0   1   0   2   1   0   0\n",
    "#    1   0.1275   0   1   0   1   0   1   0\n",
    "#    1   0.3350   0   1   0   3   1   0   0\n",
    "#   -1   0.1850   0   1   0   1   0   0   1\n",
    "#    1   0.1600   0   1   0   1   1   0   0\n",
    "#   -1   0.2400   0   1   0   2   1   0   0\n",
    "#    1   0.3300   0   0   1   3   0   0   1\n",
    "#   -1   0.3075   1   0   0   3   1   0   0\n",
    "#    1   0.2900   0   1   0   3   0   0   1\n",
    "#   -1   0.0950   0   0   1   0   1   0   0\n",
    "#   -1   0.1900   0   1   0   1   0   0   1\n",
    "#    1   0.1375   0   1   0   1   1   0   0\n",
    "#   -1   0.2100   0   1   0   1   1   0   0\n",
    "#   -1   0.3025   1   0   0   3   1   0   0\n",
    "#    1   0.1375   1   0   0   0   0   0   1\n",
    "#   -1   0.1475   1   0   0   1   0   1   0\n",
    "#    1   0.2150   0   1   0   2   1   0   0\n",
    "#   -1   0.2400   0   1   0   2   1   0   0\n",
    "#   -1   0.1375   0   0   1   0   0   0   1\n",
    "#    1   0.2200   1   0   0   2   1   0   0\n",
    "#   -1   0.1150   0   0   1   0   0   1   0\n",
    "#    1   0.1825   0   0   1   2   0   1   0\n",
    "#   -1   0.3225   1   0   0   3   0   0   1\n",
    "#   -1   0.1450   0   0   1   0   0   0   1\n",
    "#    1   0.1675   0   1   0   1   1   0   0\n",
    "#    1   0.3325   0   0   1   3   0   1   0\n",
    "#    1   0.1075   1   0   0   0   0   0   1\n",
    "#   -1   0.1350   0   0   1   0   1   0   0\n",
    "#   -1   0.1450   0   0   1   0   1   0   0\n",
    "#    1   0.1575   0   1   0   1   1   0   0\n",
    "#   -1   0.1825   0   1   0   1   0   0   1\n",
    "#   -1   0.2450   0   1   0   2   0   1   0\n",
    "#    1   0.1425   1   0   0   1   1   0   0\n",
    "#    1   0.2175   0   1   0   2   0   0   1\n",
    "#    1   0.2325   0   1   0   2   0   1   0\n",
    "#   -1   0.2875   1   0   0   3   1   0   0\n",
    "#    1   0.2625   0   1   0   2   0   0   1\n",
    "#    1   0.1575   0   1   0   1   0   0   1\n",
    "#    1   0.2750   0   0   1   2   1   0   0\n",
    "#   -1   0.2500   0   1   0   2   1   0   0\n",
    "#   -1   0.2400   0   1   0   2   0   1   0\n",
    "#    1   0.1100   1   0   0   0   0   0   1\n",
    "#   -1   0.2975   1   0   0   3   0   0   1\n",
    "#   -1   0.1725   0   0   1   1   1   0   0\n",
    "#    1   0.3225   0   0   1   3   1   0   0\n",
    "#   -1   0.1450   0   0   1   0   0   0   1\n",
    "#    1   0.1725   0   1   0   1   0   1   0\n",
    "#    1   0.3050   0   0   1   3   1   0   0\n",
    "#   -1   0.3200   1   0   0   3   0   0   1\n",
    "#    1   0.1450   1   0   0   1   1   0   0\n",
    "#   -1   0.3175   1   0   0   3   0   1   0\n",
    "#    1   0.1475   1   0   0   1   0   1   0\n",
    "#    1   0.2575   0   1   0   2   1   0   0\n",
    "#    1   0.1200   1   0   0   1   0   0   1\n",
    "#   -1   0.2425   0   1   0   2   0   1   0\n",
    "#   -1   0.0900   1   0   0   0   1   0   0\n",
    "#   -1   0.0925   0   0   1   0   1   0   0\n",
    "#   -1   0.1650   0   0   1   1   0   1   0\n",
    "#    1   0.1025   1   0   0   0   0   0   1\n",
    "#   -1   0.1475   0   0   1   0   0   0   1\n",
    "#    1   0.2225   1   0   0   2   0   0   1\n",
    "#    1   0.3250   1   0   0   3   0   0   1\n",
    "#    1   0.2800   0   0   1   2   1   0   0\n",
    "#    1   0.2625   0   1   0   2   0   0   1\n",
    "#    1   0.1450   1   0   0   1   0   1   0\n",
    "#    1   0.2350   0   1   0   2   0   1   0\n",
    "#   -1   0.3425   0   0   1   3   1   0   0\n",
    "#   -1   0.1575   0   1   0   1   0   0   1\n",
    "#   -1   0.3075   0   0   1   2   0   1   0\n",
    "#   -1   0.0950   0   0   1   0   0   1   0\n",
    "#   -1   0.1925   0   1   0   1   0   0   1\n",
    "#    1   0.1300   1   0   0   1   1   0   0\n",
    "#   -1   0.3075   1   0   0   3   0   1   0\n",
    "#   -1   0.2000   0   1   0   1   1   0   0\n",
    "#    1   0.2475   0   1   0   3   1   0   0\n",
    "#   -1   0.2825   1   0   0   3   1   0   0\n",
    "#    1   0.2425   0   1   0   3   0   1   0\n",
    "#   -1   0.2625   0   0   1   2   1   0   0\n",
    "#    1   0.0900   1   0   0   0   1   0   0\n",
    "#    1   0.2800   0   0   1   2   0   0   1\n",
    "#    1   0.2600   0   1   0   2   0   1   0\n",
    "#    1   0.0900   0   1   0   0   0   1   0\n",
    "#    1   0.2900   0   0   1   3   1   0   0\n",
    "#    1   0.1950   0   1   0   2   0   1   0\n",
    "#    1   0.2325   0   1   0   2   1   0   0\n",
    "#    1   0.2025   0   1   0   1   0   1   0\n",
    "#    1   0.3025   0   0   1   3   1   0   0\n",
    "#   -1   0.1800   0   0   1   1   0   1   0\n",
    "#   -1   0.2225   0   1   0   2   1   0   0\n",
    "#   -1   0.1425   0   0   1   0   1   0   0\n",
    "#   -1   0.2725   1   0   0   2   0   0   1\n",
    "#  \n",
    "# houses_test_ord.txt                          \n",
    "#    1   0.2550   0   1   0   2   1   0   0\n",
    "#    1   0.1625   0   1   0   1   0   1   0\n",
    "#   -1   0.2750   1   0   0   2   1   0   0\n",
    "#   -1   0.1275   0   0   1   0   0   0   1\n",
    "#   -1   0.1650   0   0   1   1   0   0   1\n",
    "#    1   0.1450   1   0   0   1   0   1   0\n",
    "#   -1   0.3275   1   0   0   3   1   0   0\n",
    "#    1   0.2175   0   1   0   2   0   1   0\n",
    "#    1   0.2725   0   0   1   2   0   1   0\n",
    "#   -1   0.3075   1   0   0   3   0   1   0\n",
    "#   -1   0.2600   1   0   0   2   0   1   0\n",
    "#   -1   0.1525   0   0   1   0   0   1   0\n",
    "#   -1   0.1450   0   0   1   0   1   0   0\n",
    "#    1   0.2375   0   1   0   2   0   0   1\n",
    "#   -1   0.1950   0   1   0   1   0   1   0\n",
    "#   -1   0.2375   0   1   0   2   0   0   1\n",
    "#    1   0.2475   0   1   0   2   1   0   0\n",
    "#    1   0.3150   0   0   1   3   0   0   1\n",
    "#    1   0.1525   1   0   0   1   1   0   0\n",
    "#    1   0.3050   0   0   1   3   0   0   1\n",
    "#    1   0.2350   0   1   0   2   0   0   1\n",
    "#   -1   0.1525   0   0   1   0   0   0   1\n",
    "#    1   0.2550   0   1   0   2   0   0   1\n",
    "#    1   0.1200   0   1   0   1   1   0   0\n",
    "#    1   0.2450   0   1   0   2   1   0   0\n",
    "#   -1   0.3300   1   0   0   3   0   0   1\n",
    "#    1   0.3275   1   0   0   3   1   0   0\n",
    "#    1   0.2300   1   0   0   2   0   1   0\n",
    "#    1   0.2275   0   1   0   2   0   0   1\n",
    "#    1   0.2350   1   0   0   2   1   0   0\n",
    "#    1   0.1475   1   0   0   1   1   0   0\n",
    "#    1   0.2850   0   0   1   3   0   0   1\n",
    "#    1   0.1000   0   0   1   0   1   0   0\n",
    "#    1   0.1750   0   1   0   1   1   0   0\n",
    "#    1   0.3075   0   0   1   3   0   0   1\n",
    "#    1   0.1550   0   1   0   1   0   0   1\n",
    "#   -1   0.0925   0   0   1   0   1   0   0\n",
    "#   -1   0.1300   0   0   1   0   0   0   1\n",
    "#    1   0.1425   0   0   1   1   1   0   0\n",
    "#    1   0.2975   0   0   1   3   0   0   1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
